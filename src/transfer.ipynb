{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Step 1: Load Model\n",
    "Before we begin transfer learning we first have to load the model. This can be done in two ways (1) load the `model.pth` which includes the model's architecture and weights, or (2) load the model class itself, defined in `pyg_model.py`. Either way works, but (2) is a bit safer when dealing with unknown files. After loading the model, we then load the state dictionary `model_state_dict.pth` which allows us to reference specific layers of the model and is crucial for examining, extracting, or modifying its underlying architecture."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<All keys matched successfully>"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import torch\n",
    "import copy\n",
    "from models import relative_positioning\n",
    "\n",
    "# Model parameters\n",
    "num_node_features = 1\n",
    "num_edge_features = 1\n",
    "hidden_channels = 64\n",
    "out_channels = 32\n",
    "\n",
    "# Load model\n",
    "pretrained_model = relative_positioning(num_node_features=num_node_features, num_edge_features=num_edge_features, \n",
    "                             hidden_channels=hidden_channels, out_channels=out_channels)\n",
    "\n",
    "# Load model state dictionary\n",
    "model_sd_path = r\"C:\\Users\\xmoot\\Desktop\\Models\\PyTorch\\ssl-seizure-detection\\relative_positioning\\jh101\\jh101_12s_7min_model1_state_dict.pth\"\n",
    "pretrained_model.load_state_dict(torch.load(model_sd_path))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Step 2: Extract Layers\n",
    "In this step we extract the layers we want to use for the supervised model downstream. In this case, we need the NNConv and GATConv layers from our model, but since our NNConv actually depends on a separate layer called EdgeMLP (which is just a multilayer perpcetron), we'll need that too, since it's essentially part of the NNConv layer's parameters. You can assign it the old fashioned way using `EdgeMLP_module = model.edge_mlp` but this will create issues later on when we try to make two copies of `EdgeMLP_module` for freezing and unfreezing it, so we use the `copy` package instead."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "EdgeMLP_module = copy.deepcopy(pretrained_model.edge_mlp)\n",
    "NNConv_module = copy.deepcopy(pretrained_model.conv1)\n",
    "GATConv_module = copy.deepcopy(pretrained_model.conv2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can examine the weights of a layer with the following:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "mlp.0.weight \t torch.Size([128, 1])\n",
      "mlp.0.bias \t torch.Size([128])\n",
      "mlp.2.weight \t torch.Size([64, 128])\n",
      "mlp.2.bias \t torch.Size([64])\n",
      "mlp.4.weight \t torch.Size([64, 64])\n",
      "mlp.4.bias \t torch.Size([64])\n"
     ]
    }
   ],
   "source": [
    "for param_tensor in EdgeMLP_module.state_dict():\n",
    "    print(param_tensor, \"\\t\", EdgeMLP_module.state_dict()[param_tensor].size())\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "And here's a test running some random input through the EdgeMLP, to verify it's functional."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[-0.3229, -0.0647, -0.2705, -0.2843, -0.1541, -0.2524, -0.4764,  0.0350,\n",
      "         -0.5136,  0.8326, -0.3843, -0.1110,  0.3624,  0.5415, -0.3629, -0.2937,\n",
      "          0.2259,  0.3114, -0.4199, -0.3076, -0.2893, -0.3380, -0.4476,  0.0408,\n",
      "         -0.5259,  0.3565,  0.3233, -0.3103,  0.0072, -0.2885, -0.3414, -0.1583,\n",
      "          0.5735, -0.1864, -0.1011,  0.0099, -0.1902, -0.4369, -0.0530, -0.1795,\n",
      "         -0.4398, -0.4034,  0.6602,  0.7605, -0.1404,  0.4234, -0.1385, -0.1724,\n",
      "         -0.3312,  0.7015,  0.6666,  0.8652,  0.2292, -0.3177, -0.2220, -0.0868,\n",
      "          0.3910, -0.3581, -0.0492,  0.4877, -0.0851, -0.5695, -0.2949,  0.6281],\n",
      "        [-0.4303, -0.2289, -0.2291, -0.2866, -0.1709, -0.4072, -0.4801,  0.0354,\n",
      "         -0.6393,  0.8586, -0.3117, -0.1384,  0.2977,  0.6900, -0.4050, -0.2402,\n",
      "          0.1145,  0.3382, -0.4300, -0.4596, -0.2861, -0.5100, -0.4041, -0.0090,\n",
      "         -0.6471,  0.2327,  0.2302, -0.3289, -0.1161, -0.2566, -0.4129, -0.0981,\n",
      "          0.5699, -0.1898, -0.0791,  0.0377, -0.1788, -0.4360,  0.0712, -0.2406,\n",
      "         -0.5305, -0.4593,  0.9282,  0.5631, -0.1431,  0.4203, -0.3087, -0.2162,\n",
      "         -0.4095,  0.8349,  0.9109,  0.8849,  0.4601, -0.2907, -0.1772, -0.0392,\n",
      "          0.4127, -0.3325,  0.1317,  0.4312, -0.1000, -0.7613, -0.2627,  0.7675],\n",
      "        [-0.4482, -0.2538, -0.2255, -0.2916, -0.1726, -0.4297, -0.4800,  0.0300,\n",
      "         -0.6565,  0.8699, -0.3035, -0.1488,  0.2871,  0.7048, -0.4126, -0.2373,\n",
      "          0.1030,  0.3455, -0.4330, -0.4764, -0.2836, -0.5324, -0.3949, -0.0118,\n",
      "         -0.6644,  0.2250,  0.2229, -0.3330, -0.1358, -0.2513, -0.4220, -0.0915,\n",
      "          0.5739, -0.1887, -0.0785,  0.0382, -0.1823, -0.4375,  0.0816, -0.2514,\n",
      "         -0.5447, -0.4692,  0.9635,  0.5365, -0.1444,  0.4247, -0.3277, -0.2213,\n",
      "         -0.4186,  0.8448,  0.9408,  0.8919,  0.4862, -0.2861, -0.1711, -0.0370,\n",
      "          0.4188, -0.3274,  0.1485,  0.4244, -0.1036, -0.7828, -0.2542,  0.7864],\n",
      "        [-0.5389, -0.2494, -0.2660, -0.5819, -0.1528, -0.1549, -0.7760, -0.1519,\n",
      "         -0.3710,  1.5918, -0.5961, -0.2944, -0.0046,  0.4284, -0.3597, -0.5393,\n",
      "          0.3795,  0.4966, -0.7240, -0.3949, -0.1391, -0.1240, -0.7610,  0.5431,\n",
      "         -0.5217,  1.2723,  1.0006, -0.5459, -0.0453, -0.5418, -0.4303, -0.4413,\n",
      "          1.2676, -0.3114, -0.1930, -0.5070, -0.3510, -0.8202, -0.3701, -0.2135,\n",
      "         -0.7087, -0.3093,  0.6015,  1.1397, -0.1702,  1.3673, -0.1247, -0.2336,\n",
      "         -0.4489,  0.3818,  0.7630,  1.2005, -0.1272, -0.5040, -0.4256, -0.3143,\n",
      "          0.8517, -0.5490, -0.7348,  0.3939, -0.4096, -0.3416, -0.4777,  0.5337],\n",
      "        [-0.3840, -0.1031, -0.2738, -0.3281, -0.1458, -0.1654, -0.5078, -0.0297,\n",
      "         -0.4515,  0.9969, -0.4116, -0.1519,  0.2743,  0.4547, -0.3187, -0.3558,\n",
      "          0.3265,  0.3446, -0.4220, -0.2693, -0.2557, -0.2527, -0.5013,  0.1424,\n",
      "         -0.5240,  0.5695,  0.4816, -0.3828,  0.0165, -0.3372, -0.3576, -0.2712,\n",
      "          0.7150, -0.2123, -0.1262, -0.0993, -0.1973, -0.5086, -0.1638, -0.1802,\n",
      "         -0.4369, -0.3704,  0.5261,  0.8591, -0.1543,  0.6390, -0.0602, -0.1909,\n",
      "         -0.3112,  0.5635,  0.5697,  0.8911,  0.0599, -0.3670, -0.2845, -0.1625,\n",
      "          0.4620, -0.3626, -0.2455,  0.5048, -0.1281, -0.4287, -0.3188,  0.5311],\n",
      "        [-0.6254, -0.3226, -0.3490, -0.7919, -0.2032, -0.1915, -1.0215, -0.2209,\n",
      "         -0.3702,  1.9769, -0.7450, -0.4050, -0.1349,  0.3895, -0.4210, -0.6427,\n",
      "          0.3913,  0.6644, -0.9992, -0.4188, -0.0994, -0.0525, -0.9642,  0.7949,\n",
      "         -0.6119,  1.7833,  1.3685, -0.5939, -0.1561, -0.7138, -0.5511, -0.4588,\n",
      "          1.7152, -0.4191, -0.2123, -0.7634, -0.5133, -1.0253, -0.5478, -0.3096,\n",
      "         -0.9187, -0.3114,  0.7722,  1.4026, -0.2127,  1.8589, -0.2278, -0.2640,\n",
      "         -0.5955,  0.2583,  0.9617,  1.4929, -0.1792, -0.6326, -0.5635, -0.4578,\n",
      "          1.1498, -0.6841, -1.0723,  0.3565, -0.5658, -0.3639, -0.5977,  0.6856],\n",
      "        [-0.4175, -0.2093, -0.2330, -0.2832, -0.1693, -0.3916, -0.4796,  0.0387,\n",
      "         -0.6273,  0.8502, -0.3179, -0.1327,  0.3053,  0.6778, -0.4000, -0.2417,\n",
      "          0.1233,  0.3336, -0.4271, -0.4447, -0.2873, -0.4936, -0.4094, -0.0061,\n",
      "         -0.6342,  0.2401,  0.2357, -0.3252, -0.1029, -0.2604, -0.4063, -0.1016,\n",
      "          0.5680, -0.1908, -0.0799,  0.0361, -0.1778, -0.4350,  0.0615, -0.2341,\n",
      "         -0.5204, -0.4523,  0.9030,  0.5828, -0.1425,  0.4174, -0.2951, -0.2128,\n",
      "         -0.4029,  0.8256,  0.8875,  0.8812,  0.4401, -0.2926, -0.1804, -0.0418,\n",
      "          0.4088, -0.3353,  0.1185,  0.4356, -0.0980, -0.7443, -0.2684,  0.7546],\n",
      "        [-0.3380, -0.0762, -0.2778, -0.2944, -0.1531, -0.2205, -0.4770,  0.0146,\n",
      "         -0.4967,  0.8800, -0.3902, -0.1227,  0.3447,  0.5125, -0.3469, -0.3226,\n",
      "          0.2579,  0.3261, -0.4176, -0.2825, -0.2833, -0.3011, -0.4600,  0.0693,\n",
      "         -0.5271,  0.4232,  0.3786, -0.3270,  0.0089, -0.3001, -0.3402, -0.2001,\n",
      "          0.6175, -0.1930, -0.1067, -0.0180, -0.1900, -0.4617, -0.0957, -0.1826,\n",
      "         -0.4407, -0.3949,  0.6110,  0.7964, -0.1506,  0.4848, -0.1001, -0.1744,\n",
      "         -0.3260,  0.6531,  0.6219,  0.8697,  0.1714, -0.3273, -0.2414, -0.1111,\n",
      "          0.4170, -0.3592, -0.1144,  0.5011, -0.0920, -0.5208, -0.2976,  0.5979],\n",
      "        [-0.5404, -0.3681, -0.2425, -0.3269, -0.2135, -0.5812, -0.4792, -0.0033,\n",
      "         -0.7516,  0.9899, -0.2777, -0.2197,  0.2507,  0.7920, -0.4661, -0.2354,\n",
      "          0.0310,  0.4190, -0.4799, -0.5285, -0.2484, -0.6454, -0.3714,  0.0096,\n",
      "         -0.7760,  0.2583,  0.2368, -0.3331, -0.2667, -0.2218, -0.4932, -0.0388,\n",
      "          0.6201, -0.1831, -0.1007,  0.0079, -0.2251, -0.4454,  0.1052, -0.3122,\n",
      "         -0.6688, -0.5326,  1.1876,  0.4405, -0.1643,  0.4867, -0.4335, -0.2534,\n",
      "         -0.4842,  0.8689,  1.0966,  0.9881,  0.6464, -0.2509, -0.1560, -0.0433,\n",
      "          0.5215, -0.3245,  0.2139,  0.4081, -0.1191, -0.8893, -0.2081,  0.9092],\n",
      "        [-0.8072, -0.2626, -0.5919, -0.4667, -0.3273, -1.0520, -0.6879, -0.1846,\n",
      "         -1.1167,  1.4774, -0.3310, -0.3671,  0.3525,  0.8216, -0.6506, -0.4056,\n",
      "          0.0037,  0.9910, -0.7213, -0.0047, -0.2576, -0.6252, -0.2472,  0.1640,\n",
      "         -1.0388,  0.6416,  0.6766, -0.2290, -0.6280, -0.3025, -0.7571,  0.0474,\n",
      "          1.0029, -0.2655, -0.1426, -0.2713, -0.4377, -0.4169, -0.1685, -0.5366,\n",
      "         -1.0839, -0.6098,  1.6089,  0.7415, -0.1872,  0.7825, -0.6316, -0.3159,\n",
      "         -0.4327,  0.4010,  1.1202,  1.4465,  0.4825, -0.1662, -0.1541, -0.2814,\n",
      "          0.8742, -0.3922, -0.2651,  0.2219, -0.0997, -1.1038, -0.2092,  1.3944]],\n",
      "       grad_fn=<AddmmBackward0>)\n"
     ]
    }
   ],
   "source": [
    "# Create some dummy data\n",
    "dummy_edge_attr = torch.randn(10, num_edge_features)  # 10 edges, each with `num_edge_features` features\n",
    "\n",
    "# Run the data through the `edge_mlp` layer\n",
    "output = EdgeMLP_module(dummy_edge_attr)\n",
    "print(output)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Step 3: Downstream Task\n",
    "After extracting the layers and verifying everything is functional, we can now either (1) use the layers and their weights as initialization, or (2) use the layers but freeze the weights (i.e. they won't be updated during training). Below uses method (1), using our transferred layers as the initial layers of our network, and then we add on newer (untrained) layers on top of it. I've opted to use another `NNConv` and `GATConv` layer from `PyG`, adding onto the existing `NNConv` and `GATConv` layers, as well as a `global_mean_pool` layer and two fully connected layers. Now we're ready to go!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch.nn as nn\n",
    "from torch_geometric.nn import NNConv, GATConv\n",
    "from torch.functional import F\n",
    "from torch_geometric.nn import global_mean_pool\n",
    "from models import EdgeMLP\n",
    "\n",
    "\n",
    "class seizure_detection1(nn.Module):\n",
    "    def __init__(self, num_edge_features, prev_channels, hidden_channels, out_channels, fc_channels):\n",
    "        super(seizure_detection1, self).__init__()\n",
    "        \n",
    "        # Transfered graph layers\n",
    "        self.edge_mlp1 = EdgeMLP_module\n",
    "        self.conv1 = NNConv_module \n",
    "        self.conv2 = GATConv_module   \n",
    "\n",
    "        # # New graph layers\n",
    "        self.edge_mlp2 = EdgeMLP(num_edge_features, prev_channels, hidden_channels) # The number of node features are updated, therefore harde code this in.\n",
    "        self.conv3 = NNConv(prev_channels, hidden_channels, self.edge_mlp2)  # New NNConv layer\n",
    "        self.conv4 = GATConv(hidden_channels, out_channels, heads=1, concat=False) # New GATConv layer\n",
    "        \n",
    "        # # Fully connected layers\n",
    "        self.fc1 = nn.Linear(out_channels, fc_channels)\n",
    "        self.fc2 = nn.Linear(fc_channels, 1)\n",
    "        \n",
    "    def forward(self, x, edge_index, edge_attr, batch, mode = \"sigmoid\"):\n",
    "        # Your forward pass\n",
    "        \n",
    "        # NNConv layer 1\n",
    "        print(\"Initial:\", x.shape, edge_index.shape, edge_attr.shape)\n",
    "        x = self.conv1(x, edge_index, edge_attr)\n",
    "        print(\"After conv1:\", x.shape, edge_index.shape, edge_attr.shape)\n",
    "        x = F.relu(x)\n",
    "        \n",
    "        # GATConv layer 1\n",
    "        x = self.conv2(x, edge_index)\n",
    "        print(\"After conv2:\", x.shape, edge_index.shape, edge_attr.shape)\n",
    "        x = F.relu(x)\n",
    "        \n",
    "        # NNConv layer 2\n",
    "        x = self.conv3(x, edge_index, edge_attr)\n",
    "        print(\"After conv3:\", x.shape, edge_index.shape, edge_attr.shape)\n",
    "        x = F.relu(x)\n",
    "        \n",
    "        # GATConv layer 2\n",
    "        x = self.conv4(x, edge_index)\n",
    "        print(\"After conv4:\", x.shape, edge_index.shape, edge_attr.shape)\n",
    "        x = F.relu(x)\n",
    "        \n",
    "        # Global average pooling\n",
    "        x = global_mean_pool(x, batch)\n",
    "        \n",
    "        # Fully connected layer 1\n",
    "        x = self.fc1(x)\n",
    "        x = F.relu(x)\n",
    "        \n",
    "        # Fully connected layer 2\n",
    "        x = self.fc2(x)\n",
    "\n",
    "        if mode == \"sigmoid\":\n",
    "            x = torch.sigmoid(x)\n",
    "            \n",
    "        elif mode == \"linear\":\n",
    "            pass\n",
    "        \n",
    "        return x"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's load our list of `Data` objects we prepared, which holds our graphs `[edge_index, x, edge_attr]` and labels `y`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load data\n",
    "from torch_geometric.loader import DataLoader\n",
    "\n",
    "data_path = r\"C:\\Users\\xmoot\\Desktop\\Data\\ssl-seizure-detection\\patient_gr\\jh101_pyg_Data.pt\"\n",
    "data = torch.load(data_path)\n",
    "loader = DataLoader(data, batch_size=32, shuffle=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now let's test the model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Initial: torch.Size([107, 1]) torch.Size([2, 11342]) torch.Size([11342, 1])\n",
      "After conv1: torch.Size([107, 64]) torch.Size([2, 11342]) torch.Size([11342, 1])\n",
      "After conv2: torch.Size([107, 64]) torch.Size([2, 11342]) torch.Size([11342, 1])\n",
      "After conv3: torch.Size([107, 128]) torch.Size([2, 11342]) torch.Size([11342, 1])\n",
      "After conv4: torch.Size([107, 64]) torch.Size([2, 11342]) torch.Size([11342, 1])\n",
      "tensor([[856.9504]], grad_fn=<AddmmBackward0>)\n"
     ]
    }
   ],
   "source": [
    "# Model parameters\n",
    "num_edge_features = 1\n",
    "prev_channels = 64 #<--- The dimension of of the node features that comes from the transferred layers, i.e. x is shape [num_nodes, prev_channels\n",
    "hidden_channels = 128\n",
    "out_channels = 64\n",
    "fc_channels = 32\n",
    "\n",
    "\n",
    "# Load model\n",
    "unfrozen_model = seizure_detection1(num_edge_features=num_edge_features, prev_channels=prev_channels, hidden_channels=hidden_channels, \n",
    "                          out_channels=out_channels, fc_channels=fc_channels)\n",
    "\n",
    "# Try an example data point\n",
    "example = data[0]\n",
    "\n",
    "out = unfrozen_model(example.x, example.edge_index, example.edge_attr, example.batch, mode=\"linear\")\n",
    "print(out)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now let's implement method (2) with frozen layers."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "import copy\n",
    "\n",
    "frozen_EdgeMLP_module = copy.deepcopy(pretrained_model.edge_mlp)\n",
    "frozen_NNConv_module = copy.deepcopy(pretrained_model.conv1)\n",
    "frozen_GATConv_module = copy.deepcopy(pretrained_model.conv2)\n",
    "\n",
    "# Freeze the layers\n",
    "for param in frozen_EdgeMLP_module.parameters():\n",
    "    param.requires_grad = False\n",
    "\n",
    "for param in frozen_NNConv_module.parameters():\n",
    "    param.requires_grad = False\n",
    "\n",
    "for param in frozen_GATConv_module.parameters():\n",
    "    param.requires_grad = False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch.nn as nn\n",
    "from torch_geometric.nn import NNConv, GATConv\n",
    "from torch.functional import F\n",
    "from torch_geometric.nn import global_mean_pool\n",
    "from models import EdgeMLP\n",
    "\n",
    "\n",
    "class seizure_detection2(nn.Module):\n",
    "    def __init__(self, num_edge_features, prev_channels, hidden_channels, out_channels, fc_channels):\n",
    "        super(seizure_detection2, self).__init__()\n",
    "        \n",
    "        # Transfered graph layers\n",
    "        self.edge_mlp1 = frozen_EdgeMLP_module\n",
    "        self.conv1 = frozen_NNConv_module \n",
    "        self.conv2 = frozen_GATConv_module   \n",
    "\n",
    "        # # New graph layers\n",
    "        self.edge_mlp2 = EdgeMLP(num_edge_features, prev_channels, hidden_channels) # The number of node features are updated, therefore harde code this in.\n",
    "        self.conv3 = NNConv(prev_channels, hidden_channels, self.edge_mlp2)  # New NNConv layer\n",
    "        self.conv4 = GATConv(hidden_channels, out_channels, heads=1, concat=False) # New GATConv layer\n",
    "        \n",
    "        # # Fully connected layers\n",
    "        self.fc1 = nn.Linear(out_channels, fc_channels)\n",
    "        self.fc2 = nn.Linear(fc_channels, 1)\n",
    "        \n",
    "    def forward(self, x, edge_index, edge_attr, batch, mode = \"sigmoid\"):\n",
    "        # Your forward pass\n",
    "        \n",
    "        # NNConv layer 1\n",
    "        print(\"Initial:\", x.shape, edge_index.shape, edge_attr.shape)\n",
    "        x = self.conv1(x, edge_index, edge_attr)\n",
    "        print(\"After conv1:\", x.shape, edge_index.shape, edge_attr.shape)\n",
    "        x = F.relu(x)\n",
    "        \n",
    "        # GATConv layer 1\n",
    "        x = self.conv2(x, edge_index)\n",
    "        print(\"After conv2:\", x.shape, edge_index.shape, edge_attr.shape)\n",
    "        x = F.relu(x)\n",
    "        \n",
    "        # NNConv layer 2\n",
    "        x = self.conv3(x, edge_index, edge_attr)\n",
    "        print(\"After conv3:\", x.shape, edge_index.shape, edge_attr.shape)\n",
    "        x = F.relu(x)\n",
    "        \n",
    "        # GATConv layer 2\n",
    "        x = self.conv4(x, edge_index)\n",
    "        print(\"After conv4:\", x.shape, edge_index.shape, edge_attr.shape)\n",
    "        x = F.relu(x)\n",
    "        \n",
    "        # Global average pooling\n",
    "        x = global_mean_pool(x, batch)\n",
    "        \n",
    "        # Fully connected layer 1\n",
    "        x = self.fc1(x)\n",
    "        x = F.relu(x)\n",
    "        \n",
    "        # Fully connected layer 2\n",
    "        x = self.fc2(x)\n",
    "\n",
    "        if mode == \"sigmoid\":\n",
    "            x = torch.sigmoid(x)\n",
    "            \n",
    "        elif mode == \"linear\":\n",
    "            pass\n",
    "        \n",
    "        return x"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Then we can check whether our models are frozen or not."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Layer: edge_mlp1.mlp.0.weight, Frozen: False\n",
      "Layer: edge_mlp1.mlp.0.bias, Frozen: False\n",
      "Layer: edge_mlp1.mlp.2.weight, Frozen: False\n",
      "Layer: edge_mlp1.mlp.2.bias, Frozen: False\n",
      "Layer: edge_mlp1.mlp.4.weight, Frozen: False\n",
      "Layer: edge_mlp1.mlp.4.bias, Frozen: False\n",
      "Layer: conv1.bias, Frozen: False\n",
      "Layer: conv1.nn.mlp.0.weight, Frozen: False\n",
      "Layer: conv1.nn.mlp.0.bias, Frozen: False\n",
      "Layer: conv1.nn.mlp.2.weight, Frozen: False\n",
      "Layer: conv1.nn.mlp.2.bias, Frozen: False\n",
      "Layer: conv1.nn.mlp.4.weight, Frozen: False\n",
      "Layer: conv1.nn.mlp.4.bias, Frozen: False\n",
      "Layer: conv1.lin.weight, Frozen: False\n",
      "Layer: conv2.att_src, Frozen: False\n",
      "Layer: conv2.att_dst, Frozen: False\n",
      "Layer: conv2.bias, Frozen: False\n",
      "Layer: conv2.lin_src.weight, Frozen: False\n",
      "Layer: edge_mlp2.mlp.0.weight, Frozen: False\n",
      "Layer: edge_mlp2.mlp.0.bias, Frozen: False\n",
      "Layer: edge_mlp2.mlp.2.weight, Frozen: False\n",
      "Layer: edge_mlp2.mlp.2.bias, Frozen: False\n",
      "Layer: edge_mlp2.mlp.4.weight, Frozen: False\n",
      "Layer: edge_mlp2.mlp.4.bias, Frozen: False\n",
      "Layer: conv3.bias, Frozen: False\n",
      "Layer: conv3.lin.weight, Frozen: False\n",
      "Layer: conv4.att_src, Frozen: False\n",
      "Layer: conv4.att_dst, Frozen: False\n",
      "Layer: conv4.bias, Frozen: False\n",
      "Layer: conv4.lin_src.weight, Frozen: False\n",
      "Layer: fc1.weight, Frozen: False\n",
      "Layer: fc1.bias, Frozen: False\n",
      "Layer: fc2.weight, Frozen: False\n",
      "Layer: fc2.bias, Frozen: False\n",
      "----------------------------------------------------\n",
      "Layer: edge_mlp1.mlp.0.weight, Frozen: True\n",
      "Layer: edge_mlp1.mlp.0.bias, Frozen: True\n",
      "Layer: edge_mlp1.mlp.2.weight, Frozen: True\n",
      "Layer: edge_mlp1.mlp.2.bias, Frozen: True\n",
      "Layer: edge_mlp1.mlp.4.weight, Frozen: True\n",
      "Layer: edge_mlp1.mlp.4.bias, Frozen: True\n",
      "Layer: conv1.bias, Frozen: True\n",
      "Layer: conv1.nn.mlp.0.weight, Frozen: True\n",
      "Layer: conv1.nn.mlp.0.bias, Frozen: True\n",
      "Layer: conv1.nn.mlp.2.weight, Frozen: True\n",
      "Layer: conv1.nn.mlp.2.bias, Frozen: True\n",
      "Layer: conv1.nn.mlp.4.weight, Frozen: True\n",
      "Layer: conv1.nn.mlp.4.bias, Frozen: True\n",
      "Layer: conv1.lin.weight, Frozen: True\n",
      "Layer: conv2.att_src, Frozen: True\n",
      "Layer: conv2.att_dst, Frozen: True\n",
      "Layer: conv2.bias, Frozen: True\n",
      "Layer: conv2.lin_src.weight, Frozen: True\n",
      "Layer: edge_mlp2.mlp.0.weight, Frozen: False\n",
      "Layer: edge_mlp2.mlp.0.bias, Frozen: False\n",
      "Layer: edge_mlp2.mlp.2.weight, Frozen: False\n",
      "Layer: edge_mlp2.mlp.2.bias, Frozen: False\n",
      "Layer: edge_mlp2.mlp.4.weight, Frozen: False\n",
      "Layer: edge_mlp2.mlp.4.bias, Frozen: False\n",
      "Layer: conv3.bias, Frozen: False\n",
      "Layer: conv3.lin.weight, Frozen: False\n",
      "Layer: conv4.att_src, Frozen: False\n",
      "Layer: conv4.att_dst, Frozen: False\n",
      "Layer: conv4.bias, Frozen: False\n",
      "Layer: conv4.lin_src.weight, Frozen: False\n",
      "Layer: fc1.weight, Frozen: False\n",
      "Layer: fc1.bias, Frozen: False\n",
      "Layer: fc2.weight, Frozen: False\n",
      "Layer: fc2.bias, Frozen: False\n"
     ]
    }
   ],
   "source": [
    "num_edge_features = 1\n",
    "prev_channels = 64\n",
    "hidden_channels = 128\n",
    "out_channels = 64\n",
    "fc_channels = 32\n",
    "\n",
    "unfrozen_model = seizure_detection1(num_edge_features=num_edge_features, prev_channels=prev_channels, hidden_channels=hidden_channels, \n",
    "                          out_channels=out_channels, fc_channels=fc_channels)\n",
    "\n",
    "frozen_model = seizure_detection2(num_edge_features=num_edge_features, prev_channels=prev_channels, hidden_channels=hidden_channels, \n",
    "                          out_channels=out_channels, fc_channels=fc_channels)\n",
    "\n",
    "for name, param in unfrozen_model.named_parameters():\n",
    "    print(f\"Layer: {name}, Frozen: {not param.requires_grad}\")\n",
    "print(\"----------------------------------------------------\")    \n",
    "for name, param in frozen_model.named_parameters():\n",
    "    print(f\"Layer: {name}, Frozen: {not param.requires_grad}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Step 4: Fine-Tuning for Seizure Detection"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "torch2_cuda11.8",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
