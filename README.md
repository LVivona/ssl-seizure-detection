# Self-Supervised Learning with Graph Neural Networks for Seizure Detection

<p align="center">
  <img src="https://drive.google.com/uc?id=1SU_F5OLTBjBJCGR3dvcpl8vKSU3Q9vOg" alt="Project Image" style="width: 100%;"/>
  <em style="font-size: small; opacity: 0.3;">Image generated by DALL·E 3</em>
</p>



## Introduction

This research project adapts several self-supervised learning (SSL) techniques with Graph Neural Network (GNN) encoders to domain of seizure detection. We appy our GNN encoder to the following SSL methods and evaluate their performance downstream on seizure detection: Relative Positioning, Temporal Shuffling, Contrastive Predictive Coding (CPC), and Variance-Invariance-Covariance Regularization (VICReg). The GNN architecture comprises of Edge-Conditioned Convolution (ECC) and Graph Attention Network (GAT) layers, utilizing PyTorch and PyTorch Geometric libraries for standard deep learning and GNN implementation. For a more detailed description of our research, see [projects/ssl-seizure-detection](https://www.xaviermootoo.com/projects/ssl-seizure-detection).

> Please refer to the relevant papers:
> - A Path Towards Autonomous Machine Intelligence [(Lecun, 2022)][def]
> - Edge-Conditioned Convolution (ECC): [(Simonovsky & Komodakis, 2017)](https://arxiv.org/abs/1704.02901)
> - Graph Attention Layer (GAT): [(Veličković et al., 2018)](https://arxiv.org/abs/1710.10903)
> - Relative Positioning and Temporal Shuffling [(Banvile et al., 2021)](https://arxiv.org/abs/2007.16104)
> - Contrastive Predictive Coding (CPC) [(Oord et al., 2018)](https://arxiv.org/abs/1807.03748)
> - Variance-Invariance-Covariance Regularization (VICreg) [(Bardes et al., 2022)](https://arxiv.org/abs/2105.04906)

## Table of Contents
1. [Usage](#usage)
2. [File Descriptions](#file-descriptions)
3. [License](#license)
4. [Contact](#contact)

## Installation

### Prerequisites
- Python 3.8-3.11
- PyTorch 2.0.1+
- PyTorch Geometric (PyG)
- scikit-learn
- Pandas
- Weights & Biases


## Usage

To run the main program, use the following command (which we optimized for GPU usage on the Graham cluster in Digital Research Alliance of Canada (Canada Compute).

```bash
python $data_path $model_path $stats_path $model_name $num_workers main.py
```

- For information on preprocessing, please see: `preprocess.ipynb`.

- For an introductory tutorial to graph pair classification with PyG, please see `tutorial.ipynb`.

## File Descriptions

- **models.py**: Contains both self-supervised and supervised models, including the GNN architecture with ECC and GAT layers.
- **train.py**: Implements the main training loop for both self-supervised and supervised models. Also includes automatic mixed precision, which provides faster training without sacrificing accuracy.
- **tutorial.ipynb**: A Jupyter notebook tutorial on how to use PyTorch Geometric (PyG) in the context of the project.
- **main.py**: The primary script to run the entire pipeline, optimized for Graham cluster resources.
- **preprocess.py**: Includes helper functions for all preprocessing tasks, such as converting initial graph representations to PyG-compatible structures.
- **preprocess.ipynb**: A guided notebook that demonstrates how to use preprocessing functions for both supervised and self-supervised learning.
- **transfer.ipynb**: A notebook illustrating how to apply transfer learning from self-supervised to supervised models and fine-tuning them.

## License

This project is licensed under the MIT License.

## Contact

For any queries, please contact [xmotoo at gmail dot com](mailto:xmootoo@gmail.com).


[def]: https://openreview.net/pdf?id=BZ5a1r-kVsf