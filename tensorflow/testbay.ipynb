{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "4\n"
     ]
    }
   ],
   "source": [
    "import tensorflow as tf\n",
    "import numpy as np\n",
    "import pickle\n",
    "x = 4\n",
    "print(x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "def generator(data):\n",
    "    \"\"\"Generates data for the dataset.\"\"\"\n",
    "    for (gr_1, gr_2, y) in data:\n",
    "        yield (\n",
    "            tuple(tf.convert_to_tensor(arr, dtype=tf.float32) for arr in gr_1),\n",
    "            tuple(tf.convert_to_tensor(arr, dtype=tf.float32) for arr in gr_2),\n",
    "            y\n",
    "        )\n",
    "\n",
    "def dataset_tf(data):\n",
    "    \"\"\"Creates a TensorFlow dataset from the data.\"\"\"\n",
    "    # Define the output types and shapes\n",
    "    output_signature = (\n",
    "        (tf.TensorSpec(shape=None, dtype=tf.float32),\n",
    "         tf.TensorSpec(shape=None, dtype=tf.float32),\n",
    "         tf.TensorSpec(shape=None, dtype=tf.float32)),\n",
    "        (tf.TensorSpec(shape=None, dtype=tf.float32),\n",
    "         tf.TensorSpec(shape=None, dtype=tf.float32),\n",
    "         tf.TensorSpec(shape=None, dtype=tf.float32)),\n",
    "        tf.TensorSpec(shape=(), dtype=tf.int32)\n",
    "    )\n",
    "\n",
    "    # Create a dataset\n",
    "    dataset = tf.data.Dataset.from_generator(\n",
    "        lambda: generator(data), # Using a lambda function to call generator with data\n",
    "        output_signature=(output_signature[0], output_signature[1], output_signature[2])\n",
    "    )\n",
    "\n",
    "    return dataset\n",
    "\n",
    "\n",
    "#FIXME: This function is not working properly; everything above is working.\n",
    "def dataset_prep(dataset, val_split=0.1, test_split=0.1, batch_size=32):\n",
    "    # Shuffle the entire dataset\n",
    "    BUFFER_SIZE = 10000\n",
    "    dataset = dataset.shuffle(BUFFER_SIZE)\n",
    "\n",
    "    # Calculate the sizes for splitting\n",
    "    total_size = sum(1 for _ in dataset)\n",
    "    val_size = int(val_split * total_size)\n",
    "    test_size = int(test_split * total_size)\n",
    "    train_size = total_size - val_size - test_size\n",
    "\n",
    "    # Split into training, validation, and test sets\n",
    "    train_dataset = dataset.take(train_size)\n",
    "    val_dataset = dataset.skip(train_size).take(val_size)\n",
    "    test_dataset = dataset.skip(train_size + val_size)\n",
    "\n",
    "    # Batch and prefetch for all datasets\n",
    "    train_dataset = train_dataset.batch(batch_size).prefetch(tf.data.experimental.AUTOTUNE)\n",
    "    val_dataset = val_dataset.batch(batch_size).prefetch(tf.data.experimental.AUTOTUNE)\n",
    "    test_dataset = test_dataset.batch(batch_size).prefetch(tf.data.experimental.AUTOTUNE)\n",
    "\n",
    "    return train_dataset, val_dataset, test_dataset\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "ename": "InvalidArgumentError",
     "evalue": "{{function_node __wrapped__IteratorGetNext_output_types_7_device_/job:localhost/replica:0/task:0/device:CPU:0}} Cannot batch tensors with different shapes in component 0. First element had shape [2,2] and element 2 had shape [3]. [Op:IteratorGetNext]",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mInvalidArgumentError\u001b[0m                      Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[20], line 19\u001b[0m\n\u001b[0;32m     17\u001b[0m train_dataset, val_dataset, test_dataset \u001b[39m=\u001b[39m dataset_prep(my_dataset, val_split\u001b[39m=\u001b[39m\u001b[39m0.1\u001b[39m, test_split\u001b[39m=\u001b[39m\u001b[39m0.1\u001b[39m, batch_size\u001b[39m=\u001b[39m\u001b[39m32\u001b[39m)\n\u001b[0;32m     18\u001b[0m \u001b[39m# Iterate through the dataset\u001b[39;00m\n\u001b[1;32m---> 19\u001b[0m \u001b[39mfor\u001b[39;00m item \u001b[39min\u001b[39;00m train_dataset:\n\u001b[0;32m     20\u001b[0m     graph1, graph2, label \u001b[39m=\u001b[39m item\n\u001b[0;32m     21\u001b[0m     \u001b[39mprint\u001b[39m(\u001b[39m'\u001b[39m\u001b[39mGraph 1:\u001b[39m\u001b[39m'\u001b[39m, graph1)\n",
      "File \u001b[1;32mc:\\tools\\Anaconda3\\envs\\tf2.12\\lib\\site-packages\\tensorflow\\python\\data\\ops\\iterator_ops.py:797\u001b[0m, in \u001b[0;36mOwnedIterator.__next__\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m    795\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39m__next__\u001b[39m(\u001b[39mself\u001b[39m):\n\u001b[0;32m    796\u001b[0m   \u001b[39mtry\u001b[39;00m:\n\u001b[1;32m--> 797\u001b[0m     \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_next_internal()\n\u001b[0;32m    798\u001b[0m   \u001b[39mexcept\u001b[39;00m errors\u001b[39m.\u001b[39mOutOfRangeError:\n\u001b[0;32m    799\u001b[0m     \u001b[39mraise\u001b[39;00m \u001b[39mStopIteration\u001b[39;00m\n",
      "File \u001b[1;32mc:\\tools\\Anaconda3\\envs\\tf2.12\\lib\\site-packages\\tensorflow\\python\\data\\ops\\iterator_ops.py:780\u001b[0m, in \u001b[0;36mOwnedIterator._next_internal\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m    777\u001b[0m \u001b[39m# TODO(b/77291417): This runs in sync mode as iterators use an error status\u001b[39;00m\n\u001b[0;32m    778\u001b[0m \u001b[39m# to communicate that there is no more data to iterate over.\u001b[39;00m\n\u001b[0;32m    779\u001b[0m \u001b[39mwith\u001b[39;00m context\u001b[39m.\u001b[39mexecution_mode(context\u001b[39m.\u001b[39mSYNC):\n\u001b[1;32m--> 780\u001b[0m   ret \u001b[39m=\u001b[39m gen_dataset_ops\u001b[39m.\u001b[39;49miterator_get_next(\n\u001b[0;32m    781\u001b[0m       \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_iterator_resource,\n\u001b[0;32m    782\u001b[0m       output_types\u001b[39m=\u001b[39;49m\u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_flat_output_types,\n\u001b[0;32m    783\u001b[0m       output_shapes\u001b[39m=\u001b[39;49m\u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_flat_output_shapes)\n\u001b[0;32m    785\u001b[0m   \u001b[39mtry\u001b[39;00m:\n\u001b[0;32m    786\u001b[0m     \u001b[39m# Fast path for the case `self._structure` is not a nested structure.\u001b[39;00m\n\u001b[0;32m    787\u001b[0m     \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_element_spec\u001b[39m.\u001b[39m_from_compatible_tensor_list(ret)  \u001b[39m# pylint: disable=protected-access\u001b[39;00m\n",
      "File \u001b[1;32mc:\\tools\\Anaconda3\\envs\\tf2.12\\lib\\site-packages\\tensorflow\\python\\ops\\gen_dataset_ops.py:3043\u001b[0m, in \u001b[0;36miterator_get_next\u001b[1;34m(iterator, output_types, output_shapes, name)\u001b[0m\n\u001b[0;32m   3041\u001b[0m   \u001b[39mreturn\u001b[39;00m _result\n\u001b[0;32m   3042\u001b[0m \u001b[39mexcept\u001b[39;00m _core\u001b[39m.\u001b[39m_NotOkStatusException \u001b[39mas\u001b[39;00m e:\n\u001b[1;32m-> 3043\u001b[0m   _ops\u001b[39m.\u001b[39;49mraise_from_not_ok_status(e, name)\n\u001b[0;32m   3044\u001b[0m \u001b[39mexcept\u001b[39;00m _core\u001b[39m.\u001b[39m_FallbackException:\n\u001b[0;32m   3045\u001b[0m   \u001b[39mpass\u001b[39;00m\n",
      "File \u001b[1;32mc:\\tools\\Anaconda3\\envs\\tf2.12\\lib\\site-packages\\tensorflow\\python\\framework\\ops.py:7262\u001b[0m, in \u001b[0;36mraise_from_not_ok_status\u001b[1;34m(e, name)\u001b[0m\n\u001b[0;32m   7260\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39mraise_from_not_ok_status\u001b[39m(e, name):\n\u001b[0;32m   7261\u001b[0m   e\u001b[39m.\u001b[39mmessage \u001b[39m+\u001b[39m\u001b[39m=\u001b[39m (\u001b[39m\"\u001b[39m\u001b[39m name: \u001b[39m\u001b[39m\"\u001b[39m \u001b[39m+\u001b[39m name \u001b[39mif\u001b[39;00m name \u001b[39mis\u001b[39;00m \u001b[39mnot\u001b[39;00m \u001b[39mNone\u001b[39;00m \u001b[39melse\u001b[39;00m \u001b[39m\"\u001b[39m\u001b[39m\"\u001b[39m)\n\u001b[1;32m-> 7262\u001b[0m   \u001b[39mraise\u001b[39;00m core\u001b[39m.\u001b[39m_status_to_exception(e) \u001b[39mfrom\u001b[39;00m \u001b[39mNone\u001b[39;00m\n",
      "\u001b[1;31mInvalidArgumentError\u001b[0m: {{function_node __wrapped__IteratorGetNext_output_types_7_device_/job:localhost/replica:0/task:0/device:CPU:0}} Cannot batch tensors with different shapes in component 0. First element had shape [2,2] and element 2 had shape [3]. [Op:IteratorGetNext]"
     ]
    }
   ],
   "source": [
    "# Test on dummy data \n",
    "data = [\n",
    "    [[np.array([[0.5645, 0.2412], [0.9563, 0.1425]]), np.array([0.8741, 0.3524, 0.4567]), np.array([[0.6324, 0.8632], [0.7841, 0.5124]])],\n",
    "     [np.array([[0.7234, 0.4234], [0.7432, 0.9876]]), np.array([0.1234, 0.5310, 0.9865]), np.array([[0.6345, 0.2354], [0.7865, 0.5432]])], 0],\n",
    "    [[np.array([[0.4523, 0.9876], [0.2413, 0.1532]]), np.array([0.3423, 0.6543, 0.7654]), np.array([[0.5432, 0.7654], [0.8675, 0.2134]])],\n",
    "     [np.array([[0.1234, 0.9765], [0.7654, 0.2345]]), np.array([0.8765, 0.2345, 0.5432]), np.array([[0.1234, 0.4567], [0.7654, 0.9876]])], 0],\n",
    "    [[np.array([[0.7654, 0.1234], [0.4567, 0.6543]]), np.array([0.9765, 0.1234, 0.8765]), np.array([[0.2345, 0.5678], [0.1234, 0.7654]])],\n",
    "     [np.array([[0.5432, 0.7654], [0.8765, 0.4321]]), np.array([0.1234, 0.5678, 0.4321]), np.array([[0.7654, 0.1234], [0.2345, 0.6543]])], 0],\n",
    "    [[np.array([[0.2345, 0.6789], [0.1234, 0.2345]]), np.array([0.8765, 0.1234, 0.4321]), np.array([[0.5432, 0.2345], [0.7654, 0.1234]])],\n",
    "     [np.array([[0.9876, 0.1234], [0.4321, 0.5678]]), np.array([0.6543, 0.1234, 0.7654]), np.array([[0.8765, 0.2345], [0.1234, 0.4321]])], 0],\n",
    "    [[np.array([0.5432, 0.8765, 0.1234]), np.array([0.7654, 0.2345]), np.array([0.4321, 0.5678, 0.8765])],\n",
    "     [np.array([0.1234, 0.6789]), np.array([0.7654, 0.1234, 0.4567]), np.array([0.2345, 0.5678, 0.1234])], 1]\n",
    "]\n",
    "\n",
    "# Test for generator() and dataset_tf()\n",
    "my_dataset = dataset_tf(data)\n",
    "train_dataset, val_dataset, test_dataset = dataset_prep(my_dataset, val_split=0.1, test_split=0.1, batch_size=32)\n",
    "# Iterate through the dataset\n",
    "for item in train_dataset:\n",
    "    graph1, graph2, label = item\n",
    "    print('Graph 1:', graph1)\n",
    "    print('Graph 2:', graph2)\n",
    "    print('Label:', label.numpy())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Graph 1 Adjaceny matrix: tf.Tensor(\n",
      "[[[ 2.441092    0.6606946  -0.12578358 ...  0.83818007 -1.5898882\n",
      "   -0.8057713 ]\n",
      "  [ 0.6606946   2.441092    1.6717803  ...  0.6053486  -2.1600127\n",
      "   -1.9578215 ]\n",
      "  [-0.12578358  1.6717803   2.441092   ...  0.4384336  -1.4936295\n",
      "   -1.5495999 ]\n",
      "  ...\n",
      "  [ 0.83818007  0.6053486   0.4384336  ...  2.441092   -1.4207016\n",
      "   -1.2727665 ]\n",
      "  [-1.5898882  -2.1600127  -1.4936295  ... -1.4207016   2.441092\n",
      "    1.8921069 ]\n",
      "  [-0.8057713  -1.9578215  -1.5495999  ... -1.2727665   1.8921069\n",
      "    2.441092  ]]\n",
      "\n",
      " [[ 2.441092    0.6606946  -0.12578358 ...  0.83818007 -1.5898882\n",
      "   -0.8057713 ]\n",
      "  [ 0.6606946   2.441092    1.6717803  ...  0.6053486  -2.1600127\n",
      "   -1.9578215 ]\n",
      "  [-0.12578358  1.6717803   2.441092   ...  0.4384336  -1.4936295\n",
      "   -1.5495999 ]\n",
      "  ...\n",
      "  [ 0.83818007  0.6053486   0.4384336  ...  2.441092   -1.4207016\n",
      "   -1.2727665 ]\n",
      "  [-1.5898882  -2.1600127  -1.4936295  ... -1.4207016   2.441092\n",
      "    1.8921069 ]\n",
      "  [-0.8057713  -1.9578215  -1.5495999  ... -1.2727665   1.8921069\n",
      "    2.441092  ]]\n",
      "\n",
      " [[ 2.441092    0.6606946  -0.12578358 ...  0.83818007 -1.5898882\n",
      "   -0.8057713 ]\n",
      "  [ 0.6606946   2.441092    1.6717803  ...  0.6053486  -2.1600127\n",
      "   -1.9578215 ]\n",
      "  [-0.12578358  1.6717803   2.441092   ...  0.4384336  -1.4936295\n",
      "   -1.5495999 ]\n",
      "  ...\n",
      "  [ 0.83818007  0.6053486   0.4384336  ...  2.441092   -1.4207016\n",
      "   -1.2727665 ]\n",
      "  [-1.5898882  -2.1600127  -1.4936295  ... -1.4207016   2.441092\n",
      "    1.8921069 ]\n",
      "  [-0.8057713  -1.9578215  -1.5495999  ... -1.2727665   1.8921069\n",
      "    2.441092  ]]\n",
      "\n",
      " ...\n",
      "\n",
      " [[ 2.441092    0.6606946  -0.12578358 ...  0.83818007 -1.5898882\n",
      "   -0.8057713 ]\n",
      "  [ 0.6606946   2.441092    1.6717803  ...  0.6053486  -2.1600127\n",
      "   -1.9578215 ]\n",
      "  [-0.12578358  1.6717803   2.441092   ...  0.4384336  -1.4936295\n",
      "   -1.5495999 ]\n",
      "  ...\n",
      "  [ 0.83818007  0.6053486   0.4384336  ...  2.441092   -1.4207016\n",
      "   -1.2727665 ]\n",
      "  [-1.5898882  -2.1600127  -1.4936295  ... -1.4207016   2.441092\n",
      "    1.8921069 ]\n",
      "  [-0.8057713  -1.9578215  -1.5495999  ... -1.2727665   1.8921069\n",
      "    2.441092  ]]\n",
      "\n",
      " [[ 2.441092    0.6606946  -0.12578358 ...  0.83818007 -1.5898882\n",
      "   -0.8057713 ]\n",
      "  [ 0.6606946   2.441092    1.6717803  ...  0.6053486  -2.1600127\n",
      "   -1.9578215 ]\n",
      "  [-0.12578358  1.6717803   2.441092   ...  0.4384336  -1.4936295\n",
      "   -1.5495999 ]\n",
      "  ...\n",
      "  [ 0.83818007  0.6053486   0.4384336  ...  2.441092   -1.4207016\n",
      "   -1.2727665 ]\n",
      "  [-1.5898882  -2.1600127  -1.4936295  ... -1.4207016   2.441092\n",
      "    1.8921069 ]\n",
      "  [-0.8057713  -1.9578215  -1.5495999  ... -1.2727665   1.8921069\n",
      "    2.441092  ]]\n",
      "\n",
      " [[ 2.441092    0.6606946  -0.12578358 ...  0.83818007 -1.5898882\n",
      "   -0.8057713 ]\n",
      "  [ 0.6606946   2.441092    1.6717803  ...  0.6053486  -2.1600127\n",
      "   -1.9578215 ]\n",
      "  [-0.12578358  1.6717803   2.441092   ...  0.4384336  -1.4936295\n",
      "   -1.5495999 ]\n",
      "  ...\n",
      "  [ 0.83818007  0.6053486   0.4384336  ...  2.441092   -1.4207016\n",
      "   -1.2727665 ]\n",
      "  [-1.5898882  -2.1600127  -1.4936295  ... -1.4207016   2.441092\n",
      "    1.8921069 ]\n",
      "  [-0.8057713  -1.9578215  -1.5495999  ... -1.2727665   1.8921069\n",
      "    2.441092  ]]], shape=(32, 107, 107), dtype=float32)\n",
      "Graph 1 Node features: tf.Tensor(\n",
      "[[[1.]\n",
      "  [1.]\n",
      "  [1.]\n",
      "  ...\n",
      "  [1.]\n",
      "  [1.]\n",
      "  [1.]]\n",
      "\n",
      " [[1.]\n",
      "  [1.]\n",
      "  [1.]\n",
      "  ...\n",
      "  [1.]\n",
      "  [1.]\n",
      "  [1.]]\n",
      "\n",
      " [[1.]\n",
      "  [1.]\n",
      "  [1.]\n",
      "  ...\n",
      "  [1.]\n",
      "  [1.]\n",
      "  [1.]]\n",
      "\n",
      " ...\n",
      "\n",
      " [[1.]\n",
      "  [1.]\n",
      "  [1.]\n",
      "  ...\n",
      "  [1.]\n",
      "  [1.]\n",
      "  [1.]]\n",
      "\n",
      " [[1.]\n",
      "  [1.]\n",
      "  [1.]\n",
      "  ...\n",
      "  [1.]\n",
      "  [1.]\n",
      "  [1.]]\n",
      "\n",
      " [[1.]\n",
      "  [1.]\n",
      "  [1.]\n",
      "  ...\n",
      "  [1.]\n",
      "  [1.]\n",
      "  [1.]]], shape=(32, 107, 1), dtype=float32)\n",
      "Graph 1 Edge features: tf.Tensor(\n",
      "[[[[1.]\n",
      "   [1.]\n",
      "   [1.]\n",
      "   ...\n",
      "   [1.]\n",
      "   [1.]\n",
      "   [1.]]\n",
      "\n",
      "  [[1.]\n",
      "   [1.]\n",
      "   [1.]\n",
      "   ...\n",
      "   [1.]\n",
      "   [1.]\n",
      "   [1.]]\n",
      "\n",
      "  [[1.]\n",
      "   [1.]\n",
      "   [1.]\n",
      "   ...\n",
      "   [1.]\n",
      "   [1.]\n",
      "   [1.]]\n",
      "\n",
      "  ...\n",
      "\n",
      "  [[1.]\n",
      "   [1.]\n",
      "   [1.]\n",
      "   ...\n",
      "   [1.]\n",
      "   [1.]\n",
      "   [1.]]\n",
      "\n",
      "  [[1.]\n",
      "   [1.]\n",
      "   [1.]\n",
      "   ...\n",
      "   [1.]\n",
      "   [1.]\n",
      "   [1.]]\n",
      "\n",
      "  [[1.]\n",
      "   [1.]\n",
      "   [1.]\n",
      "   ...\n",
      "   [1.]\n",
      "   [1.]\n",
      "   [1.]]]\n",
      "\n",
      "\n",
      " [[[1.]\n",
      "   [1.]\n",
      "   [1.]\n",
      "   ...\n",
      "   [1.]\n",
      "   [1.]\n",
      "   [1.]]\n",
      "\n",
      "  [[1.]\n",
      "   [1.]\n",
      "   [1.]\n",
      "   ...\n",
      "   [1.]\n",
      "   [1.]\n",
      "   [1.]]\n",
      "\n",
      "  [[1.]\n",
      "   [1.]\n",
      "   [1.]\n",
      "   ...\n",
      "   [1.]\n",
      "   [1.]\n",
      "   [1.]]\n",
      "\n",
      "  ...\n",
      "\n",
      "  [[1.]\n",
      "   [1.]\n",
      "   [1.]\n",
      "   ...\n",
      "   [1.]\n",
      "   [1.]\n",
      "   [1.]]\n",
      "\n",
      "  [[1.]\n",
      "   [1.]\n",
      "   [1.]\n",
      "   ...\n",
      "   [1.]\n",
      "   [1.]\n",
      "   [1.]]\n",
      "\n",
      "  [[1.]\n",
      "   [1.]\n",
      "   [1.]\n",
      "   ...\n",
      "   [1.]\n",
      "   [1.]\n",
      "   [1.]]]\n",
      "\n",
      "\n",
      " [[[1.]\n",
      "   [1.]\n",
      "   [1.]\n",
      "   ...\n",
      "   [1.]\n",
      "   [1.]\n",
      "   [1.]]\n",
      "\n",
      "  [[1.]\n",
      "   [1.]\n",
      "   [1.]\n",
      "   ...\n",
      "   [1.]\n",
      "   [1.]\n",
      "   [1.]]\n",
      "\n",
      "  [[1.]\n",
      "   [1.]\n",
      "   [1.]\n",
      "   ...\n",
      "   [1.]\n",
      "   [1.]\n",
      "   [1.]]\n",
      "\n",
      "  ...\n",
      "\n",
      "  [[1.]\n",
      "   [1.]\n",
      "   [1.]\n",
      "   ...\n",
      "   [1.]\n",
      "   [1.]\n",
      "   [1.]]\n",
      "\n",
      "  [[1.]\n",
      "   [1.]\n",
      "   [1.]\n",
      "   ...\n",
      "   [1.]\n",
      "   [1.]\n",
      "   [1.]]\n",
      "\n",
      "  [[1.]\n",
      "   [1.]\n",
      "   [1.]\n",
      "   ...\n",
      "   [1.]\n",
      "   [1.]\n",
      "   [1.]]]\n",
      "\n",
      "\n",
      " ...\n",
      "\n",
      "\n",
      " [[[1.]\n",
      "   [1.]\n",
      "   [1.]\n",
      "   ...\n",
      "   [1.]\n",
      "   [1.]\n",
      "   [1.]]\n",
      "\n",
      "  [[1.]\n",
      "   [1.]\n",
      "   [1.]\n",
      "   ...\n",
      "   [1.]\n",
      "   [1.]\n",
      "   [1.]]\n",
      "\n",
      "  [[1.]\n",
      "   [1.]\n",
      "   [1.]\n",
      "   ...\n",
      "   [1.]\n",
      "   [1.]\n",
      "   [1.]]\n",
      "\n",
      "  ...\n",
      "\n",
      "  [[1.]\n",
      "   [1.]\n",
      "   [1.]\n",
      "   ...\n",
      "   [1.]\n",
      "   [1.]\n",
      "   [1.]]\n",
      "\n",
      "  [[1.]\n",
      "   [1.]\n",
      "   [1.]\n",
      "   ...\n",
      "   [1.]\n",
      "   [1.]\n",
      "   [1.]]\n",
      "\n",
      "  [[1.]\n",
      "   [1.]\n",
      "   [1.]\n",
      "   ...\n",
      "   [1.]\n",
      "   [1.]\n",
      "   [1.]]]\n",
      "\n",
      "\n",
      " [[[1.]\n",
      "   [1.]\n",
      "   [1.]\n",
      "   ...\n",
      "   [1.]\n",
      "   [1.]\n",
      "   [1.]]\n",
      "\n",
      "  [[1.]\n",
      "   [1.]\n",
      "   [1.]\n",
      "   ...\n",
      "   [1.]\n",
      "   [1.]\n",
      "   [1.]]\n",
      "\n",
      "  [[1.]\n",
      "   [1.]\n",
      "   [1.]\n",
      "   ...\n",
      "   [1.]\n",
      "   [1.]\n",
      "   [1.]]\n",
      "\n",
      "  ...\n",
      "\n",
      "  [[1.]\n",
      "   [1.]\n",
      "   [1.]\n",
      "   ...\n",
      "   [1.]\n",
      "   [1.]\n",
      "   [1.]]\n",
      "\n",
      "  [[1.]\n",
      "   [1.]\n",
      "   [1.]\n",
      "   ...\n",
      "   [1.]\n",
      "   [1.]\n",
      "   [1.]]\n",
      "\n",
      "  [[1.]\n",
      "   [1.]\n",
      "   [1.]\n",
      "   ...\n",
      "   [1.]\n",
      "   [1.]\n",
      "   [1.]]]\n",
      "\n",
      "\n",
      " [[[1.]\n",
      "   [1.]\n",
      "   [1.]\n",
      "   ...\n",
      "   [1.]\n",
      "   [1.]\n",
      "   [1.]]\n",
      "\n",
      "  [[1.]\n",
      "   [1.]\n",
      "   [1.]\n",
      "   ...\n",
      "   [1.]\n",
      "   [1.]\n",
      "   [1.]]\n",
      "\n",
      "  [[1.]\n",
      "   [1.]\n",
      "   [1.]\n",
      "   ...\n",
      "   [1.]\n",
      "   [1.]\n",
      "   [1.]]\n",
      "\n",
      "  ...\n",
      "\n",
      "  [[1.]\n",
      "   [1.]\n",
      "   [1.]\n",
      "   ...\n",
      "   [1.]\n",
      "   [1.]\n",
      "   [1.]]\n",
      "\n",
      "  [[1.]\n",
      "   [1.]\n",
      "   [1.]\n",
      "   ...\n",
      "   [1.]\n",
      "   [1.]\n",
      "   [1.]]\n",
      "\n",
      "  [[1.]\n",
      "   [1.]\n",
      "   [1.]\n",
      "   ...\n",
      "   [1.]\n",
      "   [1.]\n",
      "   [1.]]]], shape=(32, 107, 107, 1), dtype=float32)\n",
      "Graph 2 Adjaceny matrix: tf.Tensor(\n",
      "[[[ 1.2405375   0.92151195  1.0446097  ... -1.0492547  -0.12047615\n",
      "    0.77686256]\n",
      "  [ 0.92151195  1.2405375   1.1226877  ... -1.4673939   0.10667869\n",
      "    1.1047704 ]\n",
      "  [ 1.0446097   1.1226877   1.2405375  ... -1.4110452   0.09964043\n",
      "    1.0791329 ]\n",
      "  ...\n",
      "  [-1.0492547  -1.4673939  -1.4110452  ...  1.2405375  -0.19246452\n",
      "   -1.525834  ]\n",
      "  [-0.12047615  0.10667869  0.09964043 ... -0.19246452  1.2405375\n",
      "    0.25144014]\n",
      "  [ 0.77686256  1.1047704   1.0791329  ... -1.525834    0.25144014\n",
      "    1.2405375 ]]\n",
      "\n",
      " [[ 2.4166262   1.4269344  -0.46252173 ... -1.0455447  -0.84167004\n",
      "   -0.41717604]\n",
      "  [ 1.4269344   2.4166262   0.95945764 ... -1.8606728  -1.2645267\n",
      "   -0.49023554]\n",
      "  [-0.46252173  0.95945764  2.4166262  ... -0.77650654 -2.0396848\n",
      "   -2.140198  ]\n",
      "  ...\n",
      "  [-1.0455447  -1.8606728  -0.77650654 ...  2.4166262   0.83017623\n",
      "   -0.41237456]\n",
      "  [-0.84167004 -1.2645267  -2.0396848  ...  0.83017623  2.4166262\n",
      "    1.6419415 ]\n",
      "  [-0.41717604 -0.49023554 -2.140198   ... -0.41237456  1.6419415\n",
      "    2.4166262 ]]\n",
      "\n",
      " [[ 2.557867    1.5211704   1.4064755  ...  0.76525277 -0.1466086\n",
      "    1.06594   ]\n",
      "  [ 1.5211704   2.557867    2.0786157  ...  0.04459901 -0.7260204\n",
      "    0.38188612]\n",
      "  [ 1.4064755   2.0786157   2.557867   ...  0.19945781 -1.3777204\n",
      "   -0.00400845]\n",
      "  ...\n",
      "  [ 0.76525277  0.04459901  0.19945781 ...  2.557867    1.2877423\n",
      "    1.4098086 ]\n",
      "  [-0.1466086  -0.7260204  -1.3777204  ...  1.2877423   2.557867\n",
      "    1.7272127 ]\n",
      "  [ 1.06594     0.38188612 -0.00400845 ...  1.4098086   1.7272127\n",
      "    2.557867  ]]\n",
      "\n",
      " ...\n",
      "\n",
      " [[ 2.1561897  -0.23331429 -0.20276694 ...  1.3602619   0.80022055\n",
      "    0.30351493]\n",
      "  [-0.23331429  2.1561897   1.7912081  ... -0.47045588 -0.6558004\n",
      "   -0.3703464 ]\n",
      "  [-0.20276694  1.7912081   2.1561897  ... -0.17594892 -0.9535265\n",
      "   -1.098698  ]\n",
      "  ...\n",
      "  [ 1.3602619  -0.47045588 -0.17594892 ...  2.1561897   1.1966021\n",
      "   -0.0665543 ]\n",
      "  [ 0.80022055 -0.6558004  -0.9535265  ...  1.1966021   2.1561897\n",
      "    1.3951284 ]\n",
      "  [ 0.30351493 -0.3703464  -1.098698   ... -0.0665543   1.3951284\n",
      "    2.1561897 ]]\n",
      "\n",
      " [[ 2.7640624   2.0100236   2.1775677  ... -1.1233027  -0.19237533\n",
      "    0.4940022 ]\n",
      "  [ 2.0100236   2.7640624   2.0334005  ... -1.2938204  -0.4370861\n",
      "    0.7178787 ]\n",
      "  [ 2.1775677   2.0334005   2.7640624  ... -1.2629893  -0.53158396\n",
      "    0.21314691]\n",
      "  ...\n",
      "  [-1.1233027  -1.2938204  -1.2629893  ...  2.7640624   1.0383688\n",
      "    0.25257415]\n",
      "  [-0.19237533 -0.4370861  -0.53158396 ...  1.0383688   2.7640624\n",
      "    1.7569603 ]\n",
      "  [ 0.4940022   0.7178787   0.21314691 ...  0.25257415  1.7569603\n",
      "    2.7640624 ]]\n",
      "\n",
      " [[ 1.732257    0.22780432  0.4497448  ...  0.23881632  0.28404224\n",
      "   -0.6003333 ]\n",
      "  [ 0.22780432  1.732257    0.72097284 ...  0.50866187  1.0439856\n",
      "    0.7629238 ]\n",
      "  [ 0.4497448   0.72097284  1.732257   ...  0.73190624  1.074438\n",
      "    0.73498255]\n",
      "  ...\n",
      "  [ 0.23881632  0.50866187  0.73190624 ...  1.732257    1.3212838\n",
      "    1.1949568 ]\n",
      "  [ 0.28404224  1.0439856   1.074438   ...  1.3212838   1.732257\n",
      "    1.4312506 ]\n",
      "  [-0.6003333   0.7629238   0.73498255 ...  1.1949568   1.4312506\n",
      "    1.732257  ]]], shape=(32, 107, 107), dtype=float32)\n",
      "Graph 2 Node features: tf.Tensor(\n",
      "[[[1.]\n",
      "  [1.]\n",
      "  [1.]\n",
      "  ...\n",
      "  [1.]\n",
      "  [1.]\n",
      "  [1.]]\n",
      "\n",
      " [[1.]\n",
      "  [1.]\n",
      "  [1.]\n",
      "  ...\n",
      "  [1.]\n",
      "  [1.]\n",
      "  [1.]]\n",
      "\n",
      " [[1.]\n",
      "  [1.]\n",
      "  [1.]\n",
      "  ...\n",
      "  [1.]\n",
      "  [1.]\n",
      "  [1.]]\n",
      "\n",
      " ...\n",
      "\n",
      " [[1.]\n",
      "  [1.]\n",
      "  [1.]\n",
      "  ...\n",
      "  [1.]\n",
      "  [1.]\n",
      "  [1.]]\n",
      "\n",
      " [[1.]\n",
      "  [1.]\n",
      "  [1.]\n",
      "  ...\n",
      "  [1.]\n",
      "  [1.]\n",
      "  [1.]]\n",
      "\n",
      " [[1.]\n",
      "  [1.]\n",
      "  [1.]\n",
      "  ...\n",
      "  [1.]\n",
      "  [1.]\n",
      "  [1.]]], shape=(32, 107, 1), dtype=float32)\n",
      "Graph 2 Edge features: tf.Tensor(\n",
      "[[[[1.]\n",
      "   [1.]\n",
      "   [1.]\n",
      "   ...\n",
      "   [1.]\n",
      "   [1.]\n",
      "   [1.]]\n",
      "\n",
      "  [[1.]\n",
      "   [1.]\n",
      "   [1.]\n",
      "   ...\n",
      "   [1.]\n",
      "   [1.]\n",
      "   [1.]]\n",
      "\n",
      "  [[1.]\n",
      "   [1.]\n",
      "   [1.]\n",
      "   ...\n",
      "   [1.]\n",
      "   [1.]\n",
      "   [1.]]\n",
      "\n",
      "  ...\n",
      "\n",
      "  [[1.]\n",
      "   [1.]\n",
      "   [1.]\n",
      "   ...\n",
      "   [1.]\n",
      "   [1.]\n",
      "   [1.]]\n",
      "\n",
      "  [[1.]\n",
      "   [1.]\n",
      "   [1.]\n",
      "   ...\n",
      "   [1.]\n",
      "   [1.]\n",
      "   [1.]]\n",
      "\n",
      "  [[1.]\n",
      "   [1.]\n",
      "   [1.]\n",
      "   ...\n",
      "   [1.]\n",
      "   [1.]\n",
      "   [1.]]]\n",
      "\n",
      "\n",
      " [[[1.]\n",
      "   [1.]\n",
      "   [1.]\n",
      "   ...\n",
      "   [1.]\n",
      "   [1.]\n",
      "   [1.]]\n",
      "\n",
      "  [[1.]\n",
      "   [1.]\n",
      "   [1.]\n",
      "   ...\n",
      "   [1.]\n",
      "   [1.]\n",
      "   [1.]]\n",
      "\n",
      "  [[1.]\n",
      "   [1.]\n",
      "   [1.]\n",
      "   ...\n",
      "   [1.]\n",
      "   [1.]\n",
      "   [1.]]\n",
      "\n",
      "  ...\n",
      "\n",
      "  [[1.]\n",
      "   [1.]\n",
      "   [1.]\n",
      "   ...\n",
      "   [1.]\n",
      "   [1.]\n",
      "   [1.]]\n",
      "\n",
      "  [[1.]\n",
      "   [1.]\n",
      "   [1.]\n",
      "   ...\n",
      "   [1.]\n",
      "   [1.]\n",
      "   [1.]]\n",
      "\n",
      "  [[1.]\n",
      "   [1.]\n",
      "   [1.]\n",
      "   ...\n",
      "   [1.]\n",
      "   [1.]\n",
      "   [1.]]]\n",
      "\n",
      "\n",
      " [[[1.]\n",
      "   [1.]\n",
      "   [1.]\n",
      "   ...\n",
      "   [1.]\n",
      "   [1.]\n",
      "   [1.]]\n",
      "\n",
      "  [[1.]\n",
      "   [1.]\n",
      "   [1.]\n",
      "   ...\n",
      "   [1.]\n",
      "   [1.]\n",
      "   [1.]]\n",
      "\n",
      "  [[1.]\n",
      "   [1.]\n",
      "   [1.]\n",
      "   ...\n",
      "   [1.]\n",
      "   [1.]\n",
      "   [1.]]\n",
      "\n",
      "  ...\n",
      "\n",
      "  [[1.]\n",
      "   [1.]\n",
      "   [1.]\n",
      "   ...\n",
      "   [1.]\n",
      "   [1.]\n",
      "   [1.]]\n",
      "\n",
      "  [[1.]\n",
      "   [1.]\n",
      "   [1.]\n",
      "   ...\n",
      "   [1.]\n",
      "   [1.]\n",
      "   [1.]]\n",
      "\n",
      "  [[1.]\n",
      "   [1.]\n",
      "   [1.]\n",
      "   ...\n",
      "   [1.]\n",
      "   [1.]\n",
      "   [1.]]]\n",
      "\n",
      "\n",
      " ...\n",
      "\n",
      "\n",
      " [[[1.]\n",
      "   [1.]\n",
      "   [1.]\n",
      "   ...\n",
      "   [1.]\n",
      "   [1.]\n",
      "   [1.]]\n",
      "\n",
      "  [[1.]\n",
      "   [1.]\n",
      "   [1.]\n",
      "   ...\n",
      "   [1.]\n",
      "   [1.]\n",
      "   [1.]]\n",
      "\n",
      "  [[1.]\n",
      "   [1.]\n",
      "   [1.]\n",
      "   ...\n",
      "   [1.]\n",
      "   [1.]\n",
      "   [1.]]\n",
      "\n",
      "  ...\n",
      "\n",
      "  [[1.]\n",
      "   [1.]\n",
      "   [1.]\n",
      "   ...\n",
      "   [1.]\n",
      "   [1.]\n",
      "   [1.]]\n",
      "\n",
      "  [[1.]\n",
      "   [1.]\n",
      "   [1.]\n",
      "   ...\n",
      "   [1.]\n",
      "   [1.]\n",
      "   [1.]]\n",
      "\n",
      "  [[1.]\n",
      "   [1.]\n",
      "   [1.]\n",
      "   ...\n",
      "   [1.]\n",
      "   [1.]\n",
      "   [1.]]]\n",
      "\n",
      "\n",
      " [[[1.]\n",
      "   [1.]\n",
      "   [1.]\n",
      "   ...\n",
      "   [1.]\n",
      "   [1.]\n",
      "   [1.]]\n",
      "\n",
      "  [[1.]\n",
      "   [1.]\n",
      "   [1.]\n",
      "   ...\n",
      "   [1.]\n",
      "   [1.]\n",
      "   [1.]]\n",
      "\n",
      "  [[1.]\n",
      "   [1.]\n",
      "   [1.]\n",
      "   ...\n",
      "   [1.]\n",
      "   [1.]\n",
      "   [1.]]\n",
      "\n",
      "  ...\n",
      "\n",
      "  [[1.]\n",
      "   [1.]\n",
      "   [1.]\n",
      "   ...\n",
      "   [1.]\n",
      "   [1.]\n",
      "   [1.]]\n",
      "\n",
      "  [[1.]\n",
      "   [1.]\n",
      "   [1.]\n",
      "   ...\n",
      "   [1.]\n",
      "   [1.]\n",
      "   [1.]]\n",
      "\n",
      "  [[1.]\n",
      "   [1.]\n",
      "   [1.]\n",
      "   ...\n",
      "   [1.]\n",
      "   [1.]\n",
      "   [1.]]]\n",
      "\n",
      "\n",
      " [[[1.]\n",
      "   [1.]\n",
      "   [1.]\n",
      "   ...\n",
      "   [1.]\n",
      "   [1.]\n",
      "   [1.]]\n",
      "\n",
      "  [[1.]\n",
      "   [1.]\n",
      "   [1.]\n",
      "   ...\n",
      "   [1.]\n",
      "   [1.]\n",
      "   [1.]]\n",
      "\n",
      "  [[1.]\n",
      "   [1.]\n",
      "   [1.]\n",
      "   ...\n",
      "   [1.]\n",
      "   [1.]\n",
      "   [1.]]\n",
      "\n",
      "  ...\n",
      "\n",
      "  [[1.]\n",
      "   [1.]\n",
      "   [1.]\n",
      "   ...\n",
      "   [1.]\n",
      "   [1.]\n",
      "   [1.]]\n",
      "\n",
      "  [[1.]\n",
      "   [1.]\n",
      "   [1.]\n",
      "   ...\n",
      "   [1.]\n",
      "   [1.]\n",
      "   [1.]]\n",
      "\n",
      "  [[1.]\n",
      "   [1.]\n",
      "   [1.]\n",
      "   ...\n",
      "   [1.]\n",
      "   [1.]\n",
      "   [1.]]]], shape=(32, 107, 107, 1), dtype=float32)\n",
      "Label: [0 0 1 0 1 0 0 1 0 0 0 1 0 0 1 0 0 0 0 0 0 0 0 1 0 0 1 0 0 0 0 0]\n"
     ]
    }
   ],
   "source": [
    "# Testing real data\n",
    "pseudodata_path = r\"C:\\Users\\xmoot\\Desktop\\Data\\ssl-seizure-detection\\patient_pseudolabeled\\relative_positioning\\jh101_12s_7min_np_2.pkl\"\n",
    "\n",
    "# # Load data\n",
    "data = pickle.load(open(pseudodata_path, \"rb\"))\n",
    "\n",
    "dataset = dataset_tf(data)\n",
    "\n",
    "dataset = dataset.shuffle(1000).batch(32).prefetch(10)\n",
    "# train_loader, val_loader, test_loader = dataloader_tf(data, batch_size=32, val_size=0.2, test_size=0.1, seed=16)\n",
    "for item in dataset:\n",
    "    graph1, graph2, label = item\n",
    "    print('Graph 1 Adjaceny matrix:', graph1[0])\n",
    "    print('Graph 1 Node features:', graph1[1])\n",
    "    print('Graph 1 Edge features:', graph1[2])\n",
    "    print('Graph 2 Adjaceny matrix:', graph2[0])\n",
    "    print('Graph 2 Node features:', graph2[1])\n",
    "    print('Graph 2 Edge features:', graph2[2])\n",
    "    print('Label:', label.numpy())\n",
    "    break\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Start of train_loader:\n",
      "<_BatchDataset element_spec=((TensorSpec(shape=<unknown>, dtype=tf.float32, name=None), TensorSpec(shape=<unknown>, dtype=tf.float32, name=None), TensorSpec(shape=<unknown>, dtype=tf.float32, name=None)), (TensorSpec(shape=<unknown>, dtype=tf.float32, name=None), TensorSpec(shape=<unknown>, dtype=tf.float32, name=None), TensorSpec(shape=<unknown>, dtype=tf.float32, name=None)), TensorSpec(shape=(None,), dtype=tf.int32, name=None))>\n"
     ]
    },
    {
     "ename": "",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31mCannot execute code, session has been disposed. Please try restarting the Kernel."
     ]
    },
    {
     "ename": "",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31mThe Kernel crashed while executing code in the the current cell or a previous cell. Please review the code in the cell(s) to identify a possible cause of the failure. Click <a href='https://aka.ms/vscodeJupyterKernelCrash'>here</a> for more info. View Jupyter <a href='command:jupyter.viewOutput'>log</a> for further details."
     ]
    }
   ],
   "source": [
    "import os\n",
    "import pickle\n",
    "\n",
    "from tensorflow.keras.optimizers import Adam\n",
    "from model import relative_positioning\n",
    "from dataloader_tf import dataloader_tf, dataset_tf, generator\n",
    "from evaluation import f1_score, training_curves, eval\n",
    "\n",
    "model = relative_positioning(fltrs_out=64, l2_reg=1e-3)\n",
    "    \n",
    "# Optimization algorithm\n",
    "optimizer = Adam(lr=1e-3)\n",
    "\n",
    "# Compile model\n",
    "model.compile(optimizer=optimizer, loss=\"binary_crossentropy\")\n",
    "\n",
    "# Num epochs\n",
    "epochs = 10\n",
    "\n",
    "for epoch in range(epochs):\n",
    "    for batch, (inputs, targets) in enumerate(dataset):\n",
    "        loss_value = model.train_on_batch(inputs, targets)\n",
    "    print(f\"Epoch {epoch+1}/{epochs}\")\n",
    "    print(f\"Loss: {loss_value}\")\n",
    "model.save('testmodel.h5')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "tf2.12",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.10"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
