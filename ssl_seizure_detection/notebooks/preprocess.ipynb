{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Preprocessing Guide\n",
    "This notebooks serves as a guide on converting the initial graph representations created by [DÃ­az-Montiel & Lankarany (2023)](https://www.biorxiv.org/content/10.1101/2023.06.02.543277v1.abstract) from the OpenNeuro ds003029 dataset into a format that can be used by [PyTorch Geometric](https://pytorch-geometric.readthedocs.io/en/latest/). This is fully automated using the `patch` function in `src/patch.py`. The processed data we are using can be found in the Graham cluster directory:\n",
    "\n",
    "`/User/projects/def-milad777/gr_research/brain-greg/data/ds003029-processed/graph_representation_elements`\n",
    "\n",
    "which contains folders for each patient and their runs."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import pickle\n",
    "import numpy as np\n",
    "import sys\n",
    "from ssl_seizure_detection.src.preprocess import new_grs, create_tensordata_new, convert_to_Data, pseudo_data, convert_to_PairData, convert_to_TripletData"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "### Step 1: Extracting Graph Representations\n",
    "For each patient and each run, there are three files: preictal (before seizure), ictal (seizure occurring), and postictal (after seizure). Each file is a list with entries of the form the form `graph = [A, NF, EF]`. Where `A`, `NF`, and `EF` are lists of length 4, 3, and 4 respectively defined below.\n",
    "\n",
    "`A = [A0, A1, A2, A3]`, where :\n",
    "-   `A0` = Ones, shape `(107,107)`.\n",
    "-   `A1` = Correlation, shape `(107,107)`.  \n",
    "-   `A2` = Coherence, shape `(107,107)`.\n",
    "-   `A3` = Phase, shape `(107,107)`.\n",
    "\n",
    "`NF = [NF0, NF1, NF2]`, where:\n",
    "\n",
    "-  `NF0` = Ones, shape `(107,1)`.\n",
    "-  `NF1` = Average Energy, shape `(107,1)`.\n",
    "-  `NF2` = Band Energy, shape `(107,8)`.\n",
    "\n",
    "\n",
    "`EF = [EF0, EF1, EF2, EF3]`, where:\n",
    "\n",
    "-  `EF0` = Ones, shape `(107,107,1)`.\n",
    "-  `EF1` = Correlation, shape `(107,107,1)`.\n",
    "-  `EF2` = Coherence, shape `(107,107,1)`.\n",
    "-  `EF3` = Phase, shape `(107,107,1)`.\n",
    "\n",
    "All the information above has been (experimentally) confirmed by the above and Alan's documentation of `get_nf`, `get_adj`, and `get_ef` helper functions in his `load_data()` function, but should talk to Alan about confirming these details for absolute certainty."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We'll first load the preictal, ictal, and postictal files for a single patient and run. In this case, the patient folder is `jh101` and we are using run $1$."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Mac\n",
    "path_ictal = f\"/Users/xaviermootoo/Documents/Data/ssl-seizure-detection/patient_gr/jh101/ictal_1.pickle\"\n",
    "path_preictal = f\"/Users/xaviermootoo/Documents/Data/ssl-seizure-detection/patient_gr/jh101/preictal_1.pickle\"\n",
    "path_postictal = f\"/Users/xaviermootoo/Documents/Data/ssl-seizure-detection/patient_gr/jh101/postictal_1.pickle\"\n",
    "\n",
    "# PC\n",
    "path_ictal = r\"C:\\Users\\xmoot\\Desktop\\Data\\ssl-seizure-detection\\patient_gr\\jh101\\ictal_1.pickle\"\n",
    "path_preictal = r\"C:\\Users\\xmoot\\Desktop\\Data\\ssl-seizure-detection\\patient_gr\\jh101\\preictal_1.pickle\"\n",
    "path_postictal = r\"C:\\Users\\xmoot\\Desktop\\Data\\ssl-seizure-detection\\patient_gr\\jh101\\postictal_1.pickle\"\n",
    "\n",
    "\n",
    "with open(path_preictal, 'rb') as f:\n",
    "    data_preictal = pickle.load(f)\n",
    "with open(path_ictal, 'rb') as f:\n",
    "    data_ictal = pickle.load(f)\n",
    "with open(path_postictal, 'rb') as f:\n",
    "    data_postictal = pickle.load(f)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Step 2: Selecting Graph Representations\n",
    "For simplicity we're going to select the most extensive graph representation:\n",
    "-  `A` = None\n",
    "-  `NF` = Average Energy and Band Energy, shape `(107,9)`.\n",
    "-  `EF` = Correlation, Coherence, Phase, shape `(107, 107, 3)`.\n",
    "\n",
    "Note that because most PyG layers do not use a separate adjacency matrix with weights, we will not use it, and instead we'll use all the possible edge features. This is facilitated by the `new_grs` functions which gives us the data with a label of `Y = [Y_1, Y_2]` where `Y_1` is the binary label for ictal (1) or nonictal (0), and `Y_2` is the multiclass label for preictal (0), ictal (1), or postictal (2)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Binary Classification"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Select the graph representation for each class\n",
    "new_data_preictal = new_grs(data_preictal, type=\"preictal\")\n",
    "new_data_ictal = new_grs(data_ictal, type=\"ictal\")\n",
    "new_data_postictal = new_grs(data_postictal, type=\"postictal\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "After selecting the GRs for each class, we concatenate them temporally into a single list `[preictal, ictal, postictal]`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "new_data = new_data_preictal + new_data_ictal + new_data_postictal"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of electrodes: 107\n"
     ]
    }
   ],
   "source": [
    "num_electrodes = new_data[0][0][0].shape[0]\n",
    "print(f\"Number of electrodes: {num_electrodes}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Step 3: Standard GRs $\\rightarrow$ PyG GRs\n",
    "The function `create_tensordata_new` converts the pickle file list of standard graph representations, a list with entries of the form $[ [NF, EF] , Y]$, where $NF$ are the node features, $EF$ are the edge features, and $Y$ is the graph label. The function first inserts an `edge_index` for a **complete graph** in the PyG format, which is a tensor of shape `[2, num_edges]` where each column $[i \\ \\ j]^T$ indicates the directed edge $i \\to j$; this is built using the helper function `build_K_n` found in `preprocess.py`. The node features $NF$ are untouched, but converted to float32 a tensor, notated by `x` in PyG. The edge features are converted to `edge_attr` which is a float32 tensor of shape `[num_edges, num_edge_features]` which follows the `edge_index` accordingly, i.e. the 4th column in `edge_index` (4th edge) will correspond to the edge feature `edge_attr[3,:]`, and so on. The label $Y$ is converted to a long torch tensor. The output is a list with entries of the form `[[edge_index, x, edge_attr], y]`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "pyg_grs = create_tensordata_new(num_nodes=num_electrodes, data_list=new_data, complete=True, save=False, logdir=None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1113\n",
      "<class 'torch.Tensor'>\n",
      "Edge features shape: torch.Size([11342, 3])\n",
      "Edge features stored in edge_attr: tensor([[ 0.4213,  0.3902,  0.2319],\n",
      "        [ 0.4969,  0.4126, -0.1610],\n",
      "        [ 0.4405,  0.3708,  0.7440],\n",
      "        ...,\n",
      "        [ 0.8595,  0.2592, -0.5651],\n",
      "        [ 0.7164,  0.2137, -0.8699],\n",
      "        [ 0.8794,  0.2266, -0.6079]])\n"
     ]
    }
   ],
   "source": [
    "# Look inside of pyg_grs\n",
    "print(len(pyg_grs))\n",
    "print(type(pyg_grs[0][0][0]))\n",
    "print(\"Edge features shape:\", pyg_grs[0][0][2].shape)\n",
    "print(\"Edge features stored in edge_attr:\", pyg_grs[0][0][2])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Step 4: PyG GRs $\\rightarrow$ PyG Data\n",
    "<u>**Stop after this step**</u> if you only need PyG Data for <u>**supervised learning**</u>. \n",
    "\n",
    "Here we take the PyG graph representations, and apply the `convert_to_Data` function to create a new list where each entry is now a `torch_geometric.data.Data` object. This is the main object uses to hold graphs in PyG, so we need to use it, especially for batching (for more details see my tutorial `tutorial.ipynb`, or click [here](https://pytorch-geometric.readthedocs.io/en/latest/get_started/introduction.html) for the official tutorial from PyG)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Convert the PyG GRs to the PyG Data format\n",
    "pyg_Data_path = r\"C:\\Users\\xmoot\\Desktop\\Data\\ssl-seizure-detection\\patient_gr\\jh101_pyg_Data.pt\"\n",
    "Data_list = convert_to_Data(pyg_grs, save=True, logdir=pyg_Data_path)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Step 5: Relative Positioning\n",
    "In this step we take the output of Step 3 (`pyg_grs`) and create the pseudolabeled dataset of graph pairs for the relative positioning self-supervised method.  Given our list `pyg_grs` and hyperparameters $\\tau_+$ and $\\tau_-$. The function `pseudo_data` below returns a list of graph pairs where each entry is of the form `[[edge_index1, x1, edge_attr1], [edge_index2, x2, edge_attr2], y]`, where `y` is a pseudolabel (not the old label). Since the total size of the pseudolabeled dataset can be quite large, we use the `sample_ratio` argument to randomly sample a certain portion of it (e.g., `sample_ratio = 0.2` will give us 20% of the total pseudolabeled dataset). Also note that the function will return an equal number of positive and negative samples, as `pseudo_data` automatically balances out the correspondingly classes."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of examples: 21250\n",
      "y\n",
      "0    10625\n",
      "1    10625\n",
      "Name: count, dtype: int64\n"
     ]
    }
   ],
   "source": [
    "pdata = pseudo_data(pyg_grs, tau_pos=12 // 0.12, tau_neg=60 // 0.12, stats=True, save=False, patientid=\"\", \n",
    "                            logdir=None, model=\"relative_positioning\", sample_ratio=0.10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "21250\n",
      "Edge features shape: torch.Size([11342, 3])\n",
      "Edge features stored in edge_attr: tensor([[ 0.1689,  0.2751,  0.3535],\n",
      "        [ 0.7258,  0.2714,  0.5142],\n",
      "        [ 0.4268,  0.3288,  0.0477],\n",
      "        ...,\n",
      "        [ 0.2697,  0.2210,  0.7101],\n",
      "        [ 0.4200,  0.2228, -0.2204],\n",
      "        [ 0.5756,  0.2243, -0.2721]])\n"
     ]
    }
   ],
   "source": [
    "# Look inside of pdata\n",
    "print(len(pdata))\n",
    "example = pdata[0]\n",
    "graph1, graph2, label = example\n",
    "edge_index1, x1, edge_attr1 = graph1\n",
    "edge_index2, x2, edge_attr2 = graph2\n",
    "print(\"Edge features shape:\", edge_attr1.shape)\n",
    "print(\"Edge features stored in edge_attr:\", edge_attr1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now instead of converting each graph pair to `torch_geometric.data.Data` object, we instead create a new class called `PairData` that inherits from the `torch_geometric.data.Data` class, allowing us to batch *pairs* of graphs. We use the `convert_to_PairData` function to convert the list of graph pairs to a list of `PairData` objects (see [here](https://pytorch-geometric.readthedocs.io/en/latest/advanced/batching.html) for more details)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "Pair_Data = convert_to_PairData(pdata, save=False, logdir=None)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Step 6: Temporal Shuffling\n",
    "This step is nearly identical to Step 5, we take the `pyg_grs` and use them to create a pseudolabeled dataset for the temporal shuffling self-supervised method. However, in this method we generate *graph triplets* of the form `[[edge_index1, x1, edge_attr1], [edge_index2, x2, edge_attr2], [edge_index3, x3, edge_attr3], y]` where `y` is the pseudolabel. The size of the pseudolabeled dataset for temporal shuffling can be extremely large, therefore it is <u>**strongly encouraged**</u> to use the `sample_ratio` argument to scale down the dataset."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "pdata = pseudo_data(pyg_grs, tau_pos=12 // 0.12, tau_neg=60 // 0.12, stats=True, save=False, patientid=\"patient\", logdir=None, \n",
    "                    model=\"temporal_shuffling\", sample_ratio=0.3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[ 0.1689,  0.2751,  0.3535],\n",
      "        [ 0.7258,  0.2714,  0.5142],\n",
      "        [ 0.4268,  0.3288,  0.0477],\n",
      "        ...,\n",
      "        [ 0.2697,  0.2210,  0.7101],\n",
      "        [ 0.4200,  0.2228, -0.2204],\n",
      "        [ 0.5756,  0.2243, -0.2721]])\n"
     ]
    }
   ],
   "source": [
    "print(pdata[0][0][2])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Similar to Step 5, we create a new class called `TripletData` that inherits from the `torch_geometric.data.Data` class for batching graph triplets in PyG."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Triplet_Data = convert_to_TripletData(pdata, save=False, logdir=None)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Step 7: Automatic Conversion\n",
    "The `patch` function in `patch.py` does all of the above, converting the original preictal, ictal, and postictal files from a single patient run. Please see documentation in `patch.py`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "import torch\n",
    "from ssl_seizure_detection.src.patch import single_patient_patcher\n",
    "\n",
    "# PC\n",
    "patient_dir = r\"C:\\Users\\xmoot\\Desktop\\Data\\ssl-seizure-detection\\patient_gr\"\n",
    "patient = \"jh101\"\n",
    "logdir = r\"C:\\Users\\xmoot\\Desktop\\Data\\ssl-seizure-detection\\patient_pyg\"\n",
    "\n",
    "# Patch the data\n",
    "data = single_patient_patcher(user=\"xmootoo\", patient_dir=patient_dir, patient=patient, logdir=logdir, model=\"VICRegT1\", stats=True, save=True,\n",
    "                              sigma=5, tau=0.68)\n",
    "\n",
    "jh101_data = torch.load(r\"C:\\Users\\xmoot\\Desktop\\Data\\ssl-seizure-detection\\patient_pyg\\jh101\\VICRegT1\\jh101_combined.pt\")\n",
    "\n",
    "print(len(jh101_data))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.13"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
