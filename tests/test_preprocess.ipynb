{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Intel MKL WARNING: Support of Intel(R) Streaming SIMD Extensions 4.2 (Intel(R) SSE4.2) enabled only processors has been deprecated. Intel oneAPI Math Kernel Library 2025.0 will require Intel(R) Advanced Vector Extensions (Intel(R) AVX) instructions.\n",
      "Intel MKL WARNING: Support of Intel(R) Streaming SIMD Extensions 4.2 (Intel(R) SSE4.2) enabled only processors has been deprecated. Intel oneAPI Math Kernel Library 2025.0 will require Intel(R) Advanced Vector Extensions (Intel(R) AVX) instructions.\n"
     ]
    }
   ],
   "source": [
    "import sys\n",
    "import os\n",
    "sys.path.append(\"../src\")\n",
    "\n",
    "\n",
    "import numpy as np\n",
    "import torch\n",
    "# OR to import specific functions:\n",
    "from preprocess import graph_pairs, graph_triplets, pseudo_data, convert_to_TripletData, ef_to_edge_attr, adj_to_edge_attr, create_tensordata_new, build_K_n\n",
    "from torch_geometric.data import Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of samples: 570050\n",
      "Graph 1: [3324]\n",
      "Graph 2: [3372]\n",
      "Pseudo Label: 1\n",
      "\n",
      "Graph 1: [542]\n",
      "Graph 2: [593]\n",
      "Pseudo Label: 1\n",
      "\n",
      "Graph 1: [2737]\n",
      "Graph 2: [2780]\n",
      "Pseudo Label: 1\n",
      "\n",
      "Graph 1: [2286]\n",
      "Graph 2: [3890]\n",
      "Pseudo Label: 0\n",
      "\n",
      "Graph 1: [1329]\n",
      "Graph 2: [1379]\n",
      "Pseudo Label: 1\n",
      "\n",
      "Graph 1: [1356]\n",
      "Graph 2: [3313]\n",
      "Pseudo Label: 0\n",
      "\n",
      "Graph 1: [3297]\n",
      "Graph 2: [4197]\n",
      "Pseudo Label: 0\n",
      "\n",
      "Graph 1: [334]\n",
      "Graph 2: [2599]\n",
      "Pseudo Label: 0\n",
      "\n",
      "Graph 1: [2643]\n",
      "Graph 2: [3706]\n",
      "Pseudo Label: 0\n",
      "\n",
      "Graph 1: [2939]\n",
      "Graph 2: [4065]\n",
      "Pseudo Label: 0\n",
      "\n"
     ]
    }
   ],
   "source": [
    "def test_graph_pairs():\n",
    "    # Create a synthetic dataset with 10 graph representations\n",
    "    # Note that the graph representations won't be in this format, but it doesn't matter as it only needs to work for general lists with entries [a,b,c,d].\n",
    "    n = 4500\n",
    "    data = [[[i], np.random.randint(2)] for i in range(n)]\n",
    "    \n",
    "    # Call the function with the synthetic dataset\n",
    "    sample_ratio = 0.8\n",
    "    result = graph_pairs(data, tau_pos=12//0.12, tau_neg=90//0.12, sample_ratio=sample_ratio)\n",
    "    \n",
    "    print(f\"Number of samples: {len(result)}\")\n",
    "\n",
    "    # Print the result to see what the function returns\n",
    "    k = 0\n",
    "    for pair in result:\n",
    "        print(f\"Graph 1: {pair[0]}\")\n",
    "        print(f\"Graph 2: {pair[1]}\")\n",
    "        print(f\"Pseudo Label: {pair[2]}\\n\")\n",
    "        k+=1\n",
    "        if k==10:\n",
    "            break\n",
    "\n",
    "test_graph_pairs()\n",
    "\n",
    "\n",
    "# 4500 with sample_ratio = 0.8 yields 570,000 (28s)\n",
    "# 2500 with sample_ratio = 0.7 yields 240,000\n",
    "# 2500 with sample_ratio = 0.8 yields 310,000\n",
    "# 2200 with sample_ratio = 0.7 yields 210,000\n",
    "# 2200 with sample_ratio = 0.8 yields 270,000\n",
    "# 1500 with sample_ratio = 0.7 yields 185,000"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of samples: 147634\n",
      "Graph 1: [173]\n",
      "Graph 2: [1129]\n",
      "Graph 3: [198]\n",
      "Pseudo Label: 0\n",
      "\n",
      "Graph 1: [1300]\n",
      "Graph 2: [117]\n",
      "Graph 3: [1366]\n",
      "Pseudo Label: 0\n",
      "\n",
      "Graph 1: [567]\n",
      "Graph 2: [581]\n",
      "Graph 3: [618]\n",
      "Pseudo Label: 1\n",
      "\n",
      "Graph 1: [850]\n",
      "Graph 2: [853]\n",
      "Graph 3: [890]\n",
      "Pseudo Label: 1\n",
      "\n",
      "Graph 1: [707]\n",
      "Graph 2: [758]\n",
      "Graph 3: [759]\n",
      "Pseudo Label: 1\n",
      "\n",
      "Graph 1: [383]\n",
      "Graph 2: [1186]\n",
      "Graph 3: [393]\n",
      "Pseudo Label: 0\n",
      "\n",
      "Graph 1: [1137]\n",
      "Graph 2: [1159]\n",
      "Graph 3: [1222]\n",
      "Pseudo Label: 1\n",
      "\n",
      "Graph 1: [887]\n",
      "Graph 2: [173]\n",
      "Graph 3: [940]\n",
      "Pseudo Label: 0\n",
      "\n",
      "Graph 1: [475]\n",
      "Graph 2: [1222]\n",
      "Graph 3: [509]\n",
      "Pseudo Label: 0\n",
      "\n",
      "Graph 1: [571]\n",
      "Graph 2: [1047]\n",
      "Graph 3: [669]\n",
      "Pseudo Label: 0\n",
      "\n"
     ]
    }
   ],
   "source": [
    "def test_graph_triplets():\n",
    "    # Create a synthetic dataset with 10 graph representations\n",
    "    # Note that the graph representations won't be in this format, but it doesn't matter as it only needs to work for general lists with entries [a,b,c,d].\n",
    "    n = 1500\n",
    "    data = [[[i], np.random.randint(2)] for i in range(n)]\n",
    "    \n",
    "    # Call the function with the synthetic dataset\n",
    "    sample_ratio = 0.22\n",
    "    result = graph_triplets_new(data, tau_pos=12//0.12, tau_neg=90//0.12, sample_ratio=sample_ratio)\n",
    "    \n",
    "    print(f\"Number of samples: {len(result)}\")\n",
    "\n",
    "    # Print the result to see what the function returns\n",
    "    k = 0\n",
    "    for triplet in result:\n",
    "        print(f\"Graph 1: {triplet[0]}\")\n",
    "        print(f\"Graph 2: {triplet[1]}\")\n",
    "        print(f\"Graph 3: {triplet[2]}\")\n",
    "        print(f\"Pseudo Label: {triplet[3]}\\n\")\n",
    "        k+=1\n",
    "        if k==10:\n",
    "            break\n",
    "\n",
    "test_graph_triplets()\n",
    "\n",
    "# 2200 with sample_ratio = 0.3 yields 635,662 samples\n",
    "# 2200 with sample_ratio = 0.22 yields 222,000 samples\n",
    "# 1500 with sample_ratio = 0.22 yields 150,000 samples"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of examples: 6\n",
      "y\n",
      "1    3\n",
      "0    3\n",
      "Name: count, dtype: int64\n",
      "[[['gr2', 'gr2', 'gr2'], ['gr3', 'gr3', 'gr3'], 1], [['gr2', 'gr2', 'gr2'], ['gr4', 'gr4', 'gr4'], 1], [['gr1', 'gr1', 'gr1'], ['gr5', 'gr5', 'gr5'], 0], [['gr2', 'gr2', 'gr2'], ['gr6', 'gr6', 'gr6'], 0], [['gr1', 'gr1', 'gr1'], ['gr6', 'gr6', 'gr6'], 0], [['gr4', 'gr4', 'gr4'], ['gr6', 'gr6', 'gr6'], 1]]\n",
      "Number of examples: 38\n",
      "y\n",
      "1    19\n",
      "0    19\n",
      "Name: count, dtype: int64\n",
      "[[['gr3', 'gr3', 'gr3'], ['gr5', 'gr5', 'gr5'], ['gr6', 'gr6', 'gr6'], 1], [['gr3', 'gr3', 'gr3'], ['gr5', 'gr5', 'gr5'], ['gr4', 'gr4', 'gr4'], 0], [['gr2', 'gr2', 'gr2'], ['gr3', 'gr3', 'gr3'], ['gr5', 'gr5', 'gr5'], 1], [['gr1', 'gr1', 'gr1'], ['gr6', 'gr6', 'gr6'], ['gr5', 'gr5', 'gr5'], 0], [['gr1', 'gr1', 'gr1'], ['gr5', 'gr5', 'gr5'], ['gr4', 'gr4', 'gr4'], 0], [['gr1', 'gr1', 'gr1'], ['gr2', 'gr2', 'gr2'], ['gr4', 'gr4', 'gr4'], 1], [['gr1', 'gr1', 'gr1'], ['gr3', 'gr3', 'gr3'], ['gr5', 'gr5', 'gr5'], 1], [['gr3', 'gr3', 'gr3'], ['gr6', 'gr6', 'gr6'], ['gr4', 'gr4', 'gr4'], 0], [['gr2', 'gr2', 'gr2'], ['gr5', 'gr5', 'gr5'], ['gr6', 'gr6', 'gr6'], 1], [['gr4', 'gr4', 'gr4'], ['gr5', 'gr5', 'gr5'], ['gr6', 'gr6', 'gr6'], 1], [['gr2', 'gr2', 'gr2'], ['gr6', 'gr6', 'gr6'], ['gr5', 'gr5', 'gr5'], 0], [['gr1', 'gr1', 'gr1'], ['gr2', 'gr2', 'gr2'], ['gr5', 'gr5', 'gr5'], 1], [['gr3', 'gr3', 'gr3'], ['gr4', 'gr4', 'gr4'], ['gr6', 'gr6', 'gr6'], 1], [['gr2', 'gr2', 'gr2'], ['gr4', 'gr4', 'gr4'], ['gr5', 'gr5', 'gr5'], 1], [['gr2', 'gr2', 'gr2'], ['gr3', 'gr3', 'gr3'], ['gr4', 'gr4', 'gr4'], 1], [['gr1', 'gr1', 'gr1'], ['gr4', 'gr4', 'gr4'], ['gr5', 'gr5', 'gr5'], 1], [['gr1', 'gr1', 'gr1'], ['gr6', 'gr6', 'gr6'], ['gr2', 'gr2', 'gr2'], 0], [['gr3', 'gr3', 'gr3'], ['gr6', 'gr6', 'gr6'], ['gr5', 'gr5', 'gr5'], 0], [['gr1', 'gr1', 'gr1'], ['gr4', 'gr4', 'gr4'], ['gr6', 'gr6', 'gr6'], 1], [['gr2', 'gr2', 'gr2'], ['gr3', 'gr3', 'gr3'], ['gr6', 'gr6', 'gr6'], 1], [['gr4', 'gr4', 'gr4'], ['gr6', 'gr6', 'gr6'], ['gr5', 'gr5', 'gr5'], 0], [['gr1', 'gr1', 'gr1'], ['gr6', 'gr6', 'gr6'], ['gr3', 'gr3', 'gr3'], 0], [['gr1', 'gr1', 'gr1'], ['gr2', 'gr2', 'gr2'], ['gr6', 'gr6', 'gr6'], 1], [['gr2', 'gr2', 'gr2'], ['gr6', 'gr6', 'gr6'], ['gr4', 'gr4', 'gr4'], 0], [['gr1', 'gr1', 'gr1'], ['gr5', 'gr5', 'gr5'], ['gr3', 'gr3', 'gr3'], 0], [['gr1', 'gr1', 'gr1'], ['gr3', 'gr3', 'gr3'], ['gr6', 'gr6', 'gr6'], 1], [['gr2', 'gr2', 'gr2'], ['gr6', 'gr6', 'gr6'], ['gr3', 'gr3', 'gr3'], 0], [['gr2', 'gr2', 'gr2'], ['gr4', 'gr4', 'gr4'], ['gr3', 'gr3', 'gr3'], 0], [['gr2', 'gr2', 'gr2'], ['gr5', 'gr5', 'gr5'], ['gr4', 'gr4', 'gr4'], 0], [['gr1', 'gr1', 'gr1'], ['gr5', 'gr5', 'gr5'], ['gr6', 'gr6', 'gr6'], 1], [['gr2', 'gr2', 'gr2'], ['gr4', 'gr4', 'gr4'], ['gr6', 'gr6', 'gr6'], 1], [['gr1', 'gr1', 'gr1'], ['gr3', 'gr3', 'gr3'], ['gr4', 'gr4', 'gr4'], 1], [['gr1', 'gr1', 'gr1'], ['gr5', 'gr5', 'gr5'], ['gr2', 'gr2', 'gr2'], 0], [['gr1', 'gr1', 'gr1'], ['gr6', 'gr6', 'gr6'], ['gr4', 'gr4', 'gr4'], 0], [['gr3', 'gr3', 'gr3'], ['gr4', 'gr4', 'gr4'], ['gr5', 'gr5', 'gr5'], 1], [['gr2', 'gr2', 'gr2'], ['gr5', 'gr5', 'gr5'], ['gr3', 'gr3', 'gr3'], 0], [['gr1', 'gr1', 'gr1'], ['gr4', 'gr4', 'gr4'], ['gr2', 'gr2', 'gr2'], 0], [['gr5', 'gr5', 'gr5'], ['gr4', 'gr4', 'gr4'], ['gr6', 'gr6', 'gr6'], 0]]\n",
      "Tests completed\n"
     ]
    }
   ],
   "source": [
    "def test_pseudo_data():\n",
    "    # Step 1: Create a sample data list\n",
    "    data = [\n",
    "        [[\"gr1\", \"gr1\", \"gr1\"], np.random.randint(2)],\n",
    "        [[\"gr2\", \"gr2\", \"gr2\"], np.random.randint(2)],\n",
    "        [[\"gr3\", \"gr3\", \"gr3\"], np.random.randint(2)],\n",
    "        [[\"gr4\", \"gr4\", \"gr4\"], np.random.randint(2)],\n",
    "        [[\"gr5\", \"gr5\", \"gr5\"], np.random.randint(2)],\n",
    "        [[\"gr6\", \"gr6\", \"gr6\"], np.random.randint(2)]\n",
    "        ]\n",
    "    \n",
    "    # Step 2: Test the function with various inputs\n",
    "    # Test with default parameters\n",
    "    try:\n",
    "        pairs = pseudo_data(data, tau_pos = 2, tau_neg = 3, stats = True, save = False, patientid = \"patient\", logdir = None, model = \"relative_positioning\")\n",
    "        assert isinstance(pairs, list), \"Output is not a list\"\n",
    "        \n",
    "        # Check the length of the output\n",
    "        assert len(pairs) > 0, \"Output list is empty\"\n",
    "        \n",
    "        # Check the structure of the first element in the output\n",
    "        assert len(pairs[0]) == 3, \"Output elements do not have the correct structure\"\n",
    "        print(pairs)\n",
    "\n",
    "    except Exception as e:\n",
    "        print(f\"Test with default parameters failed with error: {e}\")\n",
    "    \n",
    "    \n",
    "    # Test with a different model\n",
    "    try:\n",
    "        triplets = pseudo_data(data, tau_pos = 2, tau_neg = 4, stats = True, save = False, patientid = \"patient\", logdir = None, model = \"temporal_shuffling\")\n",
    "        assert isinstance(triplets, list), \"Output is not a list\"\n",
    "        \n",
    "        # Check the length of the output\n",
    "        assert len(triplets) > 0, \"Output list is empty\"\n",
    "        \n",
    "        # Check the structure of the first element in the output\n",
    "        assert len(triplets[0]) == 4, \"Output elements do not have the correct structure\"\n",
    "        print(triplets)\n",
    "        \n",
    "    except Exception as e:\n",
    "        print(f\"Test with temporal shuffling failed with error: {e}\")\n",
    "\n",
    "    \n",
    "    print(\"Tests completed\")\n",
    "\n",
    "test_pseudo_data()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[0.1727, 0.3077, 0.0150],\n",
      "        [0.5427, 0.1907, 0.3594],\n",
      "        [0.0342, 0.7222, 0.2739]])\n",
      "tensor([[0.1727, 0.3077, 0.0150],\n",
      "        [0.5427, 0.1907, 0.3594],\n",
      "        [0.0342, 0.7222, 0.2739]])\n",
      "tensor([[2, 0],\n",
      "        [1, 2]])\n",
      "tensor([[2, 0],\n",
      "        [1, 2]])\n",
      "tensor([1])\n",
      "tensor([1])\n",
      "Test passed\n"
     ]
    }
   ],
   "source": [
    "class TripletData(Data):\n",
    "    \"\"\"\n",
    "    Creates the torch_geometric data object for a triplets of graphs.\n",
    "    \n",
    "    \"\"\"\n",
    "    def __inc__(self, key, value, *args, **kwargs):\n",
    "        if key == 'edge_index1':\n",
    "            return self.x1.size(0)\n",
    "        if key == 'edge_index2':\n",
    "            return self.x2.size(0)\n",
    "        if key == 'edge_index3':\n",
    "            return self.x3.size(0)\n",
    "        return super().__inc__(key, value, *args, **kwargs)\n",
    "\n",
    "\n",
    "\n",
    "def test_convert_to_TripletData():\n",
    "    # Step 1: Create a sample data list\n",
    "    data_list = [\n",
    "        [\n",
    "            [torch.tensor([[0, 1], [1, 2]]), torch.rand((3, 3)), torch.rand((2, 3))],\n",
    "            [torch.tensor([[1, 0], [2, 1]]), torch.rand((3, 3)), torch.rand((2, 3))],\n",
    "            [torch.tensor([[2, 0], [1, 2]]), torch.rand((3, 3)), torch.rand((2, 3))],\n",
    "            torch.tensor([1])\n",
    "        ] \n",
    "        for _ in range(3)\n",
    "    ]\n",
    "    \n",
    "    # Step 2: Call the function with the sample data\n",
    "    output = convert_to_TripletData(data_list, save=False)\n",
    "    \n",
    "    \n",
    "    if torch.equal(output[0].x1,data_list[0][0][1]) and torch.equal(output[2].edge_index3, data_list[2][2][0]) and torch.equal(output[0].y, data_list[0][3]):\n",
    "        print(output[0].x1)\n",
    "        print(data_list[0][0][1])\n",
    "        print(data_list[2][2][0]) \n",
    "        print(output[2].edge_index3)\n",
    "        print(output[0].y)\n",
    "        print(data_list[0][3])\n",
    "        print(\"Test passed\")\n",
    "\n",
    "test_convert_to_TripletData()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test passed\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "\n",
    "def test_ef_to_edge_attr():\n",
    "    # Define a 3-node complete graph with edge features\n",
    "    edge_index = np.array([\n",
    "        [0, 1, 2, 0, 2, 1],\n",
    "        [1, 0, 0, 2, 1, 2]\n",
    "    ])\n",
    "\n",
    "    # Define edge features for 3 nodes (3 x 3 x 2 matrix)\n",
    "    ef = np.array([\n",
    "        [[0.1, 0.2], [0.3, 0.4], [0.5, 0.6]],\n",
    "        [[0.3, 0.4], [0.1, 0.2], [0.7, 0.8]],\n",
    "        [[0.5, 0.6], [0.7, 0.8], [0.1, 0.2]]\n",
    "    ])\n",
    "\n",
    "    # Expected output (6 edges x 2 features)\n",
    "    expected_edge_attr = np.array([\n",
    "        [0.3, 0.4],\n",
    "        [0.3, 0.4],\n",
    "        [0.5, 0.6],\n",
    "        [0.5, 0.6],\n",
    "        [0.7, 0.8],\n",
    "        [0.7, 0.8]\n",
    "    ])\n",
    "\n",
    "    if np.array_equal(ef_to_edge_attr(edge_index, ef), expected_edge_attr):\n",
    "        print(\"Test passed\")\n",
    "\n",
    "\n",
    "test_ef_to_edge_attr()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[[tensor([[0, 0, 0, 1, 1, 1, 2, 2, 2, 3, 3, 3],\n",
      "        [1, 2, 3, 0, 2, 3, 0, 1, 3, 0, 1, 2]]), tensor([[0.7062, 0.2018, 0.4384],\n",
      "        [0.0263, 0.8856, 0.5984],\n",
      "        [0.8255, 0.7409, 0.5824],\n",
      "        [0.6624, 0.1274, 0.6451]]), tensor([[0.6877, 0.3812],\n",
      "        [0.5184, 0.4200],\n",
      "        [0.7134, 0.6546],\n",
      "        [0.6486, 0.3674],\n",
      "        [0.7353, 0.3583],\n",
      "        [0.9322, 0.8115],\n",
      "        [0.7168, 0.4183],\n",
      "        [0.8734, 0.8871],\n",
      "        [0.4216, 0.0684],\n",
      "        [0.3000, 0.1026],\n",
      "        [0.8075, 0.5920],\n",
      "        [0.9838, 0.5842]])], tensor(0)], [[tensor([[0, 0, 0, 1, 1, 1, 2, 2, 2, 3, 3, 3],\n",
      "        [1, 2, 3, 0, 2, 3, 0, 1, 3, 0, 1, 2]]), tensor([[0.5896, 0.6931, 0.1396],\n",
      "        [0.6675, 0.2411, 0.4332],\n",
      "        [0.3772, 0.8732, 0.8673],\n",
      "        [0.6981, 0.6055, 0.0320]]), tensor([[0.9834, 0.0980],\n",
      "        [0.4269, 0.3192],\n",
      "        [0.3849, 0.5704],\n",
      "        [0.9851, 0.7094],\n",
      "        [0.4818, 0.4551],\n",
      "        [0.7171, 0.1559],\n",
      "        [0.3757, 0.6507],\n",
      "        [0.8028, 0.8147],\n",
      "        [0.9914, 0.3664],\n",
      "        [0.8068, 0.4864],\n",
      "        [0.8646, 0.9566],\n",
      "        [0.1226, 0.0357]])], tensor(0)], [[tensor([[0, 0, 0, 1, 1, 1, 2, 2, 2, 3, 3, 3],\n",
      "        [1, 2, 3, 0, 2, 3, 0, 1, 3, 0, 1, 2]]), tensor([[0.3653, 0.2938, 0.9952],\n",
      "        [0.3364, 0.2428, 0.7883],\n",
      "        [0.3423, 0.7834, 0.4113],\n",
      "        [0.9533, 0.0453, 0.7874]]), tensor([[0.6333, 0.6849],\n",
      "        [0.1623, 0.6570],\n",
      "        [0.3034, 0.7948],\n",
      "        [0.1365, 0.6208],\n",
      "        [0.9086, 0.6600],\n",
      "        [0.2265, 0.8199],\n",
      "        [0.4620, 0.4410],\n",
      "        [0.4361, 0.4588],\n",
      "        [0.6296, 0.8403],\n",
      "        [0.0745, 0.4804],\n",
      "        [0.4504, 0.7994],\n",
      "        [0.9017, 0.0787]])], tensor(1)], [[tensor([[0, 0, 0, 1, 1, 1, 2, 2, 2, 3, 3, 3],\n",
      "        [1, 2, 3, 0, 2, 3, 0, 1, 3, 0, 1, 2]]), tensor([[0.0784, 0.7824, 0.3738],\n",
      "        [0.6806, 0.2604, 0.0653],\n",
      "        [0.9652, 0.1974, 0.6822],\n",
      "        [0.6897, 0.2338, 0.0273]]), tensor([[0.8377, 0.3283],\n",
      "        [0.7287, 0.2609],\n",
      "        [0.1107, 0.1444],\n",
      "        [0.3287, 0.3340],\n",
      "        [0.1103, 0.4075],\n",
      "        [0.0884, 0.0748],\n",
      "        [0.4834, 0.7599],\n",
      "        [0.6744, 0.7422],\n",
      "        [0.2308, 0.7345],\n",
      "        [0.1127, 0.0765],\n",
      "        [0.6352, 0.6308],\n",
      "        [0.3453, 0.6933]])], tensor(1)], [[tensor([[0, 0, 0, 1, 1, 1, 2, 2, 2, 3, 3, 3],\n",
      "        [1, 2, 3, 0, 2, 3, 0, 1, 3, 0, 1, 2]]), tensor([[0.2336, 0.3733, 0.4466],\n",
      "        [0.5709, 0.9311, 0.8133],\n",
      "        [0.1489, 0.3502, 0.6065],\n",
      "        [0.9067, 0.6036, 0.1464]]), tensor([[0.5855, 0.0238],\n",
      "        [0.1492, 0.0327],\n",
      "        [0.4902, 0.6464],\n",
      "        [0.4126, 0.6201],\n",
      "        [0.7742, 0.6851],\n",
      "        [0.5548, 0.7413],\n",
      "        [0.7799, 0.2441],\n",
      "        [0.0634, 0.4602],\n",
      "        [0.8682, 0.4931],\n",
      "        [0.9556, 0.7870],\n",
      "        [0.8649, 0.5478],\n",
      "        [0.1978, 0.3266]])], tensor(0)], [[tensor([[0, 0, 0, 1, 1, 1, 2, 2, 2, 3, 3, 3],\n",
      "        [1, 2, 3, 0, 2, 3, 0, 1, 3, 0, 1, 2]]), tensor([[0.5775, 0.1401, 0.1975],\n",
      "        [0.7336, 0.3809, 0.5978],\n",
      "        [0.7132, 0.3643, 0.1414],\n",
      "        [0.1005, 0.0291, 0.6829]]), tensor([[0.8117, 0.6654],\n",
      "        [0.4159, 0.6845],\n",
      "        [0.5236, 0.9694],\n",
      "        [0.9202, 0.3900],\n",
      "        [0.7084, 0.4077],\n",
      "        [0.6529, 0.9623],\n",
      "        [0.6783, 0.0890],\n",
      "        [0.3023, 0.8570],\n",
      "        [0.5475, 0.0621],\n",
      "        [0.1989, 0.9189],\n",
      "        [0.1002, 0.4966],\n",
      "        [0.6190, 0.8244]])], tensor(0)]]\n"
     ]
    }
   ],
   "source": [
    "def test_create_tensordata_new(mode = \"binary\"):\n",
    "\n",
    "    num_nodes = 4\n",
    "    num_edges = int(num_nodes * (num_nodes - 1) / 2)\n",
    "    num_node_features = 3\n",
    "    num_edge_features = 2\n",
    "\n",
    "    # Create data_list with the 3 examples with entries of the form [[x, ef], y]\n",
    "    if mode == \"multi\":\n",
    "        data_list = [[[np.random.rand(num_nodes, num_node_features), np.random.rand(num_nodes, num_nodes, num_edge_features)], np.random.randint(3)] for i in range(6)]\n",
    "\n",
    "    if mode == \"binary\":\n",
    "        data_list = [[[np.random.rand(num_nodes, num_node_features), np.random.rand(num_nodes, num_nodes, num_edge_features)], np.random.randint(2)] for i in range(6)]\n",
    "    \n",
    "    return create_tensordata_new(num_nodes, data_list, complete=True, save=False, logdir=None)\n",
    "\n",
    "print(test_create_tensordata_new(mode = \"binary\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Case 1: No edge features.\n",
      "[[1.]\n",
      " [0.]\n",
      " [0.]\n",
      " [1.]\n",
      " [1.]\n",
      " [0.]\n",
      " [0.]\n",
      " [1.]\n",
      " [1.]\n",
      " [0.]\n",
      " [0.]\n",
      " [1.]]\n",
      "\n",
      "Case 2: Edge features in FCN format shape = (num_nodes, num_nodes, num_edge_features).\n",
      "A[0, 1]: 1\n",
      "Old edge_attr[0, 1]: [0.76202206 0.58994923]\n",
      "A[0, 2]: 0\n",
      "Old edge_attr[0, 2]: [0.67713691 0.93162194]\n",
      "A[0, 3]: 0\n",
      "Old edge_attr[0, 3]: [0.42088023 0.9501309 ]\n",
      "A[1, 0]: 1\n",
      "Old edge_attr[1, 0]: [0.0814149  0.04268138]\n",
      "A[1, 2]: 1\n",
      "Old edge_attr[1, 2]: [0.54536779 0.61504542]\n",
      "A[1, 3]: 0\n",
      "Old edge_attr[1, 3]: [0.67335006 0.53333583]\n",
      "A[2, 0]: 0\n",
      "Old edge_attr[2, 0]: [0.1271862  0.72529445]\n",
      "A[2, 1]: 1\n",
      "Old edge_attr[2, 1]: [0.39719874 0.63849772]\n",
      "A[2, 3]: 1\n",
      "Old edge_attr[2, 3]: [0.41139917 0.70986625]\n",
      "A[3, 0]: 0\n",
      "Old edge_attr[3, 0]: [0.41701962 0.75990651]\n",
      "A[3, 1]: 0\n",
      "Old edge_attr[3, 1]: [0.50577002 0.14245345]\n",
      "A[3, 2]: 1\n",
      "Old edge_attr[3, 2]: [0.79951818 0.98112661]\n",
      "New edge_attr[0]: [1.         0.76202206 0.58994923]\n",
      "New edge_attr[1]: [0.         0.67713691 0.93162194]\n",
      "New edge_attr[2]: [0.         0.42088023 0.9501309 ]\n",
      "New edge_attr[3]: [1.         0.0814149  0.04268138]\n",
      "New edge_attr[4]: [1.         0.54536779 0.61504542]\n",
      "New edge_attr[5]: [0.         0.67335006 0.53333583]\n",
      "\n",
      "Case 3: Edge features in PyG format shape = (num_edges, num_edge_features).\n",
      "New edge_attr[0]: [1.         0.03057038 0.47755671]\n",
      "Old edge_attr[0]: [0.03057038 0.47755671]\n",
      "New edge_attr[1]: [0.         0.65888129 0.95212317]\n",
      "Old edge_attr[1]: [0.65888129 0.95212317]\n",
      "New edge_attr[2]: [0.         0.13017355 0.8517976 ]\n",
      "Old edge_attr[2]: [0.13017355 0.8517976 ]\n",
      "New edge_attr[3]: [1.         0.14385503 0.55255348]\n",
      "Old edge_attr[3]: [0.14385503 0.55255348]\n",
      "New edge_attr[4]: [1.         0.66362885 0.31161706]\n",
      "Old edge_attr[4]: [0.66362885 0.31161706]\n",
      "New edge_attr[5]: [0.         0.44814474 0.49743199]\n",
      "Old edge_attr[5]: [0.44814474 0.49743199]\n",
      "New edge_attr[6]: [0.         0.25148975 0.70824153]\n",
      "Old edge_attr[6]: [0.25148975 0.70824153]\n",
      "New edge_attr[7]: [1.         0.22026406 0.05635233]\n",
      "Old edge_attr[7]: [0.22026406 0.05635233]\n",
      "New edge_attr[8]: [1.         0.14914145 0.34177874]\n",
      "Old edge_attr[8]: [0.14914145 0.34177874]\n",
      "New edge_attr[9]: [0.         0.71399021 0.59762051]\n",
      "Old edge_attr[9]: [0.71399021 0.59762051]\n",
      "New edge_attr[10]: [0.         0.6736528  0.63515136]\n",
      "Old edge_attr[10]: [0.6736528  0.63515136]\n",
      "New edge_attr[11]: [1.         0.0650012  0.66611245]\n",
      "Old edge_attr[11]: [0.0650012  0.66611245]\n"
     ]
    }
   ],
   "source": [
    "def test_adj_to_edge_attr():\n",
    "\n",
    "    # Adjacency matrix A (same for all cases)\n",
    "    A = np.array([[0, 1, 0, 0],\n",
    "                [1, 0, 1, 0],\n",
    "                [0, 1, 0, 1],\n",
    "                [0, 0, 1, 0]])\n",
    "\n",
    "    # Edge index (same for all cases). Complete graph K_4.\n",
    "    edge_index = build_K_n(4)\n",
    "\n",
    "    # Test Case 1: No edge features\n",
    "    case1_edge_attr = None\n",
    "\n",
    "    # Test Case 2: Edge features in FCN format (shape = (num_nodes, num_nodes))\n",
    "    case2_edge_attr = np.random.rand(4, 4, 2)\n",
    "\n",
    "    # Test Case 3: Edge features in PyG format (shape = (num_edges, 1))\n",
    "    case3_edge_attr = np.random.rand(12, 2)\n",
    "\n",
    "    test_cases = {\n",
    "        \"Case 1\": (A, edge_index, case1_edge_attr),\n",
    "        \"Case 2\": (A, edge_index, case2_edge_attr),\n",
    "        \"Case 3\": (A, edge_index, case3_edge_attr),\n",
    "    }\n",
    "\n",
    "    # Case 1: No edge features.\n",
    "    print(\"Case 1: No edge features.\")\n",
    "    print(adj_to_edge_attr(A, edge_index))\n",
    "\n",
    "    # Case 2: Edge features in FCN format shape = (num_nodes, num_nodes, num_edge_features).\n",
    "    print(\"\\nCase 2: Edge features in FCN format shape = (num_nodes, num_nodes, num_edge_features).\")\n",
    "    edge_attr_new = adj_to_edge_attr(A, edge_index, case2_edge_attr, \"FCN\")\n",
    "    for i in range(4):\n",
    "        for j in range(4):\n",
    "            if i != j:\n",
    "                print(f\"A[{i}, {j}]: {A[i, j]}\")\n",
    "                print(f\"Old edge_attr[{i}, {j}]: {case2_edge_attr[i, j]}\")\n",
    "    for k in range(6):\n",
    "        print(f\"New edge_attr[{k}]: {edge_attr_new[k]}\")\n",
    "\n",
    "    # Case 3: Edge features in PyG format shape = (num_edges, num_edge_features).\n",
    "    print(\"\\nCase 3: Edge features in PyG format shape = (num_edges, num_edge_features).\")\n",
    "    edge_attr_new = adj_to_edge_attr(A, edge_index, case3_edge_attr, \"PyG\")\n",
    "    for k in range(12):\n",
    "        print(f\"New edge_attr[{k}]: {edge_attr_new[k]}\")\n",
    "        print(f\"Old edge_attr[{k}]: {case3_edge_attr[k]}\")\n",
    "\n",
    "test_adj_to_edge_attr()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Intel MKL WARNING: Support of Intel(R) Streaming SIMD Extensions 4.2 (Intel(R) SSE4.2) enabled only processors has been deprecated. Intel oneAPI Math Kernel Library 2025.0 will require Intel(R) Advanced Vector Extensions (Intel(R) AVX) instructions.\n",
      "Intel MKL WARNING: Support of Intel(R) Streaming SIMD Extensions 4.2 (Intel(R) SSE4.2) enabled only processors has been deprecated. Intel oneAPI Math Kernel Library 2025.0 will require Intel(R) Advanced Vector Extensions (Intel(R) AVX) instructions.\n",
      "Intel MKL WARNING: Support of Intel(R) Streaming SIMD Extensions 4.2 (Intel(R) SSE4.2) enabled only processors has been deprecated. Intel oneAPI Math Kernel Library 2025.0 will require Intel(R) Advanced Vector Extensions (Intel(R) AVX) instructions.\n",
      "Intel MKL WARNING: Support of Intel(R) Streaming SIMD Extensions 4.2 (Intel(R) SSE4.2) enabled only processors has been deprecated. Intel oneAPI Math Kernel Library 2025.0 will require Intel(R) Advanced Vector Extensions (Intel(R) AVX) instructions.\n",
      "Intel MKL WARNING: Support of Intel(R) Streaming SIMD Extensions 4.2 (Intel(R) SSE4.2) enabled only processors has been deprecated. Intel oneAPI Math Kernel Library 2025.0 will require Intel(R) Advanced Vector Extensions (Intel(R) AVX) instructions.\n",
      "Intel MKL WARNING: Support of Intel(R) Streaming SIMD Extensions 4.2 (Intel(R) SSE4.2) enabled only processors has been deprecated. Intel oneAPI Math Kernel Library 2025.0 will require Intel(R) Advanced Vector Extensions (Intel(R) AVX) instructions.\n",
      "Intel MKL WARNING: Support of Intel(R) Streaming SIMD Extensions 4.2 (Intel(R) SSE4.2) enabled only processors has been deprecated. Intel oneAPI Math Kernel Library 2025.0 will require Intel(R) Advanced Vector Extensions (Intel(R) AVX) instructions.\n",
      "Intel MKL WARNING: Support of Intel(R) Streaming SIMD Extensions 4.2 (Intel(R) SSE4.2) enabled only processors has been deprecated. Intel oneAPI Math Kernel Library 2025.0 will require Intel(R) Advanced Vector Extensions (Intel(R) AVX) instructions.\n",
      "DataBatch(x=[3424, 9], edge_index=[2, 362944], edge_attr=[362944, 3], y=[32], batch=[3424], ptr=[33])\n",
      "Intel MKL WARNING: Support of Intel(R) Streaming SIMD Extensions 4.2 (Intel(R) SSE4.2) enabled only processors has been deprecated. Intel oneAPI Math Kernel Library 2025.0 will require Intel(R) Advanced Vector Extensions (Intel(R) AVX) instructions.\n",
      "Intel MKL WARNING: Support of Intel(R) Streaming SIMD Extensions 4.2 (Intel(R) SSE4.2) enabled only processors has been deprecated. Intel oneAPI Math Kernel Library 2025.0 will require Intel(R) Advanced Vector Extensions (Intel(R) AVX) instructions.\n",
      "Intel MKL WARNING: Support of Intel(R) Streaming SIMD Extensions 4.2 (Intel(R) SSE4.2) enabled only processors has been deprecated. Intel oneAPI Math Kernel Library 2025.0 will require Intel(R) Advanced Vector Extensions (Intel(R) AVX) instructions.\n",
      "Intel MKL WARNING: Support of Intel(R) Streaming SIMD Extensions 4.2 (Intel(R) SSE4.2) enabled only processors has been deprecated. Intel oneAPI Math Kernel Library 2025.0 will require Intel(R) Advanced Vector Extensions (Intel(R) AVX) instructions.\n",
      "Intel MKL WARNING: Support of Intel(R) Streaming SIMD Extensions 4.2 (Intel(R) SSE4.2) enabled only processors has been deprecated. Intel oneAPI Math Kernel Library 2025.0 will require Intel(R) Advanced Vector Extensions (Intel(R) AVX) instructions.\n",
      "Intel MKL WARNING: Support of Intel(R) Streaming SIMD Extensions 4.2 (Intel(R) SSE4.2) enabled only processors has been deprecated. Intel oneAPI Math Kernel Library 2025.0 will require Intel(R) Advanced Vector Extensions (Intel(R) AVX) instructions.\n",
      "Intel MKL WARNING: Support of Intel(R) Streaming SIMD Extensions 4.2 (Intel(R) SSE4.2) enabled only processors has been deprecated. Intel oneAPI Math Kernel Library 2025.0 will require Intel(R) Advanced Vector Extensions (Intel(R) AVX) instructions.\n",
      "Intel MKL WARNING: Support of Intel(R) Streaming SIMD Extensions 4.2 (Intel(R) SSE4.2) enabled only processors has been deprecated. Intel oneAPI Math Kernel Library 2025.0 will require Intel(R) Advanced Vector Extensions (Intel(R) AVX) instructions.\n",
      "DataBatch(x=[3424, 9], edge_index=[2, 362944], edge_attr=[362944, 3], y=[32], batch=[3424], ptr=[33])\n",
      "Intel MKL WARNING: Support of Intel(R) Streaming SIMD Extensions 4.2 (Intel(R) SSE4.2) enabled only processors has been deprecated. Intel oneAPI Math Kernel Library 2025.0 will require Intel(R) Advanced Vector Extensions (Intel(R) AVX) instructions.Intel MKL WARNING: Support of Intel(R) Streaming SIMD Extensions 4.2 (Intel(R) SSE4.2) enabled only processors has been deprecated. Intel oneAPI Math Kernel Library 2025.0 will require Intel(R) Advanced Vector Extensions (Intel(R) AVX) instructions.\n",
      "\n",
      "Intel MKL WARNING: Support of Intel(R) Streaming SIMD Extensions 4.2 (Intel(R) SSE4.2) enabled only processors has been deprecated. Intel oneAPI Math Kernel Library 2025.0 will require Intel(R) Advanced Vector Extensions (Intel(R) AVX) instructions.\n",
      "Intel MKL WARNING: Support of Intel(R) Streaming SIMD Extensions 4.2 (Intel(R) SSE4.2) enabled only processors has been deprecated. Intel oneAPI Math Kernel Library 2025.0 will require Intel(R) Advanced Vector Extensions (Intel(R) AVX) instructions.\n",
      "Intel MKL WARNING: Support of Intel(R) Streaming SIMD Extensions 4.2 (Intel(R) SSE4.2) enabled only processors has been deprecated. Intel oneAPI Math Kernel Library 2025.0 will require Intel(R) Advanced Vector Extensions (Intel(R) AVX) instructions.\n",
      "Intel MKL WARNING: Support of Intel(R) Streaming SIMD Extensions 4.2 (Intel(R) SSE4.2) enabled only processors has been deprecated. Intel oneAPI Math Kernel Library 2025.0 will require Intel(R) Advanced Vector Extensions (Intel(R) AVX) instructions.\n",
      "Intel MKL WARNING: Support of Intel(R) Streaming SIMD Extensions 4.2 (Intel(R) SSE4.2) enabled only processors has been deprecated. Intel oneAPI Math Kernel Library 2025.0 will require Intel(R) Advanced Vector Extensions (Intel(R) AVX) instructions.\n",
      "Intel MKL WARNING: Support of Intel(R) Streaming SIMD Extensions 4.2 (Intel(R) SSE4.2) enabled only processors has been deprecated. Intel oneAPI Math Kernel Library 2025.0 will require Intel(R) Advanced Vector Extensions (Intel(R) AVX) instructions.\n",
      "DataBatch(x=[3424, 9], edge_index=[2, 362944], edge_attr=[362944, 3], y=[32], batch=[3424], ptr=[33])\n"
     ]
    }
   ],
   "source": [
    "import sys\n",
    "sys.path.append(\"../src\")\n",
    "from preprocess import create_data_loaders\n",
    "import torch\n",
    "\n",
    "def test_create_data_loaders():\n",
    "    dataset = torch.load(\"/Users/xaviermootoo/Documents/Data/ssl-seizure-detection/patient_pyg/jh101/supervised/jh101_run1.pt\")\n",
    "    train_loader, val_loader, test_loader = create_data_loaders(dataset, data_size=1.0, val_ratio=0.2, test_ratio=0.1, batch_size=32, num_workers=4, model_id=\"supervised\")\n",
    "    for batch in train_loader:\n",
    "        print(batch)\n",
    "        break\n",
    "    for batch in val_loader:\n",
    "        print(batch)\n",
    "        break\n",
    "    for batch in test_loader:\n",
    "        print(batch)\n",
    "        break\n",
    "\n",
    "test_create_data_loaders()\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "torch2_mps",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
