{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from torch_geometric.nn import NNConv, GATConv, global_mean_pool\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "NNConvGATGNN(\n",
      "  (edge_mlp): EdgeMLP(\n",
      "    (mlp): Sequential(\n",
      "      (0): Linear(in_features=6, out_features=128, bias=True)\n",
      "      (1): ReLU()\n",
      "      (2): Linear(in_features=128, out_features=64, bias=True)\n",
      "      (3): ReLU()\n",
      "      (4): Linear(in_features=64, out_features=200, bias=True)\n",
      "    )\n",
      "  )\n",
      "  (conv1): NNConv(10, 20, aggr=add, nn=EdgeMLP(\n",
      "    (mlp): Sequential(\n",
      "      (0): Linear(in_features=6, out_features=128, bias=True)\n",
      "      (1): ReLU()\n",
      "      (2): Linear(in_features=128, out_features=64, bias=True)\n",
      "      (3): ReLU()\n",
      "      (4): Linear(in_features=64, out_features=200, bias=True)\n",
      "    )\n",
      "  ))\n",
      "  (conv2): GATConv(20, 20, heads=1)\n",
      "  (fc1): Linear(in_features=20, out_features=5, bias=True)\n",
      "  (fc2): Linear(in_features=5, out_features=1, bias=True)\n",
      ")\n"
     ]
    }
   ],
   "source": [
    "# Define the MLP for NNConv\n",
    "class EdgeMLP(nn.Module):\n",
    "    def __init__(self, num_edge_features, in_channels, out_channels):\n",
    "        super(EdgeMLP, self).__init__()\n",
    "        self.mlp = nn.Sequential(\n",
    "            nn.Linear(num_edge_features, 128),\n",
    "            nn.ReLU(),\n",
    "            nn.Linear(128, 64),\n",
    "            nn.ReLU(),\n",
    "            nn.Linear(64, in_channels * out_channels)\n",
    "        )\n",
    "        \n",
    "    def forward(self, edge_attr):\n",
    "        return self.mlp(edge_attr)\n",
    "\n",
    "\n",
    "# Adapted Graph Neural Network using NNConv and GATConv\n",
    "class NNConvGATGNN(nn.Module):\n",
    "    def __init__(self, num_node_features, num_edge_features, hidden_channels, out_channels):\n",
    "        super(NNConvGATGNN, self).__init__()\n",
    "        \n",
    "        # Initialize the MLP for NNConv\n",
    "        self.edge_mlp = EdgeMLP(num_edge_features, num_node_features, hidden_channels)\n",
    "        \n",
    "        # NNConv layer\n",
    "        self.conv1 = NNConv(num_node_features, hidden_channels, self.edge_mlp)\n",
    "        \n",
    "        # GATConv layer\n",
    "        self.conv2 = GATConv(hidden_channels, hidden_channels, heads=1, concat=False)\n",
    "\n",
    "        # Fully connected layer\n",
    "        self.fc1 = nn.Linear(hidden_channels, out_channels)\n",
    "        self.fc2 = nn.Linear(out_channels, 1)\n",
    "        \n",
    "    def forward(self, x, edge_index, edge_attr, batch):\n",
    "        # NNConv layer\n",
    "        x = self.conv1(x, edge_index, edge_attr)\n",
    "        x = F.relu(x)\n",
    "        \n",
    "        # GATConv layer\n",
    "        x = self.conv2(x, edge_index)\n",
    "        x = F.relu(x)\n",
    "        \n",
    "        # Global average pooling\n",
    "        x = global_mean_pool(x, batch) #<-- batch vector to keep track of graphs\n",
    "\n",
    "        # Fully connected layers\n",
    "        x = self.fc1(x)\n",
    "        x = F.relu(x)\n",
    "\n",
    "        x = self.fc2(x)\n",
    "        x = torch.sigmoid(x)\n",
    "        \n",
    "        return x\n",
    "\n",
    "# Initialize the model\n",
    "model_with_gat = NNConvGATGNN(num_node_features=10, num_edge_features=6, hidden_channels=20, out_channels=5)\n",
    "\n",
    "# Print the model architecture\n",
    "print(model_with_gat)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Output shape: torch.Size([2, 1])\n",
      "Output: tensor([[0.6181],\n",
      "        [0.6110]], grad_fn=<SigmoidBackward0>)\n"
     ]
    }
   ],
   "source": [
    "# Test for a batch\n",
    "from torch_geometric.data import Batch, Data\n",
    "\n",
    "# Initialize the model\n",
    "model = NNConvGATGNN(num_node_features=10, num_edge_features=6, hidden_channels=20, out_channels=5)\n",
    "\n",
    "# Create synthetic data for two graphs\n",
    "# Graph 1\n",
    "x1 = torch.randn((8, 10))  # 8 nodes with 10 features each\n",
    "edge_index1 = torch.tensor([[0, 1, 2, 3, 4, 5, 6, 7], [1, 2, 3, 4, 5, 6, 7, 0]], dtype=torch.long)  # 8 edges\n",
    "edge_attr1 = torch.randn((8, 6))  # 8 edges with 6 features each\n",
    "data1 = Data(x=x1, edge_index=edge_index1, edge_attr=edge_attr1)\n",
    "\n",
    "# Graph 2\n",
    "x2 = torch.randn((6, 10))  # 6 nodes with 10 features each\n",
    "edge_index2 = torch.tensor([[0, 1, 2, 3, 4, 5], [1, 2, 3, 4, 5, 0]], dtype=torch.long)  # 6 edges\n",
    "edge_attr2 = torch.randn((6, 6))  # 6 edges with 6 features each\n",
    "data2 = Data(x=x2, edge_index=edge_index2, edge_attr=edge_attr2)\n",
    "\n",
    "# Create a batch from multiple graphs\n",
    "batch = Batch.from_data_list([data1, data2])\n",
    "\n",
    "# Forward pass\n",
    "output = model(batch.x, batch.edge_index, batch.edge_attr, batch.batch)\n",
    "\n",
    "# Output should be of shape [num_nodes_in_all_graphs, out_channels]\n",
    "print(\"Output shape:\", output.shape)\n",
    "print(\"Output:\", output)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "NNConvGATGNN(\n",
      "  (edge_mlp): EdgeMLP(\n",
      "    (mlp): Sequential(\n",
      "      (0): Linear(in_features=6, out_features=128, bias=True)\n",
      "      (1): ReLU()\n",
      "      (2): Linear(in_features=128, out_features=64, bias=True)\n",
      "      (3): ReLU()\n",
      "      (4): Linear(in_features=64, out_features=200, bias=True)\n",
      "    )\n",
      "  )\n",
      "  (conv1): NNConv(10, 20, aggr=add, nn=EdgeMLP(\n",
      "    (mlp): Sequential(\n",
      "      (0): Linear(in_features=6, out_features=128, bias=True)\n",
      "      (1): ReLU()\n",
      "      (2): Linear(in_features=128, out_features=64, bias=True)\n",
      "      (3): ReLU()\n",
      "      (4): Linear(in_features=64, out_features=200, bias=True)\n",
      "    )\n",
      "  ))\n",
      "  (conv2): GATConv(20, 20, heads=1)\n",
      "  (fc1): Linear(in_features=20, out_features=5, bias=True)\n",
      "  (fc2): Linear(in_features=5, out_features=1, bias=True)\n",
      ")\n"
     ]
    }
   ],
   "source": [
    "# Define the MLP for NNConv\n",
    "class EdgeMLP(nn.Module):\n",
    "    def __init__(self, num_edge_features, in_channels, out_channels):\n",
    "        super(EdgeMLP, self).__init__()\n",
    "        self.mlp = nn.Sequential(\n",
    "            nn.Linear(num_edge_features, 128),\n",
    "            nn.ReLU(),\n",
    "            nn.Linear(128, 64),\n",
    "            nn.ReLU(),\n",
    "            nn.Linear(64, in_channels * out_channels)\n",
    "        )\n",
    "        \n",
    "    def forward(self, edge_attr):\n",
    "        return self.mlp(edge_attr)\n",
    "\n",
    "\n",
    "# Adapted Graph Neural Network using NNConv and GATConv\n",
    "class PairsNNConvGATGNN(nn.Module):\n",
    "    def __init__(self, num_node_features, num_edge_features, hidden_channels, out_channels):\n",
    "        super(PairsNNConvGATGNN, self).__init__()\n",
    "        \n",
    "        # Initialize the MLP for NNConv\n",
    "        self.edge_mlp = EdgeMLP(num_edge_features, num_node_features, hidden_channels)\n",
    "        \n",
    "        # NNConv layer\n",
    "        self.conv1 = NNConv(num_node_features, hidden_channels, self.edge_mlp)\n",
    "        \n",
    "        # GATConv layer\n",
    "        self.conv2 = GATConv(hidden_channels, hidden_channels, heads=1, concat=False)\n",
    "\n",
    "        # Fully connected layer\n",
    "        self.fc1 = nn.Linear(hidden_channels, out_channels)\n",
    "        self.fc2 = nn.Linear(out_channels, 1)\n",
    "    \n",
    "        \n",
    "    def forward_one(self, x, edge_index, edge_attr, batch):\n",
    "        # NNConv layer\n",
    "        x = self.conv1(x, edge_index, edge_attr)\n",
    "        x = F.relu(x)\n",
    "        \n",
    "        # GATConv layer\n",
    "        x = self.conv2(x, edge_index)\n",
    "        x = F.relu(x)\n",
    "        \n",
    "        # Global average pooling\n",
    "        x = global_mean_pool(x, batch) #<-- batch vector to keep track of graphs\n",
    "\n",
    "        # Fully connected layers\n",
    "        x = self.fc1(x)\n",
    "        x = F.relu(x)\n",
    "        \n",
    "        return x\n",
    "    \n",
    "    def forward(self, x1, edge_index1, edge_attr1, batch1, x2, edge_index2, edge_attr2, batch2):\n",
    "        # First graph's embeddings\n",
    "        z1 = self.forward_one(x1, edge_index1, edge_attr1, batch1)\n",
    "        \n",
    "        # Second graph's embeddings\n",
    "        z2 = self.forward_one(x2, edge_index2, edge_attr2, batch2)\n",
    "        \n",
    "        # Contrast the embeddings\n",
    "        z = torch.abs(z1 - z2)\n",
    "        \n",
    "        # Logistic regression\n",
    "        z = self.fc2(z)\n",
    "        z = torch.sigmoid(z)\n",
    "        \n",
    "        return z\n",
    "\n",
    "# Initialize the model\n",
    "model_with_gat = NNConvGATGNN(num_node_features=10, num_edge_features=6, hidden_channels=20, out_channels=5)\n",
    "\n",
    "# Print the model architecture\n",
    "print(model_with_gat)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "from torch_geometric.data import Data\n",
    "class PairData(Data):\n",
    "    def __inc__(self, key, value, *args, **kwargs):\n",
    "        if key == 'edge_index1':\n",
    "            return self.x1.size(0)\n",
    "        if key == 'edge_index2':\n",
    "            return self.x2.size(0)\n",
    "        return super().__inc__(key, value, *args, **kwargs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "from torch_geometric.data import Batch\n",
    "from torch_geometric.loader import DataLoader\n",
    "\n",
    "# Create a dummy graph using PyG's Data class\n",
    "def create_sample_graph(num_nodes, num_node_features, num_edge_features):\n",
    "    x1, x2 = torch.randn(num_nodes, num_node_features), torch.randn(num_nodes, num_node_features)  # Node features\n",
    "    edge_index1 = torch.tensor([[0, 2, 3, 1, 4],\n",
    "                                [2, 0, 1, 3, 3]], dtype=torch.long)\n",
    "    edge_index2 = edge_index1\n",
    "    num_edges = edge_index1.size()[1]\n",
    "    edge_attr1, edge_attr2 = torch.randn((num_edges, num_edge_features)), torch.randn((num_edges, num_edge_features))   # Edge attributes\n",
    "    \n",
    "    y = torch.randint(0, 2, (1,))\n",
    "    y = y.to(torch.float32)\n",
    "    \n",
    "    return PairData(x1=x1, edge_index1=edge_index1, edge_attr1=edge_attr1,\n",
    "                    x2=x2, edge_index2=edge_index2, edge_attr2=edge_attr2,\n",
    "                    y=y)\n",
    "\n",
    "\n",
    "num_node_features = 10\n",
    "num_edge_features = 6\n",
    "hidden_channels = 20\n",
    "out_channels = 5\n",
    "\n",
    "data_list = []\n",
    "for i in range(8):\n",
    "    data_list.append(create_sample_graph(5, 10, 6))\n",
    "\n",
    "loader = DataLoader(data_list, batch_size=4, follow_batch=['x1', 'x2'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Initialize the model\n",
    "pairs_model = PairsNNConvGATGNN(num_node_features=num_node_features, num_edge_features=num_edge_features, \n",
    "                                   hidden_channels=hidden_channels, out_channels=out_channels)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Output shape: torch.Size([4, 1])\n",
      "Output: tensor([[0.4914],\n",
      "        [0.4923],\n",
      "        [0.4885],\n",
      "        [0.4924]], grad_fn=<SigmoidBackward0>)\n",
      "Output shape: torch.Size([4, 1])\n",
      "Output: tensor([[0.4928],\n",
      "        [0.4900],\n",
      "        [0.4904],\n",
      "        [0.4925]], grad_fn=<SigmoidBackward0>)\n"
     ]
    }
   ],
   "source": [
    "for batch in loader:\n",
    "    output = pairs_model(batch.x1, batch.edge_index1, batch.edge_attr1, batch.x1_batch,\n",
    "                         batch.x2, batch.edge_index2, batch.edge_attr2, batch.x2_batch)\n",
    "    print(\"Output shape:\", output.shape)\n",
    "    print(\"Output:\", output)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
