{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# This notebook converts the graph data from the pickle file containing the list of graph representations \n",
    "# into anoter pickle file containing the list of graph representations in the format of PyG format.\n",
    "import torch\n",
    "import pickle\n",
    "import numpy as np\n",
    "from pyg_preprocess import create_tensordata, convert_to_Data, pseudo_data, convert_to_PairData"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Step 1: Load original data of GRs (Pickle file)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We first load in the pickle file of the previously generated graph representations, containing a list with entries of the form $[[A, NF, EF], Y]$ where each component is a NumPy array."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load data (MAC)\n",
    "# pickle_data_path = \"/Users/xaviermootoo/Documents/Data/ssl-seizure-detection/pickle/jh101_grs.pickle\"\n",
    "# pickle_data = pickle.load(open(pickle_data_path, \"rb\"))\n",
    "\n",
    "# Load data (PC)\n",
    "pickle_data_path = r\"C:\\Users\\xmoot\\Desktop\\Data\\ssl-seizure-detection\\patient_gr\\jh101_grs.pickle\"\n",
    "pickle_data = pickle.load(open(pickle_data_path, \"rb\"))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Step 2: Convert standard GRs to PyG GRs\n",
    "The function `create_tensordata` converts the pickle file list of standard graph representations, namely a list with entries of the form $[ [A, NF, EF] , Y]$, where $A$ is the weighted adjacency matrix, $NF$ are the node features, and $EF$ are the edge features. The function first converts $A$ to the `edge_index` format for PyTorch Geometric, which is a tensor of shape [2, num_edges] where each column $[i \\ \\ j]^T$ indicates the directed edge $i \\to j$. If $A$ is a binary adjaceny matrix it will convert it accordingly, if $A$ is a weighted adjacency matrix that is for a complete graph, it will instead generate the corresponding `edge_index` for a complete graph and then stack the weights along with $EF$ in the edge features object `edge_attr` that PyTorch geometric uses. The node features $NF$ are untouched, but converted to float32 a tensor, we typically notate this by $x$ in PyTorch geometric. By the end we have a list with entries of the form `[[edge_index, x, edge_attr], y]` where each component is a tensor, `x` and `edge_attr` are float32 whereas `edge_index` and `y` are long. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Convert normal GRs to list of PyG tensors: [[A, NF, EF], Y] -> [[edge_index, x, edge_attr], y]\n",
    "pyg_grs_path = r\"C:\\Users\\xmoot\\Desktop\\Data\\ssl-seizure-detection\\patient_gr\\jh101_pyg_grs.pt\"\n",
    "pyg_grs = create_tensordata(num_nodes=107, data_list=pickle_data, complete=True, save=True, logdir=pyg_grs_path)     "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Check if it works\n",
    "pyg_data_path = r\"C:\\Users\\xmoot\\Desktop\\Data\\ssl-seizure-detection\\patient_gr\\jh101_tensors_grs_pyg.pt\"\n",
    "pyg_data = torch.load(pyg_data_path)\n",
    "print(len(pyg_data))\n",
    "print(len(pickle_data))\n",
    "print(type(pyg_data[0][0][0]))\n",
    "print(\"Edge features shape:\", pyg_data[0][0][2].shape)\n",
    "print(\"Edge features stored in edge_attr:\", pyg_data[0][0][2])\n",
    "print(\"Edge features stored in adj:\", pickle_data[0][0][0])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Step 3: Convert PyG GRs to PyG Data objects\n",
    "Stop after this step if you only need PyG Data objects for supervised learning! Here we take the PyG graph representations, and apply the `convert_to_Data` function to create a new list where each entry is now a `torch_geometric.data.Data` object. This is the main object uses to hold graphs in PyG, so we need to use it, especially for batching."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Convert the PyG GRs to the PyG Data format\n",
    "pyg_Data_path = r\"C:\\Users\\xmoot\\Desktop\\Data\\ssl-seizure-detection\\patient_gr\\jh101_pyg_Data.pt\"\n",
    "Data_list = convert_to_Data(pyg_grs, save=True, logdir=pyg_Data_path)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Step 4: Create pseudolabeled dataset\n",
    "In this step we take the output of Step 2 and apply the relative positioning pseudolabeled dataset generation for graph pairs."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of examples: 926986\n",
      "0    483636\n",
      "1    443350\n",
      "Name: y, dtype: int64\n"
     ]
    }
   ],
   "source": [
    "# Create a list of pseudolabeled graph pairs with entries of the form: [[edge_index1, x1, edge_attr1], [edge_index2, x2, edge_attr2], y]\n",
    "pdata = pseudo_data(pyg_data, tau_pos = 12 // 0.12, tau_neg = (7 * 60) // 0.12, stats = True, save = False, patientid = \"patient\", logdir = None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "926986\n",
      "Edge features shape: torch.Size([11342, 1])\n",
      "Edge features stored in edge_attr: tensor([[ 0.6607],\n",
      "        [-0.1258],\n",
      "        [-2.1098],\n",
      "        ...,\n",
      "        [ 1.7842],\n",
      "        [-1.2728],\n",
      "        [ 1.8921]])\n"
     ]
    }
   ],
   "source": [
    "# Check if it works\n",
    "print(len(pdata))\n",
    "example = pdata[0]\n",
    "graph1, graph2, label = example\n",
    "edge_index1, x1, edge_attr1 = graph1\n",
    "edge_index2, x2, edge_attr2 = graph2\n",
    "print(\"Edge features shape:\", edge_attr1.shape)\n",
    "print(\"Edge features stored in edge_attr:\", edge_attr1)\n",
    "print(\"Edge features stored in adj:\", pickle_data[0][0][0])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Step 5: Convert pseudolabeled dataset to PairData\n",
    "Instead of converting each graph pair in the pseudolabeled dataset to a `torch_geometric.data.Data` object, we instead create a new class called `PairData` that inherits from the `torch_geometric.data.Data` class, which will allow us to do batching on pairs of graphs."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create PairData\n",
    "Pair_Data_path = r\"C:\\Users\\xmoot\\Desktop\\Data\\ssl-seizure-detection\\patient_pseudolabeled\\relative_positioning\\jh101_12s_7min_PairData.pt\"\n",
    "Pair_Data = convert_to_PairData(pdata, save=True, logdir=Pair_Data_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Link for pairs of graphs: https://pytorch-geometric.readthedocs.io/en/latest/advanced/batching.html\n",
    "# Link for creating datasets: https://pytorch-geometric.readthedocs.io/en/latest/tutorial/create_dataset.html\n",
    "# Link for Data handling tutorial: https://www.youtube.com/watch?v=Vz5bT8Xw6Dc&list=PLGMXrbDNfqTzqxB1IGgimuhtfAhGd8lHF&index=5"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
