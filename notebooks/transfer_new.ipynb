{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Step 1: Load Model\n",
    "Before we begin transfer learning we first have to load the model. This can be done in two ways (1) load the `model.pth` which includes the model's architecture and weights, or (2) load the model class itself, defined in `pyg_model.py`. Either way works, but (2) is a bit safer when dealing with unknown files. After loading the model, we then load the state dictionary `model_state_dict.pth` which allows us to reference specific layers of the model and is crucial for examining, extracting, or modifying its underlying architecture."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Intel MKL WARNING: Support of Intel(R) Streaming SIMD Extensions 4.2 (Intel(R) SSE4.2) enabled only processors has been deprecated. Intel oneAPI Math Kernel Library 2025.0 will require Intel(R) Advanced Vector Extensions (Intel(R) AVX) instructions.\n",
      "Intel MKL WARNING: Support of Intel(R) Streaming SIMD Extensions 4.2 (Intel(R) SSE4.2) enabled only processors has been deprecated. Intel oneAPI Math Kernel Library 2025.0 will require Intel(R) Advanced Vector Extensions (Intel(R) AVX) instructions.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/xaviermootoo/opt/anaconda3/envs/torch2_mps/lib/python3.10/site-packages/torch_geometric/graphgym/config.py:19: UserWarning: Could not define global config object. Please install 'yacs' via 'pip install yacs' in order to use GraphGym\n",
      "  warnings.warn(\"Could not define global config object. Please install \"\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "temporal_shuffling(\n",
       "  (encoder): gnn_encoder(\n",
       "    (edge_mlp): EdgeMLP(\n",
       "      (mlp): Sequential(\n",
       "        (0): Linear(in_features=3, out_features=128, bias=True)\n",
       "        (1): ReLU()\n",
       "        (2): Linear(in_features=128, out_features=64, bias=True)\n",
       "        (3): ReLU()\n",
       "        (4): Linear(in_features=64, out_features=576, bias=True)\n",
       "      )\n",
       "    )\n",
       "    (conv1): NNConv(9, 64, aggr=add, nn=EdgeMLP(\n",
       "      (mlp): Sequential(\n",
       "        (0): Linear(in_features=3, out_features=128, bias=True)\n",
       "        (1): ReLU()\n",
       "        (2): Linear(in_features=128, out_features=64, bias=True)\n",
       "        (3): ReLU()\n",
       "        (4): Linear(in_features=64, out_features=576, bias=True)\n",
       "      )\n",
       "    ))\n",
       "    (conv2): GATConv(64, 32, heads=1)\n",
       "    (fc1): Linear(in_features=32, out_features=64, bias=True)\n",
       "    (fc2): Linear(in_features=64, out_features=128, bias=True)\n",
       "    (fc3): Linear(in_features=128, out_features=256, bias=True)\n",
       "  )\n",
       "  (fc): Linear(in_features=512, out_features=1, bias=True)\n",
       ")"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import torch\n",
    "import copy\n",
    "import sys\n",
    "sys.path.append(\"../src\")\n",
    "\n",
    "model_path = \"/Users/xaviermootoo/Documents/Data/ssl-seizure-detection/models/jh101/model/temporal_shuffling.pth\"\n",
    "model_dict_path = \"/Users/xaviermootoo/Documents/Data/ssl-seizure-detection/models/jh101/model/temporal_shuffling_state_dict.pth\"\n",
    "\n",
    "# Load model\n",
    "model = torch.load(model_path)\n",
    "\n",
    "# Load state dictionary\n",
    "model_dict = torch.load(model_dict_path)\n",
    "\n",
    "# Set the state dictionary to the model\n",
    "model.load_state_dict(model_dict)\n",
    "model.eval()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Step 2: Extract Layers\n",
    "In this step we extract the layers we want to use for the supervised model downstream. In this case, we need the NNConv and GATConv layers from our model, but since our NNConv actually depends on a separate layer called EdgeMLP (which is just a multilayer perpcetron), we'll need that too, since it's essentially part of the NNConv layer's parameters. You can assign it the old fashioned way using `EdgeMLP_module = model.edge_mlp` but this will create issues later on when we try to make two copies of `EdgeMLP_module` for freezing and unfreezing it, so we use the `copy` package instead."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "EdgeMLP_pretrained = copy.deepcopy(model.encoder.edge_mlp)\n",
    "NNConv_pretrained = copy.deepcopy(model.encoder.conv1)\n",
    "GATConv_pretrained = copy.deepcopy(model.encoder.conv2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can examine the weights of a layer with the following:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "mlp.0.weight \t torch.Size([128, 3])\n",
      "mlp.0.bias \t torch.Size([128])\n",
      "mlp.2.weight \t torch.Size([64, 128])\n",
      "mlp.2.bias \t torch.Size([64])\n",
      "mlp.4.weight \t torch.Size([576, 64])\n",
      "mlp.4.bias \t torch.Size([576])\n"
     ]
    }
   ],
   "source": [
    "for param_tensor in EdgeMLP_pretrained.state_dict():\n",
    "    print(param_tensor, \"\\t\", EdgeMLP_pretrained.state_dict()[param_tensor].size())\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "And here's a test running some random input through the EdgeMLP, to verify it's functional."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[ 0.0321,  0.0009,  0.0084,  ...,  0.0310, -0.0705,  0.0445],\n",
      "        [-0.0479,  0.0043, -0.0925,  ...,  0.0205, -0.1029,  0.1922],\n",
      "        [-0.0017, -0.1137, -0.0789,  ...,  0.1040, -0.0402,  0.0833],\n",
      "        ...,\n",
      "        [-0.0005, -0.0056,  0.0161,  ...,  0.0091, -0.0817,  0.0355],\n",
      "        [-0.0350, -0.0275, -0.0349,  ...,  0.0347, -0.0643,  0.1101],\n",
      "        [-0.1118,  0.0496, -0.0055,  ...,  0.0199,  0.0280,  0.0592]],\n",
      "       grad_fn=<AddmmBackward0>)\n"
     ]
    }
   ],
   "source": [
    "# Create some dummy data\n",
    "dummy_edge_attr = torch.randn(10, 3)  # 10 edges, each with `num_edge_features` features\n",
    "\n",
    "# Run the data through the `edge_mlp` layer\n",
    "output = EdgeMLP_pretrained(dummy_edge_attr)\n",
    "print(output)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Step 3: Downstream Task\n",
    "After extracting the layers and verifying everything is functional, we can now either (1) use the layers and their weights as initialization, or (2) use the layers but freeze the weights (i.e. they won't be updated during training). Below uses method (1), using our transferred layers as the initial layers of our network, and then we add on newer (untrained) layers on top of it. I've opted to use another `NNConv` and `GATConv` layer from `PyG`, adding onto the existing `NNConv` and `GATConv` layers, as well as a `global_mean_pool` layer and two fully connected layers. Now we're ready to go!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "from models import supervised_downstream1\n",
    "config = {\n",
    "    \"hidden_channels\": [64, 64, 32],\n",
    "    \"dropout\": 0.1,\n",
    "}\n",
    "\n",
    "pretrained_layers = [EdgeMLP_pretrained, NNConv_pretrained, GATConv_pretrained]\n",
    "\n",
    "model = supervised_downstream1(config, pretrained_layers, frozen=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Layer: conv1, Parameter: bias, Frozen: True\n",
      "Layer: conv1, Parameter: nn.mlp.0.weight, Frozen: True\n",
      "Layer: conv1, Parameter: nn.mlp.0.bias, Frozen: True\n",
      "Layer: conv1, Parameter: nn.mlp.2.weight, Frozen: True\n",
      "Layer: conv1, Parameter: nn.mlp.2.bias, Frozen: True\n",
      "Layer: conv1, Parameter: nn.mlp.4.weight, Frozen: True\n",
      "Layer: conv1, Parameter: nn.mlp.4.bias, Frozen: True\n",
      "Layer: conv1, Parameter: lin.weight, Frozen: True\n",
      "Layer: conv1, Parameter: edge_mlp.mlp.0.weight, Frozen: True\n",
      "Layer: conv1, Parameter: edge_mlp.mlp.0.bias, Frozen: True\n",
      "Layer: conv1, Parameter: edge_mlp.mlp.2.weight, Frozen: True\n",
      "Layer: conv1, Parameter: edge_mlp.mlp.2.bias, Frozen: True\n",
      "Layer: conv1, Parameter: edge_mlp.mlp.4.weight, Frozen: True\n",
      "Layer: conv1, Parameter: edge_mlp.mlp.4.bias, Frozen: True\n",
      "Layer: conv2, Parameter: att_src, Frozen: True\n",
      "Layer: conv2, Parameter: att_dst, Frozen: True\n",
      "Layer: conv2, Parameter: bias, Frozen: True\n",
      "Layer: conv2, Parameter: lin_src.weight, Frozen: True\n"
     ]
    }
   ],
   "source": [
    "def check_frozen_status(model):\n",
    "    layers_to_check = [\"conv1\", \"conv2\"]  # Names of the layers in your model that are pretrained\n",
    "\n",
    "    for layer_name in layers_to_check:\n",
    "        layer = getattr(model, layer_name)\n",
    "        for name, param in layer.named_parameters():\n",
    "            print(f\"Layer: {layer_name}, Parameter: {name}, Frozen: {not param.requires_grad}\")\n",
    "\n",
    "# Check if the pretrained layers are frozen or not\n",
    "check_frozen_status(model)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Finetuning on Downstream Task"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total number of examples in dataset: 1113.\n",
      "Total number of examples used: 1113.\n",
      "Number of training examples: 890. Number of training batches: 28.\n",
      "Number of validation examples: 223. Number of validation batches: 7.\n",
      "Number of test examples: 112. Number of test batches: 4.\n"
     ]
    }
   ],
   "source": [
    "from preprocess import create_data_loaders\n",
    "\n",
    "# Paths\n",
    "data_path = \"/Users/xaviermootoo/Documents/Data/ssl-seizure-detection/patient_pyg/jh101/supervised/jh101_run1.pt\"\n",
    "data = torch.load(data_path)\n",
    "\n",
    "loaders, _ = create_data_loaders(data, data_size=1.0, val_ratio=0.2, test_ratio=0.1, batch_size=32, num_workers=4, model_id=\"supervised\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Intel MKL WARNING: Support of Intel(R) Streaming SIMD Extensions 4.2 (Intel(R) SSE4.2) enabled only processors has been deprecated. Intel oneAPI Math Kernel Library 2025.0 will require Intel(R) Advanced Vector Extensions (Intel(R) AVX) instructions.\n",
      "Intel MKL WARNING: Support of Intel(R) Streaming SIMD Extensions 4.2 (Intel(R) SSE4.2) enabled only processors has been deprecated. Intel oneAPI Math Kernel Library 2025.0 will require Intel(R) Advanced Vector Extensions (Intel(R) AVX) instructions.\n",
      "Intel MKL WARNING: Support of Intel(R) Streaming SIMD Extensions 4.2 (Intel(R) SSE4.2) enabled only processors has been deprecated. Intel oneAPI Math Kernel Library 2025.0 will require Intel(R) Advanced Vector Extensions (Intel(R) AVX) instructions.\n",
      "Intel MKL WARNING: Support of Intel(R) Streaming SIMD Extensions 4.2 (Intel(R) SSE4.2) enabled only processors has been deprecated. Intel oneAPI Math Kernel Library 2025.0 will require Intel(R) Advanced Vector Extensions (Intel(R) AVX) instructions.\n",
      "Intel MKL WARNING: Support of Intel(R) Streaming SIMD Extensions 4.2 (Intel(R) SSE4.2) enabled only processors has been deprecated. Intel oneAPI Math Kernel Library 2025.0 will require Intel(R) Advanced Vector Extensions (Intel(R) AVX) instructions.\n",
      "Intel MKL WARNING: Support of Intel(R) Streaming SIMD Extensions 4.2 (Intel(R) SSE4.2) enabled only processors has been deprecated. Intel oneAPI Math Kernel Library 2025.0 will require Intel(R) Advanced Vector Extensions (Intel(R) AVX) instructions.\n",
      "Intel MKL WARNING: Support of Intel(R) Streaming SIMD Extensions 4.2 (Intel(R) SSE4.2) enabled only processors has been deprecated. Intel oneAPI Math Kernel Library 2025.0 will require Intel(R) Advanced Vector Extensions (Intel(R) AVX) instructions.\n",
      "Intel MKL WARNING: Support of Intel(R) Streaming SIMD Extensions 4.2 (Intel(R) SSE4.2) enabled only processors has been deprecated. Intel oneAPI Math Kernel Library 2025.0 will require Intel(R) Advanced Vector Extensions (Intel(R) AVX) instructions.\n",
      "Model output: torch.Size([32])\n"
     ]
    }
   ],
   "source": [
    "train_loader, val_loader, test_loader = loaders\n",
    "\n",
    "for batch in train_loader:\n",
    "    print(f\"Model output: {model(batch).size()}\")\n",
    "    break"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### One Shot Transfer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "from preprocess import extract_layers\n",
    "from models import supervised_downstream1\n",
    "model_path = \"/Users/xaviermootoo/Documents/Data/ssl-seizure-detection/models/jh101/model/temporal_shuffling.pth\"\n",
    "model_dict_path = \"/Users/xaviermootoo/Documents/Data/ssl-seizure-detection/models/jh101/model/temporal_shuffling_state_dict.pth\"\n",
    "\n",
    "extraced_layers = extract_layers(model_path, model_dict_path, \"temporal_shuffling\")\n",
    "\n",
    "config = {\n",
    "    \"hidden_channels\": [64, 64, 32],\n",
    "    \"dropout\": 0.1,\n",
    "}\n",
    "\n",
    "model = supervised_downstream1(config, extraced_layers, frozen=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total number of examples in dataset: 1113.\n",
      "Total number of examples used: 1113.\n",
      "Number of training examples: 890. Number of training batches: 28.\n",
      "Number of validation examples: 223. Number of validation batches: 7.\n",
      "Number of test examples: 112. Number of test batches: 4.\n"
     ]
    }
   ],
   "source": [
    "# Paths\n",
    "from preprocess import create_data_loaders\n",
    "data_path = \"/Users/xaviermootoo/Documents/Data/ssl-seizure-detection/patient_pyg/jh101/supervised/jh101_run1.pt\"\n",
    "data = torch.load(data_path)\n",
    "\n",
    "loaders, _ = create_data_loaders(data, data_size=1.0, val_ratio=0.2, test_ratio=0.1, batch_size=32, num_workers=4, model_id=\"supervised\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Intel MKL WARNING: Support of Intel(R) Streaming SIMD Extensions 4.2 (Intel(R) SSE4.2) enabled only processors has been deprecated. Intel oneAPI Math Kernel Library 2025.0 will require Intel(R) Advanced Vector Extensions (Intel(R) AVX) instructions.\n",
      "Intel MKL WARNING: Support of Intel(R) Streaming SIMD Extensions 4.2 (Intel(R) SSE4.2) enabled only processors has been deprecated. Intel oneAPI Math Kernel Library 2025.0 will require Intel(R) Advanced Vector Extensions (Intel(R) AVX) instructions.\n",
      "Intel MKL WARNING: Support of Intel(R) Streaming SIMD Extensions 4.2 (Intel(R) SSE4.2) enabled only processors has been deprecated. Intel oneAPI Math Kernel Library 2025.0 will require Intel(R) Advanced Vector Extensions (Intel(R) AVX) instructions.\n",
      "Intel MKL WARNING: Support of Intel(R) Streaming SIMD Extensions 4.2 (Intel(R) SSE4.2) enabled only processors has been deprecated. Intel oneAPI Math Kernel Library 2025.0 will require Intel(R) Advanced Vector Extensions (Intel(R) AVX) instructions.\n",
      "Intel MKL WARNING: Support of Intel(R) Streaming SIMD Extensions 4.2 (Intel(R) SSE4.2) enabled only processors has been deprecated. Intel oneAPI Math Kernel Library 2025.0 will require Intel(R) Advanced Vector Extensions (Intel(R) AVX) instructions.\n",
      "Intel MKL WARNING: Support of Intel(R) Streaming SIMD Extensions 4.2 (Intel(R) SSE4.2) enabled only processors has been deprecated. Intel oneAPI Math Kernel Library 2025.0 will require Intel(R) Advanced Vector Extensions (Intel(R) AVX) instructions.\n",
      "Intel MKL WARNING: Support of Intel(R) Streaming SIMD Extensions 4.2 (Intel(R) SSE4.2) enabled only processors has been deprecated. Intel oneAPI Math Kernel Library 2025.0 will require Intel(R) Advanced Vector Extensions (Intel(R) AVX) instructions.\n",
      "Intel MKL WARNING: Support of Intel(R) Streaming SIMD Extensions 4.2 (Intel(R) SSE4.2) enabled only processors has been deprecated. Intel oneAPI Math Kernel Library 2025.0 will require Intel(R) Advanced Vector Extensions (Intel(R) AVX) instructions.\n",
      "Model Output: torch.Size([32])\n"
     ]
    }
   ],
   "source": [
    "train_loader = loaders[0]\n",
    "\n",
    "for batch in train_loader:\n",
    "    print(f\"Model Output: {model(batch).size()}\")\n",
    "    break"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now let's test the model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Initial: torch.Size([107, 1]) torch.Size([2, 11342]) torch.Size([11342, 1])\n",
      "After conv1: torch.Size([107, 64]) torch.Size([2, 11342]) torch.Size([11342, 1])\n",
      "After conv2: torch.Size([107, 64]) torch.Size([2, 11342]) torch.Size([11342, 1])\n",
      "After conv3: torch.Size([107, 128]) torch.Size([2, 11342]) torch.Size([11342, 1])\n",
      "After conv4: torch.Size([107, 64]) torch.Size([2, 11342]) torch.Size([11342, 1])\n",
      "tensor([[856.9504]], grad_fn=<AddmmBackward0>)\n"
     ]
    }
   ],
   "source": [
    "# Model parameters\n",
    "num_edge_features = 1\n",
    "prev_channels = 64 #<--- The dimension of of the node features that comes from the transferred layers, i.e. x is shape [num_nodes, prev_channels\n",
    "hidden_channels = 128\n",
    "out_channels = 64\n",
    "fc_channels = 32\n",
    "\n",
    "\n",
    "# Load model\n",
    "unfrozen_model = seizure_detection1(num_edge_features=num_edge_features, prev_channels=prev_channels, hidden_channels=hidden_channels, \n",
    "                          out_channels=out_channels, fc_channels=fc_channels)\n",
    "\n",
    "# Try an example data point\n",
    "example = data[0]\n",
    "\n",
    "out = unfrozen_model(example.x, example.edge_index, example.edge_attr, example.batch, mode=\"linear\")\n",
    "print(out)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now let's implement method (2) with frozen layers."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "import copy\n",
    "\n",
    "frozen_EdgeMLP_module = copy.deepcopy(pretrained_model.edge_mlp)\n",
    "frozen_NNConv_module = copy.deepcopy(pretrained_model.conv1)\n",
    "frozen_GATConv_module = copy.deepcopy(pretrained_model.conv2)\n",
    "\n",
    "# Freeze the layers\n",
    "for param in frozen_EdgeMLP_module.parameters():\n",
    "    param.requires_grad = False\n",
    "\n",
    "for param in frozen_NNConv_module.parameters():\n",
    "    param.requires_grad = False\n",
    "\n",
    "for param in frozen_GATConv_module.parameters():\n",
    "    param.requires_grad = False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch.nn as nn\n",
    "from torch_geometric.nn import NNConv, GATConv\n",
    "from torch.functional import F\n",
    "from torch_geometric.nn import global_mean_pool\n",
    "from models import EdgeMLP\n",
    "\n",
    "\n",
    "class seizure_detection2(nn.Module):\n",
    "    def __init__(self, num_edge_features, prev_channels, hidden_channels, out_channels, fc_channels):\n",
    "        super(seizure_detection2, self).__init__()\n",
    "        \n",
    "        # Transfered graph layers\n",
    "        self.edge_mlp1 = frozen_EdgeMLP_module\n",
    "        self.conv1 = frozen_NNConv_module \n",
    "        self.conv2 = frozen_GATConv_module   \n",
    "\n",
    "        # # New graph layers\n",
    "        self.edge_mlp2 = EdgeMLP(num_edge_features, prev_channels, hidden_channels) # The number of node features are updated, therefore harde code this in.\n",
    "        self.conv3 = NNConv(prev_channels, hidden_channels, self.edge_mlp2)  # New NNConv layer\n",
    "        self.conv4 = GATConv(hidden_channels, out_channels, heads=1, concat=False) # New GATConv layer\n",
    "        \n",
    "        # # Fully connected layers\n",
    "        self.fc1 = nn.Linear(out_channels, fc_channels)\n",
    "        self.fc2 = nn.Linear(fc_channels, 1)\n",
    "        \n",
    "    def forward(self, x, edge_index, edge_attr, batch, mode = \"sigmoid\"):\n",
    "        # Your forward pass\n",
    "        \n",
    "        # NNConv layer 1\n",
    "        print(\"Initial:\", x.shape, edge_index.shape, edge_attr.shape)\n",
    "        x = self.conv1(x, edge_index, edge_attr)\n",
    "        print(\"After conv1:\", x.shape, edge_index.shape, edge_attr.shape)\n",
    "        x = F.relu(x)\n",
    "        \n",
    "        # GATConv layer 1\n",
    "        x = self.conv2(x, edge_index)\n",
    "        print(\"After conv2:\", x.shape, edge_index.shape, edge_attr.shape)\n",
    "        x = F.relu(x)\n",
    "        \n",
    "        # NNConv layer 2\n",
    "        x = self.conv3(x, edge_index, edge_attr)\n",
    "        print(\"After conv3:\", x.shape, edge_index.shape, edge_attr.shape)\n",
    "        x = F.relu(x)\n",
    "        \n",
    "        # GATConv layer 2\n",
    "        x = self.conv4(x, edge_index)\n",
    "        print(\"After conv4:\", x.shape, edge_index.shape, edge_attr.shape)\n",
    "        x = F.relu(x)\n",
    "        \n",
    "        # Global average pooling\n",
    "        x = global_mean_pool(x, batch)\n",
    "        \n",
    "        # Fully connected layer 1\n",
    "        x = self.fc1(x)\n",
    "        x = F.relu(x)\n",
    "        \n",
    "        # Fully connected layer 2\n",
    "        x = self.fc2(x)\n",
    "\n",
    "        if mode == \"sigmoid\":\n",
    "            x = torch.sigmoid(x)\n",
    "            \n",
    "        elif mode == \"linear\":\n",
    "            pass\n",
    "        \n",
    "        return x"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Then we can check whether our models are frozen or not."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Layer: edge_mlp1.mlp.0.weight, Frozen: False\n",
      "Layer: edge_mlp1.mlp.0.bias, Frozen: False\n",
      "Layer: edge_mlp1.mlp.2.weight, Frozen: False\n",
      "Layer: edge_mlp1.mlp.2.bias, Frozen: False\n",
      "Layer: edge_mlp1.mlp.4.weight, Frozen: False\n",
      "Layer: edge_mlp1.mlp.4.bias, Frozen: False\n",
      "Layer: conv1.bias, Frozen: False\n",
      "Layer: conv1.nn.mlp.0.weight, Frozen: False\n",
      "Layer: conv1.nn.mlp.0.bias, Frozen: False\n",
      "Layer: conv1.nn.mlp.2.weight, Frozen: False\n",
      "Layer: conv1.nn.mlp.2.bias, Frozen: False\n",
      "Layer: conv1.nn.mlp.4.weight, Frozen: False\n",
      "Layer: conv1.nn.mlp.4.bias, Frozen: False\n",
      "Layer: conv1.lin.weight, Frozen: False\n",
      "Layer: conv2.att_src, Frozen: False\n",
      "Layer: conv2.att_dst, Frozen: False\n",
      "Layer: conv2.bias, Frozen: False\n",
      "Layer: conv2.lin_src.weight, Frozen: False\n",
      "Layer: edge_mlp2.mlp.0.weight, Frozen: False\n",
      "Layer: edge_mlp2.mlp.0.bias, Frozen: False\n",
      "Layer: edge_mlp2.mlp.2.weight, Frozen: False\n",
      "Layer: edge_mlp2.mlp.2.bias, Frozen: False\n",
      "Layer: edge_mlp2.mlp.4.weight, Frozen: False\n",
      "Layer: edge_mlp2.mlp.4.bias, Frozen: False\n",
      "Layer: conv3.bias, Frozen: False\n",
      "Layer: conv3.lin.weight, Frozen: False\n",
      "Layer: conv4.att_src, Frozen: False\n",
      "Layer: conv4.att_dst, Frozen: False\n",
      "Layer: conv4.bias, Frozen: False\n",
      "Layer: conv4.lin_src.weight, Frozen: False\n",
      "Layer: fc1.weight, Frozen: False\n",
      "Layer: fc1.bias, Frozen: False\n",
      "Layer: fc2.weight, Frozen: False\n",
      "Layer: fc2.bias, Frozen: False\n",
      "----------------------------------------------------\n",
      "Layer: edge_mlp1.mlp.0.weight, Frozen: True\n",
      "Layer: edge_mlp1.mlp.0.bias, Frozen: True\n",
      "Layer: edge_mlp1.mlp.2.weight, Frozen: True\n",
      "Layer: edge_mlp1.mlp.2.bias, Frozen: True\n",
      "Layer: edge_mlp1.mlp.4.weight, Frozen: True\n",
      "Layer: edge_mlp1.mlp.4.bias, Frozen: True\n",
      "Layer: conv1.bias, Frozen: True\n",
      "Layer: conv1.nn.mlp.0.weight, Frozen: True\n",
      "Layer: conv1.nn.mlp.0.bias, Frozen: True\n",
      "Layer: conv1.nn.mlp.2.weight, Frozen: True\n",
      "Layer: conv1.nn.mlp.2.bias, Frozen: True\n",
      "Layer: conv1.nn.mlp.4.weight, Frozen: True\n",
      "Layer: conv1.nn.mlp.4.bias, Frozen: True\n",
      "Layer: conv1.lin.weight, Frozen: True\n",
      "Layer: conv2.att_src, Frozen: True\n",
      "Layer: conv2.att_dst, Frozen: True\n",
      "Layer: conv2.bias, Frozen: True\n",
      "Layer: conv2.lin_src.weight, Frozen: True\n",
      "Layer: edge_mlp2.mlp.0.weight, Frozen: False\n",
      "Layer: edge_mlp2.mlp.0.bias, Frozen: False\n",
      "Layer: edge_mlp2.mlp.2.weight, Frozen: False\n",
      "Layer: edge_mlp2.mlp.2.bias, Frozen: False\n",
      "Layer: edge_mlp2.mlp.4.weight, Frozen: False\n",
      "Layer: edge_mlp2.mlp.4.bias, Frozen: False\n",
      "Layer: conv3.bias, Frozen: False\n",
      "Layer: conv3.lin.weight, Frozen: False\n",
      "Layer: conv4.att_src, Frozen: False\n",
      "Layer: conv4.att_dst, Frozen: False\n",
      "Layer: conv4.bias, Frozen: False\n",
      "Layer: conv4.lin_src.weight, Frozen: False\n",
      "Layer: fc1.weight, Frozen: False\n",
      "Layer: fc1.bias, Frozen: False\n",
      "Layer: fc2.weight, Frozen: False\n",
      "Layer: fc2.bias, Frozen: False\n"
     ]
    }
   ],
   "source": [
    "num_edge_features = 1\n",
    "prev_channels = 64\n",
    "hidden_channels = 128\n",
    "out_channels = 64\n",
    "fc_channels = 32\n",
    "\n",
    "unfrozen_model = seizure_detection1(num_edge_features=num_edge_features, prev_channels=prev_channels, hidden_channels=hidden_channels, \n",
    "                          out_channels=out_channels, fc_channels=fc_channels)\n",
    "\n",
    "frozen_model = seizure_detection2(num_edge_features=num_edge_features, prev_channels=prev_channels, hidden_channels=hidden_channels, \n",
    "                          out_channels=out_channels, fc_channels=fc_channels)\n",
    "\n",
    "for name, param in unfrozen_model.named_parameters():\n",
    "    print(f\"Layer: {name}, Frozen: {not param.requires_grad}\")\n",
    "print(\"----------------------------------------------------\")    \n",
    "for name, param in frozen_model.named_parameters():\n",
    "    print(f\"Layer: {name}, Frozen: {not param.requires_grad}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Step 4: Fine-Tuning for Seizure Detection"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "torch2_cuda11.8",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
