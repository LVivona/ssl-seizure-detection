{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Graph Classification Models\n",
    "This notebook serves as a tutorial for working with graph classifications in PyTorch Geometric (PyG), namely graph pair classification models (i.e. single label for a pair of graphs)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Enable GPU/MPS\n",
    "If you have a GPU or a Silicon based Mac, then we can enable hardware acceleration for PyTorch with the following.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Intel MKL WARNING: Support of Intel(R) Streaming SIMD Extensions 4.2 (Intel(R) SSE4.2) enabled only processors has been deprecated. Intel oneAPI Math Kernel Library 2025.0 will require Intel(R) Advanced Vector Extensions (Intel(R) AVX) instructions.\n",
      "Intel MKL WARNING: Support of Intel(R) Streaming SIMD Extensions 4.2 (Intel(R) SSE4.2) enabled only processors has been deprecated. Intel oneAPI Math Kernel Library 2025.0 will require Intel(R) Advanced Vector Extensions (Intel(R) AVX) instructions.\n",
      "Using device: cpu\n"
     ]
    }
   ],
   "source": [
    "# Setup GPU\n",
    "import sys\n",
    "sys.path.append(\"../src\")\n",
    "\n",
    "import torch\n",
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "print(f\"Using device: {device}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "For Macs, if you want to check whether MPS-acceleration is enabled, this is how (should print `True` for both)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "True\n",
      "True\n"
     ]
    }
   ],
   "source": [
    "print(torch.backends.mps.is_available()) #the MacOS is higher than 12.3+\n",
    "print(torch.backends.mps.is_built()) #MPS is activated"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Graph Structures\n",
    "PyG uses a class called `Data` (namely [`torch_geometric.data.Data`](https://pytorch-geometric.readthedocs.io/en/latest/generated/torch_geometric.data.Data.html)) to represent graph structures. This `Data` object consists of an `edge_index`, a torch tensor of shape `[2, num_edges]` where each column $[i \\ \\ j]^T$ represents a directed edge point from node $i$ to node $j$. The second component of `Data` are the node features notated as `x`, a torch tensor of shape `[num_nodes, num_node_features]`, and third component are the edge features are stored in the torch tensor `edge_attr` of shape `[num_edges, num_edge_features]` where its indices follow the columns of `edge_index`; that is, the 3rd column in `edge_index` is the 3rd entry of `edge_attr`, and so on."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "from torch_geometric.data import Data\n",
    "\n",
    "# Edges\n",
    "edge_index = torch.tensor([[0, 1, 1, 2],\n",
    "                           [1, 0, 2, 1]], dtype=torch.long)\n",
    "\n",
    "# Node features\n",
    "x = torch.tensor([[-1], [0], [1]], dtype=torch.float32)\n",
    "\n",
    "# Edge features\n",
    "edge_attr = torch.tensor([[1, 1, 2, 2]], dtype=torch.float32)\n",
    "edge_attr = edge_attr.T\n",
    "\n",
    "# Graph Label\n",
    "y = torch.tensor([0], dtype=torch.long)\n",
    "\n",
    "# We store each graph in a Data object. This Data object is customizable in its attributes.\n",
    "data = Data(x=x, edge_index=edge_index, edge_attr=edge_attr, y=y)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can call certain attributes of our `Data` object such as the number of nodes and number of edge features, and much more."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "dict_keys(['x', 'edge_index', 'edge_attr', 'y'])\n",
      "Number of nodes: 3\n",
      "Number of edges: 4\n",
      "Number of node features: 1\n",
      "Number of edge features: 1\n"
     ]
    }
   ],
   "source": [
    "# Descriptive data of the Data object\n",
    "print((data.to_dict()).keys())\n",
    "print(\"Number of nodes:\", data.num_nodes)\n",
    "print(\"Number of edges:\", data.num_edges)\n",
    "print(\"Number of node features:\", data.num_node_features)\n",
    "print(\"Number of edge features:\", data.num_edge_features)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Once we've loaded all our graph representations into their respctive `Data` objects, we'll place them in a list, and use a special `DataLoader` from PyG to handle our data. This is important to use the PyG `DataLoader` and not the native torch `DataLoader` as it can handle batching of graphs much more efficiently."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Node features:\n",
      "tensor([[-1.],\n",
      "        [ 0.],\n",
      "        [ 1.],\n",
      "        [-1.],\n",
      "        [ 0.],\n",
      "        [ 1.]])\n",
      "Edge index:\n",
      "tensor([[0, 1, 1, 2, 3, 4, 4, 5],\n",
      "        [1, 0, 2, 1, 4, 3, 5, 4]])\n",
      "Edge features:\n",
      "tensor([[1.],\n",
      "        [1.],\n",
      "        [2.],\n",
      "        [2.],\n",
      "        [1.],\n",
      "        [1.],\n",
      "        [2.],\n",
      "        [2.]])\n",
      "Batch objects which tracks which nodes belong to which graph:\n",
      "tensor([0, 0, 0, 1, 1, 1])\n",
      "Graph labels:\n",
      "tensor([0, 0])\n"
     ]
    }
   ],
   "source": [
    "from torch_geometric.loader import DataLoader\n",
    "\n",
    "# Load Data objects into a list\n",
    "data_list = [data, data, data, data]\n",
    "\n",
    "# Load data list into a DataLoader object\n",
    "loader = DataLoader(data_list, batch_size = 2)\n",
    "\n",
    "# Print out objects for a single batch (2 graphs)\n",
    "for batch in loader:\n",
    "  print(\"Node features:\")\n",
    "  print(batch.x)\n",
    "  print(\"Edge index:\")\n",
    "  print(batch.edge_index)\n",
    "  print(\"Edge features:\")\n",
    "  print(batch.edge_attr)\n",
    "  print(\"Batch objects which tracks which nodes belong to which graph:\")\n",
    "  print(batch.batch)\n",
    "  print(\"Graph labels:\")\n",
    "  print(batch.y)\n",
    "  break"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Binary Classification\n",
    "Below is an example of a binary classifier using a Graph Convolutional Network (GCN), which includes two `GCNConv` layers from [`conv.GCNConv`](https://pytorch-geometric.readthedocs.io/en/latest/generated/torch_geometric.nn.conv.GCNConv.html#torch_geometric.nn.conv.GCNConv)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# A simple GCN model which only takes in two graphs\n",
    "import torch\n",
    "import torch.nn.functional as F\n",
    "from torch.nn import Sequential, Linear, ReLU\n",
    "from torch_geometric.nn import GCNConv, global_mean_pool\n",
    "\n",
    "class GraphClassifier(torch.nn.Module):\n",
    "    def __init__(self, num_node_features, num_edge_features):\n",
    "        super(GraphClassifier, self).__init__()\n",
    "\n",
    "        # Node feature transformation layers\n",
    "        self.conv1 = GCNConv(num_node_features, 64)\n",
    "        self.conv2 = GCNConv(64, 128)\n",
    "        \n",
    "        # Readout layer\n",
    "        self.readout = global_mean_pool\n",
    "\n",
    "        # Classifier\n",
    "        self.classifier = Linear(128, 1)\n",
    "\n",
    "    def forward(self, x, edge_index, edge_attr, batch):\n",
    "        # Update node features\n",
    "        x = self.conv1(x, edge_index)\n",
    "        x = F.relu(x)\n",
    "        x = self.conv2(x, edge_index)\n",
    "        x = F.relu(x)\n",
    "\n",
    "        # Readout layer to get graph-level representation\n",
    "        x = self.readout(x, batch)  # <-- Use the batch vector here\n",
    "\n",
    "        # Classifier to predict the graph label\n",
    "        x = self.classifier(x)\n",
    "        x = torch.sigmoid(x)\n",
    "\n",
    "        return x.squeeze(-1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Training\n",
    "To train in PyG it's the essentially the same as training in regular PyTorch with a few caveats. We initialize the model, optimizer, and loss; then we run the training loop over a certain number of epochs and iterate of the batches in the `DataLoader`. The difference here is that we are using the `batch._` format for the inputs (you could also just modify the model to split up this batch object accordingly). What is *very* important is the `batch.batch` object which tracks which nodes correspond to which graphs in our batch, i.e. a value of $5$ would correspond to the 6th graph in our batch, and it tells the GNN how to perform batch operations properly, such as global mean pooling."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 1, Loss: 0.6771679520606995\n",
      "Epoch: 2, Loss: 0.5609591603279114\n",
      "Epoch: 3, Loss: 0.38505038619041443\n",
      "Epoch: 4, Loss: 0.18876181542873383\n",
      "Epoch: 5, Loss: 0.0562790110707283\n",
      "Epoch: 6, Loss: 0.010304301045835018\n",
      "Epoch: 7, Loss: 0.0014619937865063548\n",
      "Epoch: 8, Loss: 0.00019777602574322373\n",
      "Epoch: 9, Loss: 2.8484399081207812e-05\n",
      "Epoch: 10, Loss: 4.6508216655638535e-06\n",
      "Epoch: 11, Loss: 8.904502806217351e-07\n",
      "Epoch: 12, Loss: 2.0218260488036321e-07\n",
      "Epoch: 13, Loss: 5.459987661993182e-08\n",
      "Epoch: 14, Loss: 1.743337207926743e-08\n",
      "Epoch: 15, Loss: 6.495862514555029e-09\n",
      "Epoch: 16, Loss: 2.779728669466408e-09\n",
      "Epoch: 17, Loss: 1.3469956261502603e-09\n",
      "Epoch: 18, Loss: 7.284987613154215e-10\n",
      "Epoch: 19, Loss: 4.333319814087133e-10\n"
     ]
    }
   ],
   "source": [
    "# Initialize model\n",
    "model = GraphClassifier(num_node_features=1, num_edge_features=1).to(device)\n",
    "optimizer = torch.optim.Adam(model.parameters(), lr=0.01)\n",
    "criterion = torch.nn.BCELoss().to(device)\n",
    "\n",
    "# Training loop\n",
    "for epoch in range(1, 20):\n",
    "    for batch in loader:\n",
    "        \n",
    "        # Move batch to GPU\n",
    "        batch.x = batch.x.to(device)\n",
    "        batch.edge_index = batch.edge_index.to(device)\n",
    "        batch.edge_attr = batch.edge_attr.to(device)\n",
    "        batch.y = batch.y.to(device)\n",
    "        batch.batch = batch.batch.to(device)\n",
    "        \n",
    "        optimizer.zero_grad()\n",
    "        \n",
    "        out = model(batch.x, batch.edge_index, batch.edge_attr, batch.batch)\n",
    "        loss = criterion(out, batch.y.float())\n",
    "        \n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "    print(f'Epoch: {epoch}, Loss: {loss.item()}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Multiclass Classification\n",
    "Let's try out the main model we'll be using in BRAINGREG, which is given by `supervised_model` in `models.py`. We'll also test the data for the multiclass classification setting, so our label $y$ is no longer binary, it is a multiclass label encoded as a 3D one-hot vector $\\vec{y}\\in\\R^3$."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "from torch_geometric.data import Data\n",
    "\n",
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "\n",
    "# Edges\n",
    "edge_index = torch.tensor([[0, 1, 1, 2],\n",
    "                           [1, 0, 2, 1]], dtype=torch.long)\n",
    "\n",
    "# Node features\n",
    "x = torch.tensor([[-1], [0], [1]], dtype=torch.float32)\n",
    "\n",
    "# Edge features\n",
    "edge_attr = torch.tensor([[1, 1, 2, 2]], dtype=torch.float32)\n",
    "\n",
    "edge_attr = edge_attr.T\n",
    "\n",
    "# Graph Label\n",
    "y = torch.tensor(2, dtype=torch.long)\n",
    "\n",
    "# We store each graph in a Data object. This Data object is customizable in its attributes.\n",
    "data = Data(x=x, edge_index=edge_index, edge_attr=edge_attr, y=y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "from torch_geometric.loader import DataLoader\n",
    "\n",
    "# Load Data objects into a list\n",
    "data_list = [data, data, data, data]\n",
    "\n",
    "# Load data list into a DataLoader object\n",
    "loader = DataLoader(data_list, batch_size = 2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([8, 1])\n",
      "tensor([2, 2])\n",
      "torch.Size([8, 1])\n",
      "tensor([2, 2])\n"
     ]
    }
   ],
   "source": [
    "for batch in loader:\n",
    "  print((batch.edge_attr).shape)\n",
    "  print(batch.y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 1, Loss: 0.943538248538971\n",
      "Epoch: 2, Loss: 0.6356375217437744\n",
      "Epoch: 3, Loss: 0.55167156457901\n",
      "Epoch: 4, Loss: 0.5514447093009949\n",
      "Epoch: 5, Loss: 0.5514447093009949\n",
      "Epoch: 6, Loss: 0.5514447093009949\n",
      "Epoch: 7, Loss: 0.5514447093009949\n",
      "Epoch: 8, Loss: 0.5514447093009949\n",
      "Epoch: 9, Loss: 0.5514447093009949\n",
      "Epoch: 10, Loss: 0.5514447093009949\n",
      "Epoch: 11, Loss: 0.5514447093009949\n",
      "Epoch: 12, Loss: 0.5514447093009949\n",
      "Epoch: 13, Loss: 0.5514447093009949\n",
      "Epoch: 14, Loss: 0.5514447093009949\n",
      "Epoch: 15, Loss: 0.5514447093009949\n",
      "Epoch: 16, Loss: 0.5514447093009949\n",
      "Epoch: 17, Loss: 0.5514447093009949\n",
      "Epoch: 18, Loss: 0.5514447093009949\n",
      "Epoch: 19, Loss: 0.5514447093009949\n",
      "Epoch: 20, Loss: 0.5514447093009949\n",
      "Epoch: 21, Loss: 0.5514447093009949\n",
      "Epoch: 22, Loss: 0.5514447093009949\n",
      "Epoch: 23, Loss: 0.5514447093009949\n",
      "Epoch: 24, Loss: 0.5514447093009949\n",
      "Epoch: 25, Loss: 0.5514447093009949\n",
      "Epoch: 26, Loss: 0.5514447093009949\n",
      "Epoch: 27, Loss: 0.5514447093009949\n",
      "Epoch: 28, Loss: 0.5514447093009949\n",
      "Epoch: 29, Loss: 0.5514447093009949\n",
      "Epoch: 30, Loss: 0.5514447093009949\n",
      "Epoch: 31, Loss: 0.5514447093009949\n",
      "Epoch: 32, Loss: 0.5514447093009949\n",
      "Epoch: 33, Loss: 0.5514447093009949\n",
      "Epoch: 34, Loss: 0.5514447093009949\n",
      "Epoch: 35, Loss: 0.5514447093009949\n",
      "Epoch: 36, Loss: 0.5514447093009949\n",
      "Epoch: 37, Loss: 0.5514447093009949\n",
      "Epoch: 38, Loss: 0.5514447093009949\n",
      "Epoch: 39, Loss: 0.5514447093009949\n",
      "Epoch: 40, Loss: 0.5514447093009949\n",
      "Epoch: 41, Loss: 0.5514447093009949\n",
      "Epoch: 42, Loss: 0.5514447093009949\n",
      "Epoch: 43, Loss: 0.5514447093009949\n",
      "Epoch: 44, Loss: 0.5514447093009949\n",
      "Epoch: 45, Loss: 0.5514447093009949\n",
      "Epoch: 46, Loss: 0.5514447093009949\n",
      "Epoch: 47, Loss: 0.5514447093009949\n",
      "Epoch: 48, Loss: 0.5514447093009949\n",
      "Epoch: 49, Loss: 0.5514447093009949\n",
      "Epoch: 50, Loss: 0.5514447093009949\n",
      "Epoch: 51, Loss: 0.5514447093009949\n",
      "Epoch: 52, Loss: 0.5514447093009949\n",
      "Epoch: 53, Loss: 0.5514447093009949\n",
      "Epoch: 54, Loss: 0.5514447093009949\n",
      "Epoch: 55, Loss: 0.5514447093009949\n",
      "Epoch: 56, Loss: 0.5514447093009949\n",
      "Epoch: 57, Loss: 0.5514447093009949\n",
      "Epoch: 58, Loss: 0.5514447093009949\n",
      "Epoch: 59, Loss: 0.5514447093009949\n",
      "Epoch: 60, Loss: 0.5514447093009949\n",
      "Epoch: 61, Loss: 0.5514447093009949\n",
      "Epoch: 62, Loss: 0.5514447093009949\n",
      "Epoch: 63, Loss: 0.5514447093009949\n",
      "Epoch: 64, Loss: 0.5514447093009949\n",
      "Epoch: 65, Loss: 0.5514447093009949\n",
      "Epoch: 66, Loss: 0.5514447093009949\n",
      "Epoch: 67, Loss: 0.5514447093009949\n",
      "Epoch: 68, Loss: 0.5514447093009949\n",
      "Epoch: 69, Loss: 0.5514447093009949\n",
      "Epoch: 70, Loss: 0.5514447093009949\n",
      "Epoch: 71, Loss: 0.5514447093009949\n",
      "Epoch: 72, Loss: 0.5514447093009949\n",
      "Epoch: 73, Loss: 0.5514447093009949\n",
      "Epoch: 74, Loss: 0.5514447093009949\n",
      "Epoch: 75, Loss: 0.5514447093009949\n",
      "Epoch: 76, Loss: 0.5514447093009949\n",
      "Epoch: 77, Loss: 0.5514447093009949\n",
      "Epoch: 78, Loss: 0.5514447093009949\n",
      "Epoch: 79, Loss: 0.5514447093009949\n",
      "Epoch: 80, Loss: 0.5514447093009949\n",
      "Epoch: 81, Loss: 0.5514447093009949\n",
      "Epoch: 82, Loss: 0.5514447093009949\n",
      "Epoch: 83, Loss: 0.5514447093009949\n",
      "Epoch: 84, Loss: 0.5514447093009949\n",
      "Epoch: 85, Loss: 0.5514447093009949\n",
      "Epoch: 86, Loss: 0.5514447093009949\n",
      "Epoch: 87, Loss: 0.5514447093009949\n",
      "Epoch: 88, Loss: 0.5514447093009949\n",
      "Epoch: 89, Loss: 0.5514447093009949\n",
      "Epoch: 90, Loss: 0.5514447093009949\n",
      "Epoch: 91, Loss: 0.5514447093009949\n",
      "Epoch: 92, Loss: 0.5514447093009949\n",
      "Epoch: 93, Loss: 0.5514447093009949\n",
      "Epoch: 94, Loss: 0.5514447093009949\n",
      "Epoch: 95, Loss: 0.5514447093009949\n",
      "Epoch: 96, Loss: 0.5514447093009949\n",
      "Epoch: 97, Loss: 0.5514447093009949\n",
      "Epoch: 98, Loss: 0.5514447093009949\n",
      "Epoch: 99, Loss: 0.5514447093009949\n"
     ]
    }
   ],
   "source": [
    "from models import supervised_model\n",
    "\n",
    "# Initialize model\n",
    "model = supervised_model(num_node_features=1, num_edge_features=1, hidden_channels=64, out_channels=32, dropout=0.05).to(device)\n",
    "optimizer = torch.optim.Adam(model.parameters(), lr=0.01)\n",
    "criterion = torch.nn.CrossEntropyLoss().to(device)\n",
    "\n",
    "# Training loop\n",
    "for epoch in range(1, 100):\n",
    "    for batch in loader:\n",
    "        \n",
    "        # Move batch to GPU\n",
    "        batch.x = batch.x.to(device)\n",
    "        batch.edge_index = batch.edge_index.to(device)\n",
    "        batch.edge_attr = batch.edge_attr.to(device)\n",
    "        batch.y = batch.y.to(device)\n",
    "        batch.batch = batch.batch.to(device)\n",
    "        \n",
    "        optimizer.zero_grad()\n",
    "\n",
    "        out = model(batch.x, batch.edge_index, batch.edge_attr, batch.batch, classify=\"multi\", dropout=True)\n",
    "        loss = criterion(out, batch.y)\n",
    "        \n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "    print(f'Epoch: {epoch}, Loss: {loss.item()}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Graph Pair Classification"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "If you're interested in graph pair models, where each example in the batch is now a *pair* of graphs and we're trying to predict their graph pair label, then we have to create a custom class `PairData` that inherits from the `torch_geometric.data.Data` class."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Load the graph representations into a `PairData` class."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[0.],\n",
      "        [1.],\n",
      "        [2.],\n",
      "        [3.],\n",
      "        [4.],\n",
      "        [5.]])\n"
     ]
    }
   ],
   "source": [
    "from preprocess import PairData\n",
    "\n",
    "# Node features of shape (num_nodes, num_node_features) and type torch.float32\n",
    "x1 = torch.tensor([[0, 0, 0],\n",
    "                    [1, 1, 1],\n",
    "                    [2, 2, 2],\n",
    "                    [3, 3, 3]], dtype=torch.float32)\n",
    "x2 = torch.tensor([[4, 4, 4],\n",
    "                    [5, 5, 5],\n",
    "                    [6, 6, 6]], dtype=torch.float32)\n",
    "\n",
    "# Edge indices of shape (2, num_edges) and type torch.long\n",
    "edge_index1 = torch.tensor([[0, 1, 1, 2, 2, 3],\n",
    "                             [1, 0, 2, 1, 3, 2]], dtype=torch.long)\n",
    "edge_index2 = torch.tensor([[0, 1, 1, 2],\n",
    "                             [1, 0, 2, 1]], dtype=torch.long)\n",
    "\n",
    "# Edge features of shape (num_edges, num_edge_features) and type torch.float32\n",
    "edge_attr1 = torch.tensor([[0],\n",
    "                            [1],\n",
    "                            [2],\n",
    "                            [3],\n",
    "                            [4],\n",
    "                            [5]], dtype=torch.float32)\n",
    "edge_attr2 = torch.tensor([[6],\n",
    "                            [7],\n",
    "                            [8],\n",
    "                            [9]], dtype=torch.float32)\n",
    "\n",
    "# Pair label of shape (1,) and type torch.long\n",
    "y = torch.tensor([1], dtype=torch.float32)\n",
    "\n",
    "data = PairData(x1=x1, edge_index1=edge_index1, edge_attr1=edge_attr1,  # Graph 1.\n",
    "                x2=x2, edge_index2=edge_index2, edge_attr2=edge_attr2,  # Graph 2.\n",
    "                y=y) #Graph pair label. \n",
    "\n",
    "print(data.edge_attr1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### DataLoader for Graph Pairs\n",
    "We can use the `torch_geometric.loader.Dataloader` to load our list of `PairData` objects, except we use an additional argument of `follow_batch=['x1', 'x2']`, which allows us to correctly identify the graph pairs in our batch."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[4., 4., 4.],\n",
      "        [5., 5., 5.],\n",
      "        [6., 6., 6.],\n",
      "        [4., 4., 4.],\n",
      "        [5., 5., 5.],\n",
      "        [6., 6., 6.]])\n",
      "tensor([1., 1.])\n",
      "Which nodes correspond to which graph: tensor([0, 0, 0, 0, 1, 1, 1, 1])\n",
      "Which nodes correspond to which graph: tensor([0, 0, 0, 1, 1, 1])\n",
      "tensor([[4., 4., 4.],\n",
      "        [5., 5., 5.],\n",
      "        [6., 6., 6.]])\n",
      "tensor([1.])\n",
      "Which nodes correspond to which graph: tensor([0, 0, 0, 0])\n",
      "Which nodes correspond to which graph: tensor([0, 0, 0])\n"
     ]
    }
   ],
   "source": [
    "# Dataloader for pairs of graphs\n",
    "from torch_geometric.loader import DataLoader\n",
    "from torch_geometric.data import Batch\n",
    "\n",
    "# We will have our list of graphs in the form of Data objects\n",
    "data_list = [data, data, data]\n",
    "\n",
    "# Create the dataloader. The follow_batch tells the dataloader which nodes belong to which graph in this \n",
    "# giant disconnected graph that the batch creates. We can typically split the data_list into train, val, test and then \n",
    "# create individual loaders correspondingly.\n",
    "pair_loader = DataLoader(data_list, batch_size=2, follow_batch=['x1', 'x2'])\n",
    "\n",
    "\n",
    "# We can iterate through batches with the following. Each batch is a data.Batch() object\n",
    "for batch in pair_loader:\n",
    "    inputs = ((batch.x1, batch.edge_index1, batch.edge_attr1), (batch.x2, batch.edge_index2, batch.edge_attr2))\n",
    "    graph_1, graph_2 = inputs\n",
    "    labels = batch.y\n",
    "    print(batch.x2)\n",
    "    print(labels)\n",
    "    print(\"Which nodes correspond to which graph:\", batch.x1_batch)\n",
    "    print(\"Which nodes correspond to which graph:\", batch.x2_batch)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### GCN Model for Graph Pairs\n",
    "We use a simple GCN model for graph pairs, same as before."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Simple graph pair classifier\n",
    "class PairGraphClassifier(torch.nn.Module):\n",
    "    def __init__(self, num_node_features, num_edge_features):\n",
    "        super(PairGraphClassifier, self).__init__()\n",
    "\n",
    "        # Node feature transformation layers\n",
    "        self.conv1 = GCNConv(num_node_features, 64)\n",
    "        self.conv2 = GCNConv(64, 128)\n",
    "\n",
    "        # Edge feature transformation layers\n",
    "        self.edge_mlp = Sequential(Linear(num_edge_features, 32),\n",
    "                                   ReLU(),\n",
    "                                   Linear(32, 64))\n",
    "\n",
    "        # Classifier\n",
    "        self.classifier = Linear(256, 1)  # 128 features from each graph\n",
    "\n",
    "    def forward_one(self, x, edge_index, edge_attr, batch):\n",
    "        x = self.conv1(x, edge_index)\n",
    "        x = F.relu(x)\n",
    "        x = self.conv2(x, edge_index)\n",
    "        x = F.relu(x)\n",
    "\n",
    "        edge_attr = self.edge_mlp(edge_attr)\n",
    "        x = global_mean_pool(x, batch)  # Use batch vector for separate pooling\n",
    "        return x\n",
    "\n",
    "    def forward(self, x_1, edge_index1, edge_attr1, batch1, x2, edge_index2, edge_attr2, batch2):\n",
    "        \n",
    "        x_1 = self.forward_one(x_1, edge_index1, edge_attr1, batch1)\n",
    "        x2 = self.forward_one(x2, edge_index2, edge_attr2, batch2)\n",
    "\n",
    "        x = torch.cat([x_1, x2], dim=1)\n",
    "        x = self.classifier(x)\n",
    "        x = torch.sigmoid(x)\n",
    "\n",
    "        return x.squeeze(-1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Train the graph pair model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 1, Loss: 0.18142934143543243\n",
      "Epoch: 2, Loss: 0.008289927616715431\n",
      "Epoch: 3, Loss: 0.00026128129684366286\n",
      "Epoch: 4, Loss: 8.821526535029989e-06\n",
      "Epoch: 5, Loss: 3.576279254957626e-07\n",
      "Epoch: 6, Loss: 0.0\n",
      "Epoch: 7, Loss: 0.0\n",
      "Epoch: 8, Loss: 0.0\n",
      "Epoch: 9, Loss: 0.0\n",
      "Epoch: 10, Loss: 0.0\n",
      "Epoch: 11, Loss: 0.0\n",
      "Epoch: 12, Loss: 0.0\n",
      "Epoch: 13, Loss: 0.0\n",
      "Epoch: 14, Loss: 0.0\n",
      "Epoch: 15, Loss: 0.0\n",
      "Epoch: 16, Loss: 0.0\n",
      "Epoch: 17, Loss: 0.0\n",
      "Epoch: 18, Loss: 0.0\n",
      "Epoch: 19, Loss: 0.0\n",
      "We have a graph pair model working!!!\n"
     ]
    }
   ],
   "source": [
    "# Initialize device\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "\n",
    "# Initialize model\n",
    "model = PairGraphClassifier(num_node_features=3, num_edge_features=1)\n",
    "model.to(device)\n",
    "optimizer = torch.optim.Adam(model.parameters(), lr=0.01)\n",
    "criterion = torch.nn.BCELoss()\n",
    "criterion.to(device)\n",
    "\n",
    "# Training loop\n",
    "for epoch in range(1, 20):\n",
    "    for batch in pair_loader:\n",
    "        # Move batch data to the device\n",
    "        batch.x1 = batch.x1.to(device)\n",
    "        batch.edge_index1 = batch.edge_index1.to(device)\n",
    "        batch.edge_attr1 = batch.edge_attr1.to(device)\n",
    "        batch.x1_batch = batch.x1_batch.to(device)\n",
    "        \n",
    "        batch.x2 = batch.x2.to(device)\n",
    "        batch.edge_index2 = batch.edge_index2.to(device)\n",
    "        batch.edge_attr2 = batch.edge_attr2.to(device)\n",
    "        batch.x2_batch = batch.x2_batch.to(device)\n",
    "        \n",
    "        batch.y = batch.y.to(device)\n",
    "\n",
    "        optimizer.zero_grad()\n",
    "        \n",
    "        out = model(batch.x1, batch.edge_index1, batch.edge_attr1, batch.x1_batch,\n",
    "                    batch.x2, batch.edge_index2, batch.edge_attr2, batch.x2_batch)\n",
    "        loss = criterion(out, batch.y)\n",
    "        \n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        \n",
    "    print(f'Epoch: {epoch}, Loss: {loss.item()}')\n",
    "print(\"We have a graph pair model working!!!\")\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
