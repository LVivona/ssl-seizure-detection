{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Intel MKL WARNING: Support of Intel(R) Streaming SIMD Extensions 4.2 (Intel(R) SSE4.2) enabled only processors has been deprecated. Intel oneAPI Math Kernel Library 2025.0 will require Intel(R) Advanced Vector Extensions (Intel(R) AVX) instructions.\n",
      "Intel MKL WARNING: Support of Intel(R) Streaming SIMD Extensions 4.2 (Intel(R) SSE4.2) enabled only processors has been deprecated. Intel oneAPI Math Kernel Library 2025.0 will require Intel(R) Advanced Vector Extensions (Intel(R) AVX) instructions.\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import pickle\n",
    "import sys\n",
    "import torch\n",
    "sys.path.append(\"../src\")\n",
    "from preprocess import new_grs, create_tensordata_new, convert_to_Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "path_ictal = \"/Users/xaviermootoo/Documents/Data/ssl-seizure-detection/patient_gr/jh101/ictal_1.pickle\"\n",
    "path_preictal = \"/Users/xaviermootoo/Documents/Data/ssl-seizure-detection/patient_gr/jh101/preictal_1.pickle\"\n",
    "path_postical = \"/Users/xaviermootoo/Documents/Data/ssl-seizure-detection/patient_gr/jh101/postictal_1.pickle\"\n",
    "\n",
    "data_preictal = pickle.load(open(path_preictal, 'rb'))\n",
    "data_ictal = pickle.load(open(path_ictal, 'rb'))\n",
    "data_postictal = pickle.load(open(path_postical, 'rb'))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Structure\n",
    "List with entries of the form `graph = [A, NF, EF]`. Where `A`, `NF`, and `EF` are lists of length 4, 3, and 4 respectively. \n",
    "\n",
    "`A = [A0, A1, A2, A3]`, where :\n",
    "-   `A0` = Ones, shape `(107,107)`.\n",
    "-   `A1` = Correlation, shape `(107,107)`.  \n",
    "-   `A2` = Coherence, shape `(107,107)`.\n",
    "-   `A3` = Phase, shape `(107,107)`.\n",
    "\n",
    "`NF = [NF0, NF1, NF2]`, where:\n",
    "\n",
    "-  `NF0` = Ones, shape `(107,1)`.\n",
    "-  `NF1` = Average Energy, shape `(107,1)`.\n",
    "-  `NF2` = Band Energy, shape `(107,8)`.\n",
    "\n",
    "\n",
    "`EF = [EF0, EF1, EF2, EF3]`, where:\n",
    "\n",
    "-  `EF0` = Ones, shape `(107,107,1)`.\n",
    "-  `EF1` = Correlation, shape `(107,107,1)`.\n",
    "-  `EF2` = Coherence, shape `(107,107,1)`.\n",
    "-  `EF3` = Phase, shape `(107,107,1)`.\n",
    "\n",
    "All the information above has been (experimentally) confirmed by the above and Alan's documentation of `get_nf`, `get_adj`, and `get_ef` helper functions in his `load_data()` function, but should talk to Alan about confirming these details for absolute certainty."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "A0 = E0 for first graph? True.\n",
      "A1 = E1 for first graph? True.\n",
      "A2 = E2 for first graph? True.\n",
      "A3 = E3 for first graph? True.\n"
     ]
    }
   ],
   "source": [
    "print(f\"A0 = E0 for first graph? {np.array_equal(data[0][0][0], data[0][2][0].reshape(107, 107))}.\")\n",
    "print(f\"A1 = E1 for first graph? {np.array_equal(data[0][0][1], data[0][2][1].reshape(107, 107))}.\")\n",
    "print(f\"A2 = E2 for first graph? {np.array_equal(data[0][0][2], data[0][2][2].reshape(107, 107))}.\")\n",
    "print(f\"A3 = E3 for first graph? {np.array_equal(data[0][0][3], data[0][2][3].reshape(107, 107))}.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Temporal Concatenation\n",
    "For each run, we are going to concatenate the features in a larger list of `[preictal, ictal, postictal]`. We're then going to feed this into the `preprocess.ipynb` pipeline we've created (or just using one big patch). For simplicity we're going to use the most extensive graph representation possible by using:\n",
    "-  `A` = None\n",
    "-  `NF` = Average Energy and Band Energy, shape `(107,9)`.\n",
    "-  `EF` = Correlation, Coherence, Phase, shape `(107, 107, 3)`.\n",
    "\n",
    "for each patient."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We'll call this new list of graph representations `new_data`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "from preprocess import new_grs\n",
    "\n",
    "# Make new data for each class\n",
    "new_data_preictal = new_grs(data_preictal, type=\"preictal\", mode=\"binary\")\n",
    "new_data_ictal = new_grs(data_ictal, type=\"ictal\", mode=\"binary\")\n",
    "new_data_postictal = new_grs(data_postictal, type=\"postictal\", mode=\"binary\")\n",
    "\n",
    "# Concatenate all data temporally\n",
    "new_data = new_data_preictal + new_data_ictal + new_data_postictal"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now we'll convert `new_data` to `pyg_data` so it is in tensor format."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We'll name this new list of torch tensors with entries `[[edge_index, x, edge_attr], y]` as `pyg_grs`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "pyg_grs = create_tensordata_new(num_nodes=107, data_list=new_data, complete=True, save=False, logdir=None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of examples: 455510\n",
      "y\n",
      "1    227755\n",
      "0    227755\n",
      "Name: count, dtype: int64\n"
     ]
    }
   ],
   "source": [
    "import sys\n",
    "import torch\n",
    "sys.path.append(\"../src\")\n",
    "from preprocess import pseudo_data\n",
    "\n",
    "pyg_grs = torch.load(\"/Users/xaviermootoo/Documents/VScode/ssl-seizure-detection/pyg_grs.pt\")\n",
    "pdata = pseudo_data(pyg_grs, tau_pos = 12 // 0.12, tau_neg = (75) // 0.12, stats = True, save = False, patientid = \"patient\", \n",
    "                    logdir = None, model = \"temporal_shuffling\", sample_ratio=0.10)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "After this we then convert the list of tensor `pyg_grs` to the PyG data structure `torch_geometric.data.Data`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "Data_list = convert_to_Data(pyg_grs, save=False, logdir=None)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The rest is up to `preprocess.ipynb` to handle..."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "sys.path.append(\"../src\")\n",
    "import torch\n",
    "from new_patch import patch\n",
    "\n",
    "# Test case\n",
    "path_ictal = \"/Users/xaviermootoo/Documents/Data/ssl-seizure-detection/patient_gr/jh101/ictal_1.pickle\"\n",
    "path_preictal = \"/Users/xaviermootoo/Documents/Data/ssl-seizure-detection/patient_gr/jh101/preictal_1.pickle\"\n",
    "path_postical = \"/Users/xaviermootoo/Documents/Data/ssl-seizure-detection/patient_gr/jh101/postictal_1.pickle\"\n",
    "\n",
    "graphrep_dir = [path_preictal, path_ictal, path_postical]\n",
    "logdir = \"/Users/xaviermootoo/Documents/Data/ssl-seizure-detection/pyg_data/jh101\"\n",
    "filename = \"jh101_run1\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "patched_data = patch(graphrep_dir=graphrep_dir,  logdir=logdir, file_name=filename, num_electrodes=107, tau_pos=12//0.12, tau_neg=(7 * 60)//0.12, \n",
    "          model=\"supervised\", stats=True, sample_ratio=1.0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of examples: 125307\n",
      "y\n",
      "1    125307\n",
      "Name: count, dtype: int64\n"
     ]
    }
   ],
   "source": [
    "patched_data_rp = patch(graphrep_dir=graphrep_dir,  logdir=logdir, file_name=filename, num_electrodes=107, tau_pos=12//0.12, tau_neg=(7 * 60)//0.12, \n",
    "          model=\"relative_positioning\", stats=True, sample_ratio=1.0)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "torch2_mps",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
