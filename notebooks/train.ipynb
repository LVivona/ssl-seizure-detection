{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\tools\\Anaconda3\\envs\\torch2_cuda11.8\\lib\\site-packages\\torch_geometric\\graphgym\\config.py:19: UserWarning: Could not define global config object. Please install 'yacs' via 'pip install yacs' in order to use GraphGym\n",
      "  warnings.warn(\"Could not define global config object. Please install \"\n",
      "c:\\tools\\Anaconda3\\envs\\torch2_cuda11.8\\lib\\site-packages\\torchaudio\\backend\\utils.py:74: UserWarning: No audio backend is available.\n",
      "  warnings.warn(\"No audio backend is available.\")\n"
     ]
    }
   ],
   "source": [
    "import sys\n",
    "sys.path.append('../src')\n",
    "from train import train"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Supervised Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "Tracking run with wandb version 0.15.12"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Run data is saved locally in <code>c:\\Users\\xmoot\\Desktop\\VSCode\\ssl-seizure-detection\\notebooks\\wandb\\run-20231019_002813-x3m62zy8</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Syncing run <strong><a href='https://wandb.ai/xmootoo/ssl-seizure-detection/runs/x3m62zy8' target=\"_blank\">patient_jh101_model_supervised</a></strong> to <a href='https://wandb.ai/xmootoo/ssl-seizure-detection' target=\"_blank\">Weights & Biases</a> (<a href='https://wandb.me/run' target=\"_blank\">docs</a>)<br/>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View project at <a href='https://wandb.ai/xmootoo/ssl-seizure-detection' target=\"_blank\">https://wandb.ai/xmootoo/ssl-seizure-detection</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View run at <a href='https://wandb.ai/xmootoo/ssl-seizure-detection/runs/x3m62zy8' target=\"_blank\">https://wandb.ai/xmootoo/ssl-seizure-detection/runs/x3m62zy8</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using device: cuda\n",
      "Total number of examples in dataset: 1113.\n",
      "Total number of examples used: 1113.\n",
      "Number of training examples: 890. Number of training batches: 28.\n",
      "Number of validation examples: 223. Number of validation batches: 7.\n",
      "Number of test examples: 112. Number of test batches: 4.\n",
      "Time elapsed after 100 batches (training): 12.176496982574463\n",
      "Time elapsed after 100 batches (evaluation): 10.492000579833984\n",
      "Epoch: 1, Train Loss: 0.3753520915550845, Train Accuracy: 86.06741573033707, Validation Loss: 0.44631307891436983, Validation Accuracy: 79.37219730941705\n",
      "Time elapsed after 100 batches (training): 11.137999057769775\n",
      "Time elapsed after 100 batches (evaluation): 10.601998567581177\n",
      "Epoch: 2, Train Loss: 0.30813442622976644, Train Accuracy: 85.95505617977528, Validation Loss: 0.38933708518743515, Validation Accuracy: 81.16591928251121\n",
      "Time elapsed after 100 batches (training): 11.196998834609985\n",
      "Time elapsed after 100 batches (evaluation): 10.517999172210693\n",
      "Epoch: 3, Train Loss: 0.26618041869785103, Train Accuracy: 87.19101123595506, Validation Loss: 0.3820166843278067, Validation Accuracy: 85.65022421524664\n",
      "Time elapsed after 100 batches (training): 11.121999502182007\n",
      "Time elapsed after 100 batches (evaluation): 10.884000301361084\n",
      "Epoch: 4, Train Loss: 0.24781421172831739, Train Accuracy: 87.52808988764045, Validation Loss: 0.3800951157297407, Validation Accuracy: 86.54708520179372\n",
      "Time elapsed after 100 batches (training): 11.078499794006348\n",
      "Time elapsed after 100 batches (evaluation): 10.469999313354492\n",
      "Epoch: 5, Train Loss: 0.25726416760257315, Train Accuracy: 88.20224719101124, Validation Loss: 0.3336894416383335, Validation Accuracy: 86.54708520179372\n",
      "Time elapsed after 100 batches (training): 10.645999670028687\n",
      "Time elapsed after 100 batches (evaluation): 10.210500240325928\n",
      "Epoch: 6, Train Loss: 0.24103038518556527, Train Accuracy: 88.20224719101124, Validation Loss: 0.34371077695063185, Validation Accuracy: 85.65022421524664\n",
      "Time elapsed after 100 batches (training): 10.89199948310852\n",
      "Time elapsed after 100 batches (evaluation): 10.344499111175537\n",
      "Epoch: 7, Train Loss: 0.2326044182160071, Train Accuracy: 90.11235955056179, Validation Loss: 0.3934572956391743, Validation Accuracy: 86.54708520179372\n",
      "Time elapsed after 100 batches (training): 10.729498863220215\n",
      "Time elapsed after 100 batches (evaluation): 10.463000059127808\n",
      "Epoch: 8, Train Loss: 0.2348997596917408, Train Accuracy: 89.7752808988764, Validation Loss: 0.35920629650354385, Validation Accuracy: 86.99551569506727\n",
      "Time elapsed after 100 batches (training): 10.887003660202026\n",
      "Time elapsed after 100 batches (evaluation): 10.070500612258911\n",
      "Epoch: 9, Train Loss: 0.22972149694604532, Train Accuracy: 90.11235955056179, Validation Loss: 0.3474595919251442, Validation Accuracy: 86.99551569506727\n",
      "Time elapsed after 100 batches (training): 10.594998359680176\n",
      "Time elapsed after 100 batches (evaluation): 11.395496606826782\n",
      "Epoch: 10, Train Loss: 0.22633468945111548, Train Accuracy: 91.34831460674157, Validation Loss: 0.3919241673180035, Validation Accuracy: 87.4439461883408\n",
      "Time elapsed after 100 batches (training): 11.069996118545532\n",
      "Time elapsed after 100 batches (evaluation): 10.169501304626465\n",
      "Epoch: 11, Train Loss: 0.22561037779918738, Train Accuracy: 90.78651685393258, Validation Loss: 0.3520468462790762, Validation Accuracy: 86.54708520179372\n",
      "Time elapsed after 100 batches (training): 10.475502252578735\n",
      "Time elapsed after 100 batches (evaluation): 10.220999240875244\n",
      "Epoch: 12, Train Loss: 0.22380471375903913, Train Accuracy: 90.89887640449439, Validation Loss: 0.34359791076609064, Validation Accuracy: 86.54708520179372\n",
      "Time elapsed after 100 batches (training): 10.443498849868774\n",
      "Time elapsed after 100 batches (evaluation): 9.899498701095581\n",
      "Epoch: 13, Train Loss: 0.20752302131482533, Train Accuracy: 92.02247191011236, Validation Loss: 0.36645744847399847, Validation Accuracy: 86.99551569506727\n",
      "Time elapsed after 100 batches (training): 10.27799940109253\n",
      "Time elapsed after 100 batches (evaluation): 10.098500728607178\n",
      "Epoch: 14, Train Loss: 0.20995870565197297, Train Accuracy: 92.02247191011236, Validation Loss: 0.3246049088026796, Validation Accuracy: 87.4439461883408\n",
      "Time elapsed after 100 batches (training): 10.474502563476562\n",
      "Time elapsed after 100 batches (evaluation): 10.105499267578125\n",
      "Epoch: 15, Train Loss: 0.20791246835142374, Train Accuracy: 92.80898876404494, Validation Loss: 0.37281935289502144, Validation Accuracy: 86.99551569506727\n",
      "Time elapsed after 100 batches (training): 10.465998411178589\n",
      "Time elapsed after 100 batches (evaluation): 10.084999561309814\n",
      "Epoch: 16, Train Loss: 0.20850500610790082, Train Accuracy: 93.14606741573034, Validation Loss: 0.3143439968781812, Validation Accuracy: 87.4439461883408\n",
      "Time elapsed after 100 batches (training): 10.95000171661377\n",
      "Time elapsed after 100 batches (evaluation): 10.345502138137817\n",
      "Epoch: 17, Train Loss: 0.20053540649158613, Train Accuracy: 92.80898876404494, Validation Loss: 0.3534592996750559, Validation Accuracy: 87.89237668161435\n",
      "Time elapsed after 100 batches (training): 10.67850112915039\n",
      "Time elapsed after 100 batches (evaluation): 10.230498313903809\n",
      "Epoch: 18, Train Loss: 0.1992189065952386, Train Accuracy: 93.14606741573034, Validation Loss: 0.33599319575088366, Validation Accuracy: 87.4439461883408\n",
      "Time elapsed after 100 batches (training): 10.64200210571289\n",
      "Time elapsed after 100 batches (evaluation): 10.296499013900757\n",
      "Epoch: 19, Train Loss: 0.19778229070029088, Train Accuracy: 92.80898876404494, Validation Loss: 0.3127509169280529, Validation Accuracy: 86.99551569506727\n",
      "Time elapsed after 100 batches (training): 10.48549747467041\n",
      "Time elapsed after 100 batches (evaluation): 10.059500932693481\n",
      "Epoch: 20, Train Loss: 0.19529106321611575, Train Accuracy: 93.48314606741573, Validation Loss: 0.327959873846599, Validation Accuracy: 87.4439461883408\n",
      "Time elapsed after 100 batches (training): 10.488501071929932\n",
      "Time elapsed after 100 batches (evaluation): 10.050498485565186\n",
      "Epoch: 21, Train Loss: 0.19439390088830674, Train Accuracy: 93.59550561797752, Validation Loss: 0.28884074624095646, Validation Accuracy: 89.23766816143498\n",
      "Time elapsed after 100 batches (training): 10.481499671936035\n",
      "Time elapsed after 100 batches (evaluation): 10.035996913909912\n",
      "Epoch: 22, Train Loss: 0.19377475923725537, Train Accuracy: 93.03370786516854, Validation Loss: 0.29507106649024145, Validation Accuracy: 87.89237668161435\n",
      "Time elapsed after 100 batches (training): 10.499999284744263\n",
      "Time elapsed after 100 batches (evaluation): 10.012001037597656\n",
      "Epoch: 23, Train Loss: 0.18640942618783032, Train Accuracy: 94.26966292134831, Validation Loss: 0.3199484571814537, Validation Accuracy: 85.65022421524664\n",
      "Time elapsed after 100 batches (training): 10.691998958587646\n",
      "Time elapsed after 100 batches (evaluation): 10.049500703811646\n",
      "Epoch: 24, Train Loss: 0.18314218587641204, Train Accuracy: 94.15730337078652, Validation Loss: 0.3153631846819605, Validation Accuracy: 86.09865470852019\n",
      "Time elapsed after 100 batches (training): 10.674500703811646\n",
      "Time elapsed after 100 batches (evaluation): 10.058500051498413\n",
      "Epoch: 25, Train Loss: 0.17751773646367447, Train Accuracy: 94.71910112359551, Validation Loss: 0.33508046503577915, Validation Accuracy: 85.20179372197309\n",
      "Time elapsed after 100 batches (training): 10.659000158309937\n",
      "Time elapsed after 100 batches (evaluation): 10.062999248504639\n",
      "Epoch: 26, Train Loss: 0.17441470827907324, Train Accuracy: 94.15730337078652, Validation Loss: 0.279739964221205, Validation Accuracy: 87.89237668161435\n",
      "Time elapsed after 100 batches (training): 10.458998680114746\n",
      "Time elapsed after 100 batches (evaluation): 10.06099796295166\n",
      "Epoch: 27, Train Loss: 0.1910685006795185, Train Accuracy: 93.59550561797752, Validation Loss: 0.24381155520677567, Validation Accuracy: 89.68609865470852\n",
      "Time elapsed after 100 batches (training): 10.676998376846313\n",
      "Time elapsed after 100 batches (evaluation): 10.066499471664429\n",
      "Epoch: 28, Train Loss: 0.16273198117102897, Train Accuracy: 94.38202247191012, Validation Loss: 0.22808307089975902, Validation Accuracy: 91.92825112107623\n",
      "Time elapsed after 100 batches (training): 10.465499639511108\n",
      "Time elapsed after 100 batches (evaluation): 10.07449746131897\n",
      "Epoch: 29, Train Loss: 0.16350967224155152, Train Accuracy: 94.15730337078652, Validation Loss: 0.22848689130374364, Validation Accuracy: 91.92825112107623\n",
      "Time elapsed after 100 batches (training): 10.680498123168945\n",
      "Time elapsed after 100 batches (evaluation): 10.274498701095581\n",
      "Epoch: 30, Train Loss: 0.17044337413140706, Train Accuracy: 93.59550561797752, Validation Loss: 0.27820674649306704, Validation Accuracy: 88.78923766816143\n",
      "Time elapsed after 100 batches (evaluation): 2.930499792098999\n",
      "Epoch: 30. Test Loss: 0.1396354790776968. Test Accuracy: 96.42857142857143.\n",
      "Training complete.\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "Waiting for W&B process to finish... <strong style=\"color:green\">(success).</strong>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<style>\n",
       "    table.wandb td:nth-child(1) { padding: 0 10px; text-align: left ; width: auto;} td:nth-child(2) {text-align: left ; width: 100%}\n",
       "    .wandb-row { display: flex; flex-direction: row; flex-wrap: wrap; justify-content: flex-start; width: 100% }\n",
       "    .wandb-col { display: flex; flex-direction: column; flex-basis: 100%; flex: 1; padding: 10px; }\n",
       "    </style>\n",
       "<div class=\"wandb-row\"><div class=\"wandb-col\"><h3>Run history:</h3><br/><table class=\"wandb\"><tr><td>Epoch</td><td>▁▁▁▂▂▂▂▃▃▃▃▄▄▄▄▅▅▅▅▆▆▆▆▇▇▇▇███</td></tr><tr><td>Training Accuracy</td><td>▁▁▂▂▃▃▄▄▄▅▅▅▆▆▆▇▆▇▆▇▇▇████▇██▇</td></tr><tr><td>Training Loss</td><td>█▆▄▄▄▄▃▃▃▃▃▃▂▃▂▃▂▂▂▂▂▂▂▂▁▁▂▁▁▁</td></tr><tr><td>Validation Accuracy</td><td>▁▂▄▅▅▄▅▅▅▅▅▅▅▅▅▅▆▅▅▅▇▆▄▅▄▆▇██▆</td></tr><tr><td>Validation Loss</td><td>█▆▆▆▄▅▆▅▅▆▅▅▅▄▆▄▅▄▄▄▃▃▄▄▄▃▂▁▁▃</td></tr><tr><td>test_acc</td><td>▁</td></tr><tr><td>test_loss</td><td>▁</td></tr></table><br/></div><div class=\"wandb-col\"><h3>Run summary:</h3><br/><table class=\"wandb\"><tr><td>Epoch</td><td>30</td></tr><tr><td>Training Accuracy</td><td>93.59551</td></tr><tr><td>Training Loss</td><td>0.17044</td></tr><tr><td>Validation Accuracy</td><td>88.78924</td></tr><tr><td>Validation Loss</td><td>0.27821</td></tr><tr><td>test_acc</td><td>96.42857</td></tr><tr><td>test_loss</td><td>0.13964</td></tr></table><br/></div></div>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View run <strong style=\"color:#cdcd00\">patient_jh101_model_supervised</strong> at: <a href='https://wandb.ai/xmootoo/ssl-seizure-detection/runs/x3m62zy8' target=\"_blank\">https://wandb.ai/xmootoo/ssl-seizure-detection/runs/x3m62zy8</a><br/>Synced 6 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Find logs at: <code>.\\wandb\\run-20231019_002813-x3m62zy8\\logs</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Mac \n",
    "# data_path = \"/Users/xaviermootoo/Documents/Data/ssl-seizure-detection/patient_pyg/jh101/supervised/jh101_run1.pt\"\n",
    "# logdir = \"/Users/xaviermootoo/Documents/Data/ssl-seizure-detection/models/jh101_run1\"\n",
    "\n",
    "# PC\n",
    "data_path = r\"C:\\Users\\xmoot\\Desktop\\Data\\ssl-seizure-detection\\patient_pyg\\jh101\\supervised\\jh101_run1.pt\"\n",
    "logdir = r\"C:\\Users\\xmoot\\Desktop\\Data\\ssl-seizure-detection\\models\"\n",
    "\n",
    "# Training parameters\n",
    "patient_id = \"jh101\"\n",
    "epochs = 30\n",
    "model_name = \"supervised\"\n",
    "\n",
    "config = {\n",
    "    \"num_node_features\": 9,\n",
    "    \"num_edge_features\": 3,\n",
    "    \"hidden_channels\": 64,\n",
    "    \"out_channels\": 32,\n",
    "    \"dropout\": 0.1,\n",
    "}\n",
    "data_size = 1.0\n",
    "\n",
    "train(data_path, logdir, patient_id, epochs, config, data_size=data_size, val_ratio=0.2, test_ratio=0.1, \n",
    "          batch_size=32, num_workers=4, lr=1e-3, weight_decay=1e-3, timing=True, model_id=\"supervised\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Relative Positioning Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Failed to detect the name of this notebook, you can set it manually with the WANDB_NOTEBOOK_NAME environment variable to enable code saving.\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Currently logged in as: \u001b[33mxmootoo\u001b[0m. Use \u001b[1m`wandb login --relogin`\u001b[0m to force relogin\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "Tracking run with wandb version 0.15.12"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Run data is saved locally in <code>c:\\Users\\xmoot\\Desktop\\VSCode\\ssl-seizure-detection\\notebooks\\wandb\\run-20231019_002332-907fa9ss</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Syncing run <strong><a href='https://wandb.ai/xmootoo/ssl-seizure-detection/runs/907fa9ss' target=\"_blank\">patient_jh101_model_relative_positioning</a></strong> to <a href='https://wandb.ai/xmootoo/ssl-seizure-detection' target=\"_blank\">Weights & Biases</a> (<a href='https://wandb.me/run' target=\"_blank\">docs</a>)<br/>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View project at <a href='https://wandb.ai/xmootoo/ssl-seizure-detection' target=\"_blank\">https://wandb.ai/xmootoo/ssl-seizure-detection</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View run at <a href='https://wandb.ai/xmootoo/ssl-seizure-detection/runs/907fa9ss' target=\"_blank\">https://wandb.ai/xmootoo/ssl-seizure-detection/runs/907fa9ss</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using device: cuda\n",
      "Total number of examples in dataset: 82810.\n",
      "Total number of examples used: 15000.\n",
      "Number of training examples: 12000. Number of training batches: 375.\n",
      "Number of validation examples: 3000. Number of validation batches: 94.\n",
      "Time elapsed after 100 batches (training): 16.906001091003418\n",
      "Time elapsed after 100 batches (training): 10.530999422073364\n",
      "Time elapsed after 100 batches (training): 10.741497993469238\n",
      "Time elapsed after 100 batches (training): 10.570498704910278\n",
      "Time elapsed after 100 batches (evaluation): 13.948500394821167\n",
      "Epoch: 1, Train Loss: 0.38374514897664386, Train Accuracy: 82.94166666666666, Validation Loss: 0.22317350782612536, Validation Accuracy: 91.86666666666666\n",
      "Time elapsed after 100 batches (training): 14.534500360488892\n",
      "Time elapsed after 100 batches (training): 11.089513540267944\n",
      "Time elapsed after 100 batches (training): 10.875999450683594\n",
      "Time elapsed after 100 batches (training): 10.986000061035156\n",
      "Time elapsed after 100 batches (evaluation): 14.27499794960022\n",
      "Epoch: 2, Train Loss: 0.22838112158576648, Train Accuracy: 91.275, Validation Loss: 0.17226635732073733, Validation Accuracy: 93.76666666666667\n",
      "Time elapsed after 100 batches (training): 14.983502864837646\n",
      "Time elapsed after 100 batches (training): 11.10999584197998\n",
      "Time elapsed after 100 batches (training): 11.05899453163147\n",
      "Time elapsed after 100 batches (training): 9.884997606277466\n",
      "Time elapsed after 100 batches (evaluation): 14.351500034332275\n",
      "Epoch: 3, Train Loss: 0.12411784000943105, Train Accuracy: 95.61666666666666, Validation Loss: 0.07207123134681519, Validation Accuracy: 97.53333333333333\n",
      "Time elapsed after 100 batches (training): 14.925500869750977\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[1;32mc:\\Users\\xmoot\\Desktop\\VSCode\\ssl-seizure-detection\\notebooks\\train.ipynb Cell 5\u001b[0m line \u001b[0;36m2\n\u001b[0;32m     <a href='vscode-notebook-cell:/c%3A/Users/xmoot/Desktop/VSCode/ssl-seizure-detection/notebooks/train.ipynb#W4sZmlsZQ%3D%3D?line=20'>21</a>\u001b[0m val_ratio\u001b[39m=\u001b[39m\u001b[39m0.2\u001b[39m\n\u001b[0;32m     <a href='vscode-notebook-cell:/c%3A/Users/xmoot/Desktop/VSCode/ssl-seizure-detection/notebooks/train.ipynb#W4sZmlsZQ%3D%3D?line=21'>22</a>\u001b[0m test_ratio\u001b[39m=\u001b[39m\u001b[39m0\u001b[39m\n\u001b[1;32m---> <a href='vscode-notebook-cell:/c%3A/Users/xmoot/Desktop/VSCode/ssl-seizure-detection/notebooks/train.ipynb#W4sZmlsZQ%3D%3D?line=23'>24</a>\u001b[0m train(data_path, logdir, patient_id, epochs, config, data_size\u001b[39m=\u001b[39;49mdata_size, val_ratio\u001b[39m=\u001b[39;49m\u001b[39m0.2\u001b[39;49m, test_ratio\u001b[39m=\u001b[39;49m\u001b[39m0.0\u001b[39;49m, \n\u001b[0;32m     <a href='vscode-notebook-cell:/c%3A/Users/xmoot/Desktop/VSCode/ssl-seizure-detection/notebooks/train.ipynb#W4sZmlsZQ%3D%3D?line=24'>25</a>\u001b[0m           batch_size\u001b[39m=\u001b[39;49m\u001b[39m32\u001b[39;49m, num_workers\u001b[39m=\u001b[39;49m\u001b[39m4\u001b[39;49m, lr\u001b[39m=\u001b[39;49m\u001b[39m1e-3\u001b[39;49m, weight_decay\u001b[39m=\u001b[39;49m\u001b[39m1e-3\u001b[39;49m, timing\u001b[39m=\u001b[39;49m\u001b[39mTrue\u001b[39;49;00m, model_id\u001b[39m=\u001b[39;49mmodel_id)\n",
      "File \u001b[1;32mc:\\Users\\xmoot\\Desktop\\VSCode\\ssl-seizure-detection\\notebooks\\../src\\train.py:241\u001b[0m, in \u001b[0;36mtrain\u001b[1;34m(data_path, logdir, patient_id, epochs, config, data_size, val_ratio, test_ratio, batch_size, num_workers, lr, weight_decay, model_id, timing, classify, head, dropout)\u001b[0m\n\u001b[0;32m    237\u001b[0m \u001b[39m# Train our model for multiple epochs\u001b[39;00m\n\u001b[0;32m    238\u001b[0m \u001b[39mfor\u001b[39;00m epoch \u001b[39min\u001b[39;00m \u001b[39mrange\u001b[39m(epochs):\n\u001b[0;32m    239\u001b[0m     \n\u001b[0;32m    240\u001b[0m     \u001b[39m#<----------Training---------->\u001b[39;00m\n\u001b[1;32m--> 241\u001b[0m     epoch_train_loss, epoch_train_acc \u001b[39m=\u001b[39m train_model(model, train_loader, optimizer, criterion, device, classify, head, dropout, \n\u001b[0;32m    242\u001b[0m                                                     model_id, timing)\n\u001b[0;32m    244\u001b[0m     \u001b[39m#<----------Validation---------->\u001b[39;00m\n\u001b[0;32m    245\u001b[0m     epoch_val_loss, epoch_val_acc \u001b[39m=\u001b[39m evaluate_model(model, val_loader, criterion, device, classify, head, dropout\u001b[39m=\u001b[39m\u001b[39mFalse\u001b[39;00m, model_id\u001b[39m=\u001b[39mmodel_id, timing\u001b[39m=\u001b[39mtiming)\n",
      "File \u001b[1;32mc:\\Users\\xmoot\\Desktop\\VSCode\\ssl-seizure-detection\\notebooks\\../src\\train.py:39\u001b[0m, in \u001b[0;36mtrain_model\u001b[1;34m(model, train_loader, optimizer, criterion, device, classify, head, dropout, model_id, timing)\u001b[0m\n\u001b[0;32m     36\u001b[0m batch \u001b[39m=\u001b[39m batch\u001b[39m.\u001b[39mto(device)\n\u001b[0;32m     38\u001b[0m \u001b[39m# Compute forward pass\u001b[39;00m\n\u001b[1;32m---> 39\u001b[0m outputs \u001b[39m=\u001b[39m forward_pass(model, batch, model_id, classify, head, dropout)\n\u001b[0;32m     41\u001b[0m \u001b[39m# Calculate loss\u001b[39;00m\n\u001b[0;32m     42\u001b[0m loss \u001b[39m=\u001b[39m criterion(outputs\u001b[39m.\u001b[39msqueeze()\u001b[39m.\u001b[39mto(device), batch\u001b[39m.\u001b[39my\u001b[39m.\u001b[39mfloat()\u001b[39m.\u001b[39mto(device))\n",
      "File \u001b[1;32mc:\\Users\\xmoot\\Desktop\\VSCode\\ssl-seizure-detection\\notebooks\\../src\\train.py:16\u001b[0m, in \u001b[0;36mforward_pass\u001b[1;34m(model, batch, model_id, classify, head, dropout)\u001b[0m\n\u001b[0;32m     14\u001b[0m     \u001b[39mreturn\u001b[39;00m model(batch, classify, head, dropout)\n\u001b[0;32m     15\u001b[0m \u001b[39melif\u001b[39;00m model_id\u001b[39m==\u001b[39m\u001b[39m\"\u001b[39m\u001b[39mrelative_positioning\u001b[39m\u001b[39m\"\u001b[39m \u001b[39mor\u001b[39;00m model_id\u001b[39m==\u001b[39m\u001b[39m\"\u001b[39m\u001b[39mtemporal_shuffling\u001b[39m\u001b[39m\"\u001b[39m:\n\u001b[1;32m---> 16\u001b[0m     \u001b[39mreturn\u001b[39;00m model(batch, head)\n",
      "File \u001b[1;32mc:\\tools\\Anaconda3\\envs\\torch2_cuda11.8\\lib\\site-packages\\torch\\nn\\modules\\module.py:1501\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m   1496\u001b[0m \u001b[39m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[0;32m   1497\u001b[0m \u001b[39m# this function, and just call forward.\u001b[39;00m\n\u001b[0;32m   1498\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mnot\u001b[39;00m (\u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_backward_hooks \u001b[39mor\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_backward_pre_hooks \u001b[39mor\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_forward_hooks \u001b[39mor\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_forward_pre_hooks\n\u001b[0;32m   1499\u001b[0m         \u001b[39mor\u001b[39;00m _global_backward_pre_hooks \u001b[39mor\u001b[39;00m _global_backward_hooks\n\u001b[0;32m   1500\u001b[0m         \u001b[39mor\u001b[39;00m _global_forward_hooks \u001b[39mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[1;32m-> 1501\u001b[0m     \u001b[39mreturn\u001b[39;00m forward_call(\u001b[39m*\u001b[39margs, \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mkwargs)\n\u001b[0;32m   1502\u001b[0m \u001b[39m# Do not call functions when jit is used\u001b[39;00m\n\u001b[0;32m   1503\u001b[0m full_backward_hooks, non_full_backward_hooks \u001b[39m=\u001b[39m [], []\n",
      "File \u001b[1;32mc:\\Users\\xmoot\\Desktop\\VSCode\\ssl-seizure-detection\\notebooks\\../src\\models.py:87\u001b[0m, in \u001b[0;36mrelative_positioning.forward\u001b[1;34m(self, batch, head)\u001b[0m\n\u001b[0;32m     85\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39mforward\u001b[39m(\u001b[39mself\u001b[39m, batch, head\u001b[39m=\u001b[39m\u001b[39m\"\u001b[39m\u001b[39mlinear\u001b[39m\u001b[39m\"\u001b[39m):\n\u001b[0;32m     86\u001b[0m     \u001b[39m# Graph embeddings\u001b[39;00m\n\u001b[1;32m---> 87\u001b[0m     z1 \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mencoder(batch\u001b[39m.\u001b[39;49mx1, batch\u001b[39m.\u001b[39;49medge_index1, batch\u001b[39m.\u001b[39;49medge_attr1, batch\u001b[39m.\u001b[39;49mx1_batch)\n\u001b[0;32m     88\u001b[0m     z2 \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mencoder(batch\u001b[39m.\u001b[39mx2, batch\u001b[39m.\u001b[39medge_index2, batch\u001b[39m.\u001b[39medge_attr2, batch\u001b[39m.\u001b[39mx2_batch)\n\u001b[0;32m     90\u001b[0m     \u001b[39m# Contrast the embeddings\u001b[39;00m\n",
      "File \u001b[1;32mc:\\tools\\Anaconda3\\envs\\torch2_cuda11.8\\lib\\site-packages\\torch\\nn\\modules\\module.py:1501\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m   1496\u001b[0m \u001b[39m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[0;32m   1497\u001b[0m \u001b[39m# this function, and just call forward.\u001b[39;00m\n\u001b[0;32m   1498\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mnot\u001b[39;00m (\u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_backward_hooks \u001b[39mor\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_backward_pre_hooks \u001b[39mor\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_forward_hooks \u001b[39mor\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_forward_pre_hooks\n\u001b[0;32m   1499\u001b[0m         \u001b[39mor\u001b[39;00m _global_backward_pre_hooks \u001b[39mor\u001b[39;00m _global_backward_hooks\n\u001b[0;32m   1500\u001b[0m         \u001b[39mor\u001b[39;00m _global_forward_hooks \u001b[39mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[1;32m-> 1501\u001b[0m     \u001b[39mreturn\u001b[39;00m forward_call(\u001b[39m*\u001b[39margs, \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mkwargs)\n\u001b[0;32m   1502\u001b[0m \u001b[39m# Do not call functions when jit is used\u001b[39;00m\n\u001b[0;32m   1503\u001b[0m full_backward_hooks, non_full_backward_hooks \u001b[39m=\u001b[39m [], []\n",
      "File \u001b[1;32mc:\\Users\\xmoot\\Desktop\\VSCode\\ssl-seizure-detection\\notebooks\\../src\\models.py:54\u001b[0m, in \u001b[0;36mgnn_encoder.forward\u001b[1;34m(self, x, edge_index, edge_attr, batch)\u001b[0m\n\u001b[0;32m     51\u001b[0m x \u001b[39m=\u001b[39m F\u001b[39m.\u001b[39mrelu(\u001b[39mself\u001b[39m\u001b[39m.\u001b[39mconv1(x, edge_index, edge_attr))\n\u001b[0;32m     53\u001b[0m \u001b[39m# GATConv layer\u001b[39;00m\n\u001b[1;32m---> 54\u001b[0m x \u001b[39m=\u001b[39m F\u001b[39m.\u001b[39mrelu(\u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mconv2(x, edge_index))\n\u001b[0;32m     56\u001b[0m \u001b[39m# Global average pooling\u001b[39;00m\n\u001b[0;32m     57\u001b[0m x \u001b[39m=\u001b[39m global_mean_pool(x, batch) \u001b[39m#<-- batch vector to keep track of graphs\u001b[39;00m\n",
      "File \u001b[1;32mc:\\tools\\Anaconda3\\envs\\torch2_cuda11.8\\lib\\site-packages\\torch\\nn\\modules\\module.py:1501\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m   1496\u001b[0m \u001b[39m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[0;32m   1497\u001b[0m \u001b[39m# this function, and just call forward.\u001b[39;00m\n\u001b[0;32m   1498\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mnot\u001b[39;00m (\u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_backward_hooks \u001b[39mor\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_backward_pre_hooks \u001b[39mor\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_forward_hooks \u001b[39mor\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_forward_pre_hooks\n\u001b[0;32m   1499\u001b[0m         \u001b[39mor\u001b[39;00m _global_backward_pre_hooks \u001b[39mor\u001b[39;00m _global_backward_hooks\n\u001b[0;32m   1500\u001b[0m         \u001b[39mor\u001b[39;00m _global_forward_hooks \u001b[39mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[1;32m-> 1501\u001b[0m     \u001b[39mreturn\u001b[39;00m forward_call(\u001b[39m*\u001b[39margs, \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mkwargs)\n\u001b[0;32m   1502\u001b[0m \u001b[39m# Do not call functions when jit is used\u001b[39;00m\n\u001b[0;32m   1503\u001b[0m full_backward_hooks, non_full_backward_hooks \u001b[39m=\u001b[39m [], []\n",
      "File \u001b[1;32mc:\\tools\\Anaconda3\\envs\\torch2_cuda11.8\\lib\\site-packages\\torch_geometric\\nn\\conv\\gat_conv.py:237\u001b[0m, in \u001b[0;36mGATConv.forward\u001b[1;34m(self, x, edge_index, edge_attr, size, return_attention_weights)\u001b[0m\n\u001b[0;32m    235\u001b[0m         num_nodes \u001b[39m=\u001b[39m \u001b[39mmin\u001b[39m(num_nodes, x_dst\u001b[39m.\u001b[39msize(\u001b[39m0\u001b[39m))\n\u001b[0;32m    236\u001b[0m     num_nodes \u001b[39m=\u001b[39m \u001b[39mmin\u001b[39m(size) \u001b[39mif\u001b[39;00m size \u001b[39mis\u001b[39;00m \u001b[39mnot\u001b[39;00m \u001b[39mNone\u001b[39;00m \u001b[39melse\u001b[39;00m num_nodes\n\u001b[1;32m--> 237\u001b[0m     edge_index, edge_attr \u001b[39m=\u001b[39m remove_self_loops(\n\u001b[0;32m    238\u001b[0m         edge_index, edge_attr)\n\u001b[0;32m    239\u001b[0m     edge_index, edge_attr \u001b[39m=\u001b[39m add_self_loops(\n\u001b[0;32m    240\u001b[0m         edge_index, edge_attr, fill_value\u001b[39m=\u001b[39m\u001b[39mself\u001b[39m\u001b[39m.\u001b[39mfill_value,\n\u001b[0;32m    241\u001b[0m         num_nodes\u001b[39m=\u001b[39mnum_nodes)\n\u001b[0;32m    242\u001b[0m \u001b[39melif\u001b[39;00m \u001b[39misinstance\u001b[39m(edge_index, SparseTensor):\n",
      "File \u001b[1;32mc:\\tools\\Anaconda3\\envs\\torch2_cuda11.8\\lib\\site-packages\\torch_geometric\\utils\\loop.py:80\u001b[0m, in \u001b[0;36mremove_self_loops\u001b[1;34m(edge_index, edge_attr)\u001b[0m\n\u001b[0;32m     77\u001b[0m mask \u001b[39m=\u001b[39m edge_index[\u001b[39m0\u001b[39m] \u001b[39m!=\u001b[39m edge_index[\u001b[39m1\u001b[39m]\n\u001b[0;32m     78\u001b[0m edge_index \u001b[39m=\u001b[39m edge_index[:, mask]\n\u001b[1;32m---> 80\u001b[0m \u001b[39mif\u001b[39;00m layout \u001b[39mis\u001b[39;49;00m \u001b[39mnot\u001b[39;49;00m \u001b[39mNone\u001b[39;49;00m:\n\u001b[0;32m     81\u001b[0m     \u001b[39massert\u001b[39;00m edge_attr \u001b[39mis\u001b[39;00m \u001b[39mnot\u001b[39;00m \u001b[39mNone\u001b[39;00m\n\u001b[0;32m     82\u001b[0m     edge_attr \u001b[39m=\u001b[39m edge_attr[mask]\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "# Mac\n",
    "# data_path = \"/Users/xaviermootoo/Documents/Data/ssl-seizure-detection/patient_pyg/jh101/relative_positioning/jh101_run1_12s_90s.pt\"\n",
    "# logdir = \"/Users/xaviermootoo/Documents/Data/ssl-seizure-detection/models/jh101_run1_rp\"\n",
    "\n",
    "# PC\n",
    "data_path = r\"C:\\Users\\xmoot\\Desktop\\Data\\ssl-seizure-detection\\patient_pyg\\jh101\\relative_positioning\\jh101_run1_12s_90s_0.8sr.pt\"\n",
    "logdir = r\"C:\\Users\\xmoot\\Desktop\\Data\\ssl-seizure-detection\\models\"\n",
    "\n",
    "\n",
    "# Training parameters\n",
    "patient_id = \"jh101\"\n",
    "epochs = 10\n",
    "model_id = \"relative_positioning\"\n",
    "\n",
    "config = {\n",
    "    \"num_node_features\": 9,\n",
    "    \"num_edge_features\": 3,\n",
    "    \"hidden_channels\": [64, 32, 64, 128, 256],\n",
    "    }\n",
    "data_size=15000\n",
    "val_ratio=0.2\n",
    "test_ratio=0\n",
    "\n",
    "train(data_path, logdir, patient_id, epochs, config, data_size=data_size, val_ratio=0.2, test_ratio=0.0, \n",
    "          batch_size=32, num_workers=4, lr=1e-3, weight_decay=1e-3, timing=True, model_id=model_id)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Temporal Shuffling Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "Tracking run with wandb version 0.15.12"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Run data is saved locally in <code>c:\\Users\\xmoot\\Desktop\\VSCode\\ssl-seizure-detection\\notebooks\\wandb\\run-20231018_233012-v05ehd3x</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Syncing run <strong><a href='https://wandb.ai/xmootoo/ssl-seizure-detection/runs/v05ehd3x' target=\"_blank\">patient_jh101_model_temporal_shuffling</a></strong> to <a href='https://wandb.ai/xmootoo/ssl-seizure-detection' target=\"_blank\">Weights & Biases</a> (<a href='https://wandb.me/run' target=\"_blank\">docs</a>)<br/>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View project at <a href='https://wandb.ai/xmootoo/ssl-seizure-detection' target=\"_blank\">https://wandb.ai/xmootoo/ssl-seizure-detection</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View run at <a href='https://wandb.ai/xmootoo/ssl-seizure-detection/runs/v05ehd3x' target=\"_blank\">https://wandb.ai/xmootoo/ssl-seizure-detection/runs/v05ehd3x</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using device: cuda\n",
      "Total number of examples in dataset: 278130.\n",
      "Total number of examples used: 1000.\n",
      "Number of training examples: 800. Number of training batches: 25.\n",
      "Number of validation examples: 200. Number of validation batches: 7.\n",
      "Time elapsed after 100 batches (training): 12.718000650405884\n",
      "Time elapsed after 100 batches (evaluation): 12.438498735427856\n",
      "Epoch: 1, Train Loss: 0.7215001153945922, Train Accuracy: 50.25, Validation Loss: 0.707123305116381, Validation Accuracy: 52.5\n",
      "Training complete.\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "Waiting for W&B process to finish... <strong style=\"color:green\">(success).</strong>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<style>\n",
       "    table.wandb td:nth-child(1) { padding: 0 10px; text-align: left ; width: auto;} td:nth-child(2) {text-align: left ; width: 100%}\n",
       "    .wandb-row { display: flex; flex-direction: row; flex-wrap: wrap; justify-content: flex-start; width: 100% }\n",
       "    .wandb-col { display: flex; flex-direction: column; flex-basis: 100%; flex: 1; padding: 10px; }\n",
       "    </style>\n",
       "<div class=\"wandb-row\"><div class=\"wandb-col\"><h3>Run history:</h3><br/><table class=\"wandb\"><tr><td>Epoch</td><td>▁</td></tr><tr><td>Training Accuracy</td><td>▁</td></tr><tr><td>Training Loss</td><td>▁</td></tr><tr><td>Validation Accuracy</td><td>▁</td></tr><tr><td>Validation Loss</td><td>▁</td></tr></table><br/></div><div class=\"wandb-col\"><h3>Run summary:</h3><br/><table class=\"wandb\"><tr><td>Epoch</td><td>1</td></tr><tr><td>Training Accuracy</td><td>50.25</td></tr><tr><td>Training Loss</td><td>0.7215</td></tr><tr><td>Validation Accuracy</td><td>52.5</td></tr><tr><td>Validation Loss</td><td>0.70712</td></tr></table><br/></div></div>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View run <strong style=\"color:#cdcd00\">patient_jh101_model_temporal_shuffling</strong> at: <a href='https://wandb.ai/xmootoo/ssl-seizure-detection/runs/v05ehd3x' target=\"_blank\">https://wandb.ai/xmootoo/ssl-seizure-detection/runs/v05ehd3x</a><br/>Synced 6 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Find logs at: <code>.\\wandb\\run-20231018_233012-v05ehd3x\\logs</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Mac\n",
    "data_path = \"/Users/xaviermootoo/Documents/Data/ssl-seizure-detection/patient_pyg/jh101/temporal_shuffling/jh101_run1_12s_90_0.22sr.pt\"\n",
    "logdir = \"/Users/xaviermootoo/Documents/Data/ssl-seizure-detection/models/jh101_run1_ts\"\n",
    "\n",
    "# PC\n",
    "data_path = r\"C:\\Users\\xmoot\\Desktop\\Data\\ssl-seizure-detection\\patient_pyg\\jh101\\temporal_shuffling\\jh101_run1_12s_90s_0.3sr.pt\"\n",
    "logdir = r\"C:\\Users\\xmoot\\Desktop\\Data\\ssl-seizure-detection\\models\"\n",
    "\n",
    "# Training parameters\n",
    "patient_id = \"jh101\"\n",
    "epochs = 1\n",
    "model_id = \"temporal_shuffling\"\n",
    "\n",
    "config = {\n",
    "    \"num_node_features\": 9,\n",
    "    \"num_edge_features\": 3,\n",
    "    \"hidden_channels\": [64, 32, 64, 128, 256],\n",
    "}\n",
    "data_size = 1000\n",
    "\n",
    "train(data_path, logdir, patient_id, epochs, config, data_size=data_size, val_ratio=0.2, test_ratio=0, \n",
    "          batch_size=32, num_workers=4, lr=1e-3, weight_decay=1e-3, timing=True, model_id=model_id)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "torch2_mps",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
