{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Preprocessing Guide\n",
    "This notebooks serves as a guide on converting the initial graph representations created by [DÃ­az-Montiel & Lankarany (2023)](https://www.biorxiv.org/content/10.1101/2023.06.02.543277v1.abstract) from the OpenNeuro ds003029 dataset into a format that can be used by [PyTorch Geometric](https://pytorch-geometric.readthedocs.io/en/latest/). This is fully automated using the `patch` function in `src/patch.py`. The processed data we are using can be found in the Graham cluster directory:\n",
    "\n",
    "`/User/projects/def-milad777/gr_research/brain-greg/data/ds003029-processed/graph_representation_elements`\n",
    "\n",
    "which contains folders for each patient and their runs."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Intel MKL WARNING: Support of Intel(R) Streaming SIMD Extensions 4.2 (Intel(R) SSE4.2) enabled only processors has been deprecated. Intel oneAPI Math Kernel Library 2025.0 will require Intel(R) Advanced Vector Extensions (Intel(R) AVX) instructions.\n",
      "Intel MKL WARNING: Support of Intel(R) Streaming SIMD Extensions 4.2 (Intel(R) SSE4.2) enabled only processors has been deprecated. Intel oneAPI Math Kernel Library 2025.0 will require Intel(R) Advanced Vector Extensions (Intel(R) AVX) instructions.\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "import pickle\n",
    "import numpy as np\n",
    "import sys\n",
    "sys.path.append('../src')\n",
    "from preprocess import new_grs, create_tensordata_new, convert_to_Data, pseudo_data, convert_to_PairData, convert_to_TripletData"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "### Step 1: Extracting Graph Representations\n",
    "For each patient and each run, there are three files: preictal (before seizure), ictal (seizure occurring), and postictal (after seizure). Each file is a list with entries of the form the form `graph = [A, NF, EF]`. Where `A`, `NF`, and `EF` are lists of length 4, 3, and 4 respectively defined below.\n",
    "\n",
    "`A = [A0, A1, A2, A3]`, where :\n",
    "-   `A0` = Ones, shape `(107,107)`.\n",
    "-   `A1` = Correlation, shape `(107,107)`.  \n",
    "-   `A2` = Coherence, shape `(107,107)`.\n",
    "-   `A3` = Phase, shape `(107,107)`.\n",
    "\n",
    "`NF = [NF0, NF1, NF2]`, where:\n",
    "\n",
    "-  `NF0` = Ones, shape `(107,1)`.\n",
    "-  `NF1` = Average Energy, shape `(107,1)`.\n",
    "-  `NF2` = Band Energy, shape `(107,8)`.\n",
    "\n",
    "\n",
    "`EF = [EF0, EF1, EF2, EF3]`, where:\n",
    "\n",
    "-  `EF0` = Ones, shape `(107,107,1)`.\n",
    "-  `EF1` = Correlation, shape `(107,107,1)`.\n",
    "-  `EF2` = Coherence, shape `(107,107,1)`.\n",
    "-  `EF3` = Phase, shape `(107,107,1)`.\n",
    "\n",
    "All the information above has been (experimentally) confirmed by the above and Alan's documentation of `get_nf`, `get_adj`, and `get_ef` helper functions in his `load_data()` function, but should talk to Alan about confirming these details for absolute certainty."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We'll first load the preictal, ictal, and postictal files for a single patient and run. In this case, the patient folder is `jh101` and we are using run $1$."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "path_ictal_1 = f\"/Users/xaviermootoo/Documents/Data/ssl-seizure-detection/patient_gr/jh101/ictal_1.pickle\"\n",
    "path_preictal_1 = f\"/Users/xaviermootoo/Documents/Data/ssl-seizure-detection/patient_gr/jh101/preictal_1.pickle\"\n",
    "path_postictal_1 = f\"/Users/xaviermootoo/Documents/Data/ssl-seizure-detection/patient_gr/jh101/postictal_1.pickle\"\n",
    "\n",
    "with open(path_preictal_1, 'rb') as f:\n",
    "    data_preictal_1 = pickle.load(f)\n",
    "with open(path_ictal_1, 'rb') as f:\n",
    "    data_ictal_1 = pickle.load(f)\n",
    "with open(path_postictal_1, 'rb') as f:\n",
    "    data_postictal_1 = pickle.load(f)\n",
    "\n",
    "path_ictal_2 = f\"/Users/xaviermootoo/Documents/Data/ssl-seizure-detection/patient_gr/pt3/ictal_2.pickle\"\n",
    "path_preictal_2 = f\"/Users/xaviermootoo/Documents/Data/ssl-seizure-detection/patient_gr/pt3/preictal_2.pickle\"\n",
    "path_postictal_2 = f\"/Users/xaviermootoo/Documents/Data/ssl-seizure-detection/patient_gr/pt3/postictal_2.pickle\"\n",
    "\n",
    "with open(path_preictal_2, 'rb') as f:\n",
    "    data_preictal_2 = pickle.load(f)\n",
    "with open(path_ictal_2, 'rb') as f:\n",
    "    data_ictal_2 = pickle.load(f)\n",
    "with open(path_postictal_2, 'rb') as f:\n",
    "    data_postictal_2 = pickle.load(f)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Valid & Corrupt File List\n",
    "**jh101**:\n",
    "- Run 1 (valid)\n",
    "- Run 2 (valid)\n",
    "- Run 3 (valid)\n",
    "- Run 4 (valid)\n",
    "\n",
    "**pt3**:\n",
    "- Run 1 (corrupted)\n",
    "- Run 2 (valid)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Step 2: Selecting Graph Representations\n",
    "For simplicity we're going to select the most extensive graph representation:\n",
    "-  `A` = None\n",
    "-  `NF` = Average Energy and Band Energy, shape `(107,9)`.\n",
    "-  `EF` = Correlation, Coherence, Phase, shape `(107, 107, 3)`.\n",
    "\n",
    "Note that because most PyG layers do not use a separate adjacency matrix with weights, we will not use it, and instead we'll use all the possible edge features. This is facilitated by the `new_grs` functions which gives us the option of **binary classification** and **multiclass classification** based `mode` argument."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Binary Classification"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Select the graph representation for each class\n",
    "new_data_preictal = new_grs(data_preictal, type=\"preictal\", mode=\"binary\")\n",
    "new_data_ictal = new_grs(data_ictal, type=\"ictal\", mode=\"binary\")\n",
    "new_data_postictal = new_grs(data_postictal, type=\"postictal\", mode=\"binary\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Multiclass Classification"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Select the graph representation for each class\n",
    "new_data_preictal = new_grs(data_preictal, type=\"preictal\", mode=\"multiclass\")\n",
    "new_data_ictal = new_grs(data_ictal, type=\"ictal\", mode=\"multiclass\")\n",
    "new_data_postictal = new_grs(data_postictal, type=\"postictal\", mode=\"multiclass\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "After selecting the GRs for each class, we concatenate them temporally into a single list `[preictal, ictal, postictal]`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "new_data = new_data_preictal + new_data_ictal + new_data_postictal"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Step 3: Standard GRs $\\rightarrow$ PyG GRs\n",
    "The function `create_tensordata_new` converts the pickle file list of standard graph representations, a list with entries of the form $[ [NF, EF] , Y]$, where $NF$ are the node features, $EF$ are the edge features, and $Y$ is the graph label. The function first inserts an `edge_index` for a **complete graph** in the PyG format, which is a tensor of shape `[2, num_edges]` where each column $[i \\ \\ j]^T$ indicates the directed edge $i \\to j$; this is built using the helper function `build_K_n` found in `preprocess.py`. The node features $NF$ are untouched, but converted to float32 a tensor, notated by `x` in PyG. The edge features are converted to `edge_attr` which is a float32 tensor of shape `[num_edges, num_edge_features]` which follows the `edge_index` accordingly, i.e. the 4th column in `edge_index` (4th edge) will correspond to the edge feature `edge_attr[3,:]`, and so on. The label $Y$ is converted to a long torch tensor. The output is a list with entries of the form `[[edge_index, x, edge_attr], y]`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "pyg_grs = create_tensordata_new(num_nodes=107, data_list=new_data, complete=True, save=False, logdir=None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1113\n",
      "<class 'torch.Tensor'>\n",
      "Edge features shape: torch.Size([11342, 3])\n",
      "Edge features stored in edge_attr: tensor([[ 0.4213,  0.3902,  0.2319],\n",
      "        [ 0.4969,  0.4126, -0.1610],\n",
      "        [ 0.4405,  0.3708,  0.7440],\n",
      "        ...,\n",
      "        [ 0.8595,  0.2592, -0.5651],\n",
      "        [ 0.7164,  0.2137, -0.8699],\n",
      "        [ 0.8794,  0.2266, -0.6079]])\n"
     ]
    }
   ],
   "source": [
    "# Look inside of pyg_grs\n",
    "print(len(pyg_grs))\n",
    "print(type(pyg_grs[0][0][0]))\n",
    "print(\"Edge features shape:\", pyg_grs[0][0][2].shape)\n",
    "print(\"Edge features stored in edge_attr:\", pyg_grs[0][0][2])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Step 4: PyG GRs $\\rightarrow$ PyG Data\n",
    "<u>**Stop after this step**</u> if you only need PyG Data for <u>**supervised learning**</u>. \n",
    "\n",
    "Here we take the PyG graph representations, and apply the `convert_to_Data` function to create a new list where each entry is now a `torch_geometric.data.Data` object. This is the main object uses to hold graphs in PyG, so we need to use it, especially for batching (for more details see my tutorial `tutorial.ipynb`, or click [here](https://pytorch-geometric.readthedocs.io/en/latest/get_started/introduction.html) for the official tutorial from PyG)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Convert the PyG GRs to the PyG Data format\n",
    "pyg_Data_path = r\"C:\\Users\\xmoot\\Desktop\\Data\\ssl-seizure-detection\\patient_gr\\jh101_pyg_Data.pt\"\n",
    "Data_list = convert_to_Data(pyg_grs, save=True, logdir=pyg_Data_path)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Step 5: Relative Positioning\n",
    "In this step we take the output of Step 3 (`pyg_grs`) and create the pseudolabeled dataset of graph pairs for the relative positioning self-supervised method.  Given our list `pyg_grs` and hyperparameters $\\tau_+$ and $\\tau_-$. The function `pseudo_data` below returns a list of graph pairs where each entry is of the form `[[edge_index1, x1, edge_attr1], [edge_index2, x2, edge_attr2], y]`, where `y` is a pseudolabel (not the old label). Since the total size of the pseudolabeled dataset can be quite large, we use the `sample_ratio` argument to randomly sample a certain portion of it (e.g., `sample_ratio = 0.2` will give us 20% of the total pseudolabeled dataset). Also note that the function will return an equal number of positive and negative samples, as `pseudo_data` automatically balances out the correspondingly classes."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of examples: 21250\n",
      "y\n",
      "0    10625\n",
      "1    10625\n",
      "Name: count, dtype: int64\n"
     ]
    }
   ],
   "source": [
    "pdata = pseudo_data(pyg_grs, tau_pos=12 // 0.12, tau_neg=60 // 0.12, stats=True, save=False, patientid=\"\", \n",
    "                            logdir=None, model=\"relative_positioning\", sample_ratio=0.10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "21250\n",
      "Edge features shape: torch.Size([11342, 3])\n",
      "Edge features stored in edge_attr: tensor([[ 0.1689,  0.2751,  0.3535],\n",
      "        [ 0.7258,  0.2714,  0.5142],\n",
      "        [ 0.4268,  0.3288,  0.0477],\n",
      "        ...,\n",
      "        [ 0.2697,  0.2210,  0.7101],\n",
      "        [ 0.4200,  0.2228, -0.2204],\n",
      "        [ 0.5756,  0.2243, -0.2721]])\n"
     ]
    }
   ],
   "source": [
    "# Look inside of pdata\n",
    "print(len(pdata))\n",
    "example = pdata[0]\n",
    "graph1, graph2, label = example\n",
    "edge_index1, x1, edge_attr1 = graph1\n",
    "edge_index2, x2, edge_attr2 = graph2\n",
    "print(\"Edge features shape:\", edge_attr1.shape)\n",
    "print(\"Edge features stored in edge_attr:\", edge_attr1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now instead of converting each graph pair to `torch_geometric.data.Data` object, we instead create a new class called `PairData` that inherits from the `torch_geometric.data.Data` class, allowing us to batch *pairs* of graphs. We use the `convert_to_PairData` function to convert the list of graph pairs to a list of `PairData` objects (see [here](https://pytorch-geometric.readthedocs.io/en/latest/advanced/batching.html) for more details)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "Pair_Data = convert_to_PairData(pdata, save=False, logdir=None)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Step 6: Temporal Shuffling\n",
    "This step is nearly identical to Step 5, we take the `pyg_grs` and use them to create a pseudolabeled dataset for the temporal shuffling self-supervised method. However, in this method we generate *graph triplets* of the form `[[edge_index1, x1, edge_attr1], [edge_index2, x2, edge_attr2], [edge_index3, x3, edge_attr3], y]` where `y` is the pseudolabel. The size of the pseudolabeled dataset for temporal shuffling can be extremely large, therefore it is <u>**strongly encouraged**</u> to use the `sample_ratio` argument to scale down the dataset."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "pdata = pseudo_data(pyg_grs, tau_pos=12 // 0.12, tau_neg=60 // 0.12, stats=True, save=False, patientid=\"patient\", logdir=None, \n",
    "                    model=\"temporal_shuffling\", sample_ratio=0.3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[ 0.1689,  0.2751,  0.3535],\n",
      "        [ 0.7258,  0.2714,  0.5142],\n",
      "        [ 0.4268,  0.3288,  0.0477],\n",
      "        ...,\n",
      "        [ 0.2697,  0.2210,  0.7101],\n",
      "        [ 0.4200,  0.2228, -0.2204],\n",
      "        [ 0.5756,  0.2243, -0.2721]])\n"
     ]
    }
   ],
   "source": [
    "print(pdata[0][0][2])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Similar to Step 5, we create a new class called `TripletData` that inherits from the `torch_geometric.data.Data` class for batching graph triplets in PyG."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Triplet_Data = convert_to_TripletData(pdata, save=False, logdir=None)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Step 7: Automatic Conversion\n",
    "The `patch` function in `patch.py` does all of the above, converting the original preictal, ictal, and postictal files from a single patient run. Please see documentation in `patch.py`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Intel MKL WARNING: Support of Intel(R) Streaming SIMD Extensions 4.2 (Intel(R) SSE4.2) enabled only processors has been deprecated. Intel oneAPI Math Kernel Library 2025.0 will require Intel(R) Advanced Vector Extensions (Intel(R) AVX) instructions.\n",
      "Intel MKL WARNING: Support of Intel(R) Streaming SIMD Extensions 4.2 (Intel(R) SSE4.2) enabled only processors has been deprecated. Intel oneAPI Math Kernel Library 2025.0 will require Intel(R) Advanced Vector Extensions (Intel(R) AVX) instructions.\n",
      "Number of examples: 1264\n",
      "y\n",
      "1    632\n",
      "0    632\n",
      "Name: count, dtype: int64\n"
     ]
    }
   ],
   "source": [
    "import sys\n",
    "sys.path.append('../src')\n",
    "from patch import *\n",
    "\n",
    "path_preictal = \"/Users/xaviermootoo/Documents/Data/ssl-seizure-detection/patient_gr/jh101/preictal_1.pickle\"\n",
    "path_ictal = \"/Users/xaviermootoo/Documents/Data/ssl-seizure-detection/patient_gr/jh101/ictal_1.pickle\"\n",
    "path_postictal = \"/Users/xaviermootoo/Documents/Data/ssl-seizure-detection/patient_gr/jh101/postictal_1.pickle\"\n",
    "\n",
    "graphrep_dir = (path_preictal, path_ictal, path_postictal)\n",
    "\n",
    "data = patch(graphrep_dir=graphrep_dir, logdir=None, file_name=\"\", num_electrodes=107, tau_pos=12//0.12, tau_neg=120//0.12, \n",
    "          model=\"relative_positioning\", stats=True, save=False, sample_ratio=0.1)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
